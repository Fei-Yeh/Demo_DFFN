I0218 21:03:20.696786 31980 caffe.cpp:218] Using GPUs 0
I0218 21:03:20.745122 31980 caffe.cpp:223] GPU 0: GeForce GTX TITAN X
I0218 21:03:21.102032 31980 solver.cpp:48] Initializing solver from parameters: 
test_iter: 2096
test_interval: 20000
base_lr: 0.1
display: 1000
max_iter: 20000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 20000
snapshot_prefix: "./snapshot/paviau/"
solver_mode: GPU
device_id: 0
net: "./prototxt_files/train_paviau.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 5000
stepvalue: 10000
stepvalue: 15000
stepvalue: 20000
I0218 21:03:21.102150 31980 solver.cpp:91] Creating training net from net file: ./prototxt_files/train_paviau.prototxt
I0218 21:03:21.103025 31980 net.cpp:332] The NetState phase (0) differed from the phase (1) specified by a rule in layer paviau
I0218 21:03:21.103081 31980 net.cpp:332] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I0218 21:03:21.103688 31980 net.cpp:58] Initializing net from parameters: 
name: "DFFN_paviau"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "paviau"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "samples/paviau/train.txt"
    batch_size: 100
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "data"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution10"
  top: "Convolution10"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution19"
  top: "Convolution19"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Convolution19"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Convolution18"
  bottom: "Convolution20"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU20"
  type: "ReLU"
  bottom: "Convolution21"
  top: "Convolution21"
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Eltwise9"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "Convolution23"
  top: "Convolution23"
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution24"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "Eltwise11"
  top: "Eltwise11"
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU24"
  type: "ReLU"
  bottom: "Convolution25"
  top: "Convolution25"
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Convolution25"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Eltwise11"
  bottom: "Convolution26"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "Eltwise12"
  top: "Eltwise12"
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Eltwise12"
  top: "Convolution27"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU26"
  type: "ReLU"
  bottom: "Convolution27"
  top: "Convolution27"
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Convolution27"
  top: "Convolution28"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm28"
  type: "BatchNorm"
  bottom: "Convolution28"
  top: "Convolution28"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale28"
  type: "Scale"
  bottom: "Convolution28"
  top: "Convolution28"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise13"
  type: "Eltwise"
  bottom: "Eltwise12"
  bottom: "Convolution28"
  top: "Eltwise13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU27"
  type: "ReLU"
  bottom: "Eltwise13"
  top: "Eltwise13"
}
layer {
  name: "Convolution35"
  type: "Convolution"
  bottom: "Eltwise13"
  top: "Convolution35"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm35"
  type: "BatchNorm"
  bottom: "Convolution35"
  top: "Convolution35"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale35"
  type: "Scale"
  bottom: "Convolution35"
  top: "Convolution35"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution36"
  type: "Convolution"
  bottom: "Eltwise13"
  top: "Convolution36"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm36"
  type: "BatchNorm"
  bottom: "Convolution36"
  top: "Convolution36"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale36"
  type: "Scale"
  bottom: "Convolution36"
  top: "Convolution36"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU34"
  type: "ReLU"
  bottom: "Convolution36"
  top: "Convolution36"
}
layer {
  name: "Convolution37"
  type: "Convolution"
  bottom: "Convolution36"
  top: "Convolution37"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm37"
  type: "BatchNorm"
  bottom: "Convolution37"
  top: "Convolution37"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale37"
  type: "Scale"
  bottom: "Convolution37"
  top: "Convolution37"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise17"
  type: "Eltwise"
  bottom: "Convolution35"
  bottom: "Convolution37"
  top: "Eltwise17"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU35"
  type: "ReLU"
  bottom: "Eltwise17"
  top: "Eltwise17"
}
layer {
  name: "Convolution38"
  type: "Convolution"
  bottom: "Eltwise17"
  top: "Convolution38"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm38"
  type: "BatchNorm"
  bottom: "Convolution38"
  top: "Convolution38"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale38"
  type: "Scale"
  bottom: "Convolution38"
  top: "Convolution38"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU36"
  type: "ReLU"
  bottom: "Convolution38"
  top: "Convolution38"
}
layer {
  name: "Convolution39"
  type: "Convolution"
  bottom: "Convolution38"
  top: "Convolution39"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm39"
  type: "BatchNorm"
  bottom: "Convolution39"
  top: "Convolution39"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale39"
  type: "Scale"
  bottom: "Convolution39"
  top: "Convolution39"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise18"
  type: "Eltwise"
  bottom: "Eltwise17"
  bottom: "Convolution39"
  top: "Eltwise18"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU37"
  type: "ReLU"
  bottom: "Eltwise18"
  top: "Eltwise18"
}
layer {
  name: "Convolution40"
  type: "Convolution"
  bottom: "Eltwise18"
  top: "Convolution40"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm40"
  type: "BatchNorm"
  bottom: "Convolution40"
  top: "Convolution40"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale40"
  type: "Scale"
  bottom: "Convolution40"
  top: "Convolution40"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU38"
  type: "ReLU"
  bottom: "Convolution40"
  top: "Convolution40"
}
layer {
  name: "Convolution41"
  type: "Convolution"
  bottom: "Convolution40"
  top: "Convolution41"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm41"
  type: "BatchNorm"
  bottom: "Convolution41"
  top: "Convolution41"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale41"
  type: "Scale"
  bottom: "Convolution41"
  top: "Convolution41"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise19"
  type: "Eltwise"
  bottom: "Eltwise18"
  bottom: "Convolution41"
  top: "Eltwise19"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU39"
  type: "ReLU"
  bottom: "Eltwise19"
  top: "Eltwise19"
}
layer {
  name: "Convolution42"
  type: "Convolution"
  bottom: "Eltwise19"
  top: "Convolution42"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm42"
  type: "BatchNorm"
  bottom: "Convolution42"
  top: "Convolution42"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale42"
  type: "Scale"
  bottom: "Convolution42"
  top: "Convolution42"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU40"
  type: "ReLU"
  bottom: "Convolution42"
  top: "Convolution42"
}
layer {
  name: "Convolution43"
  type: "Convolution"
  bottom: "Convolution42"
  top: "Convolution43"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm43"
  type: "BatchNorm"
  bottom: "Convolution43"
  top: "Convolution43"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale43"
  type: "Scale"
  bottom: "Convolution43"
  top: "Convolution43"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise20"
  type: "Eltwise"
  bottom: "Eltwise19"
  bottom: "Convolution43"
  top: "Eltwise20"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU41"
  type: "ReLU"
  bottom: "Eltwise20"
  top: "Eltwise20"
}
layer {
  name: "Convolution44"
  type: "Convolution"
  bottom: "Eltwise20"
  top: "Convolution44"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm44"
  type: "BatchNorm"
  bottom: "Convolution44"
  top: "Convolution44"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_
I0218 21:03:21.104101 31980 layer_factory.hpp:77] Creating layer paviau
I0218 21:03:21.104116 31980 net.cpp:100] Creating Layer paviau
I0218 21:03:21.104122 31980 net.cpp:418] paviau -> data
I0218 21:03:21.104141 31980 net.cpp:418] paviau -> label
I0218 21:03:21.104151 31980 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: samples/paviau/train.txt
I0218 21:03:21.104176 31980 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I0218 21:03:21.104933 31980 hdf5.cpp:36] Datatype class: H5T_FLOAT
I0218 21:03:21.117911 31980 net.cpp:150] Setting up paviau
I0218 21:03:21.117947 31980 net.cpp:157] Top shape: 100 5 23 23 (264500)
I0218 21:03:21.117952 31980 net.cpp:157] Top shape: 100 1 (100)
I0218 21:03:21.117955 31980 net.cpp:165] Memory required for data: 1058400
I0218 21:03:21.117962 31980 layer_factory.hpp:77] Creating layer Convolution1
I0218 21:03:21.117982 31980 net.cpp:100] Creating Layer Convolution1
I0218 21:03:21.117988 31980 net.cpp:444] Convolution1 <- data
I0218 21:03:21.118000 31980 net.cpp:418] Convolution1 -> Convolution1
I0218 21:03:21.300240 31980 net.cpp:150] Setting up Convolution1
I0218 21:03:21.300277 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.300282 31980 net.cpp:165] Memory required for data: 4444000
I0218 21:03:21.300305 31980 layer_factory.hpp:77] Creating layer BatchNorm1
I0218 21:03:21.300319 31980 net.cpp:100] Creating Layer BatchNorm1
I0218 21:03:21.300323 31980 net.cpp:444] BatchNorm1 <- Convolution1
I0218 21:03:21.300329 31980 net.cpp:405] BatchNorm1 -> Convolution1 (in-place)
I0218 21:03:21.300473 31980 net.cpp:150] Setting up BatchNorm1
I0218 21:03:21.300479 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.300482 31980 net.cpp:165] Memory required for data: 7829600
I0218 21:03:21.300490 31980 layer_factory.hpp:77] Creating layer Scale1
I0218 21:03:21.300504 31980 net.cpp:100] Creating Layer Scale1
I0218 21:03:21.300514 31980 net.cpp:444] Scale1 <- Convolution1
I0218 21:03:21.300518 31980 net.cpp:405] Scale1 -> Convolution1 (in-place)
I0218 21:03:21.300555 31980 layer_factory.hpp:77] Creating layer Scale1
I0218 21:03:21.300640 31980 net.cpp:150] Setting up Scale1
I0218 21:03:21.300647 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.300649 31980 net.cpp:165] Memory required for data: 11215200
I0218 21:03:21.300654 31980 layer_factory.hpp:77] Creating layer ReLU1
I0218 21:03:21.300662 31980 net.cpp:100] Creating Layer ReLU1
I0218 21:03:21.300663 31980 net.cpp:444] ReLU1 <- Convolution1
I0218 21:03:21.300668 31980 net.cpp:405] ReLU1 -> Convolution1 (in-place)
I0218 21:03:21.301162 31980 net.cpp:150] Setting up ReLU1
I0218 21:03:21.301174 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.301177 31980 net.cpp:165] Memory required for data: 14600800
I0218 21:03:21.301180 31980 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I0218 21:03:21.301187 31980 net.cpp:100] Creating Layer Convolution1_ReLU1_0_split
I0218 21:03:21.301189 31980 net.cpp:444] Convolution1_ReLU1_0_split <- Convolution1
I0218 21:03:21.301194 31980 net.cpp:418] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I0218 21:03:21.301200 31980 net.cpp:418] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I0218 21:03:21.301231 31980 net.cpp:150] Setting up Convolution1_ReLU1_0_split
I0218 21:03:21.301237 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.301241 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.301244 31980 net.cpp:165] Memory required for data: 21372000
I0218 21:03:21.301246 31980 layer_factory.hpp:77] Creating layer Convolution2
I0218 21:03:21.301256 31980 net.cpp:100] Creating Layer Convolution2
I0218 21:03:21.301259 31980 net.cpp:444] Convolution2 <- Convolution1_ReLU1_0_split_0
I0218 21:03:21.301265 31980 net.cpp:418] Convolution2 -> Convolution2
I0218 21:03:21.302862 31980 net.cpp:150] Setting up Convolution2
I0218 21:03:21.302876 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.302880 31980 net.cpp:165] Memory required for data: 24757600
I0218 21:03:21.302887 31980 layer_factory.hpp:77] Creating layer BatchNorm2
I0218 21:03:21.302892 31980 net.cpp:100] Creating Layer BatchNorm2
I0218 21:03:21.302896 31980 net.cpp:444] BatchNorm2 <- Convolution2
I0218 21:03:21.302901 31980 net.cpp:405] BatchNorm2 -> Convolution2 (in-place)
I0218 21:03:21.303030 31980 net.cpp:150] Setting up BatchNorm2
I0218 21:03:21.303035 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.303038 31980 net.cpp:165] Memory required for data: 28143200
I0218 21:03:21.303045 31980 layer_factory.hpp:77] Creating layer Scale2
I0218 21:03:21.303050 31980 net.cpp:100] Creating Layer Scale2
I0218 21:03:21.303052 31980 net.cpp:444] Scale2 <- Convolution2
I0218 21:03:21.303057 31980 net.cpp:405] Scale2 -> Convolution2 (in-place)
I0218 21:03:21.303084 31980 layer_factory.hpp:77] Creating layer Scale2
I0218 21:03:21.303161 31980 net.cpp:150] Setting up Scale2
I0218 21:03:21.303167 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.303170 31980 net.cpp:165] Memory required for data: 31528800
I0218 21:03:21.303174 31980 layer_factory.hpp:77] Creating layer ReLU2
I0218 21:03:21.303179 31980 net.cpp:100] Creating Layer ReLU2
I0218 21:03:21.303181 31980 net.cpp:444] ReLU2 <- Convolution2
I0218 21:03:21.303185 31980 net.cpp:405] ReLU2 -> Convolution2 (in-place)
I0218 21:03:21.303309 31980 net.cpp:150] Setting up ReLU2
I0218 21:03:21.303316 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.303319 31980 net.cpp:165] Memory required for data: 34914400
I0218 21:03:21.303323 31980 layer_factory.hpp:77] Creating layer Convolution3
I0218 21:03:21.303330 31980 net.cpp:100] Creating Layer Convolution3
I0218 21:03:21.303333 31980 net.cpp:444] Convolution3 <- Convolution2
I0218 21:03:21.303337 31980 net.cpp:418] Convolution3 -> Convolution3
I0218 21:03:21.304643 31980 net.cpp:150] Setting up Convolution3
I0218 21:03:21.304662 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.304666 31980 net.cpp:165] Memory required for data: 38300000
I0218 21:03:21.304672 31980 layer_factory.hpp:77] Creating layer BatchNorm3
I0218 21:03:21.304678 31980 net.cpp:100] Creating Layer BatchNorm3
I0218 21:03:21.304682 31980 net.cpp:444] BatchNorm3 <- Convolution3
I0218 21:03:21.304687 31980 net.cpp:405] BatchNorm3 -> Convolution3 (in-place)
I0218 21:03:21.304823 31980 net.cpp:150] Setting up BatchNorm3
I0218 21:03:21.304831 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.304832 31980 net.cpp:165] Memory required for data: 41685600
I0218 21:03:21.304841 31980 layer_factory.hpp:77] Creating layer Scale3
I0218 21:03:21.304846 31980 net.cpp:100] Creating Layer Scale3
I0218 21:03:21.304849 31980 net.cpp:444] Scale3 <- Convolution3
I0218 21:03:21.304854 31980 net.cpp:405] Scale3 -> Convolution3 (in-place)
I0218 21:03:21.304883 31980 layer_factory.hpp:77] Creating layer Scale3
I0218 21:03:21.304968 31980 net.cpp:150] Setting up Scale3
I0218 21:03:21.304975 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.304977 31980 net.cpp:165] Memory required for data: 45071200
I0218 21:03:21.304982 31980 layer_factory.hpp:77] Creating layer Eltwise1
I0218 21:03:21.304987 31980 net.cpp:100] Creating Layer Eltwise1
I0218 21:03:21.304991 31980 net.cpp:444] Eltwise1 <- Convolution1_ReLU1_0_split_1
I0218 21:03:21.304993 31980 net.cpp:444] Eltwise1 <- Convolution3
I0218 21:03:21.304998 31980 net.cpp:418] Eltwise1 -> Eltwise1
I0218 21:03:21.305019 31980 net.cpp:150] Setting up Eltwise1
I0218 21:03:21.305024 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.305028 31980 net.cpp:165] Memory required for data: 48456800
I0218 21:03:21.305030 31980 layer_factory.hpp:77] Creating layer ReLU3
I0218 21:03:21.305034 31980 net.cpp:100] Creating Layer ReLU3
I0218 21:03:21.305038 31980 net.cpp:444] ReLU3 <- Eltwise1
I0218 21:03:21.305042 31980 net.cpp:405] ReLU3 -> Eltwise1 (in-place)
I0218 21:03:21.305541 31980 net.cpp:150] Setting up ReLU3
I0218 21:03:21.305552 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.305554 31980 net.cpp:165] Memory required for data: 51842400
I0218 21:03:21.305558 31980 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I0218 21:03:21.305564 31980 net.cpp:100] Creating Layer Eltwise1_ReLU3_0_split
I0218 21:03:21.305567 31980 net.cpp:444] Eltwise1_ReLU3_0_split <- Eltwise1
I0218 21:03:21.305573 31980 net.cpp:418] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I0218 21:03:21.305580 31980 net.cpp:418] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I0218 21:03:21.305613 31980 net.cpp:150] Setting up Eltwise1_ReLU3_0_split
I0218 21:03:21.305619 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.305622 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.305624 31980 net.cpp:165] Memory required for data: 58613600
I0218 21:03:21.305627 31980 layer_factory.hpp:77] Creating layer Convolution4
I0218 21:03:21.305637 31980 net.cpp:100] Creating Layer Convolution4
I0218 21:03:21.305641 31980 net.cpp:444] Convolution4 <- Eltwise1_ReLU3_0_split_0
I0218 21:03:21.305645 31980 net.cpp:418] Convolution4 -> Convolution4
I0218 21:03:21.306598 31980 net.cpp:150] Setting up Convolution4
I0218 21:03:21.306612 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.306614 31980 net.cpp:165] Memory required for data: 61999200
I0218 21:03:21.306620 31980 layer_factory.hpp:77] Creating layer BatchNorm4
I0218 21:03:21.306627 31980 net.cpp:100] Creating Layer BatchNorm4
I0218 21:03:21.306630 31980 net.cpp:444] BatchNorm4 <- Convolution4
I0218 21:03:21.306634 31980 net.cpp:405] BatchNorm4 -> Convolution4 (in-place)
I0218 21:03:21.306772 31980 net.cpp:150] Setting up BatchNorm4
I0218 21:03:21.306779 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.306782 31980 net.cpp:165] Memory required for data: 65384800
I0218 21:03:21.306787 31980 layer_factory.hpp:77] Creating layer Scale4
I0218 21:03:21.306797 31980 net.cpp:100] Creating Layer Scale4
I0218 21:03:21.306804 31980 net.cpp:444] Scale4 <- Convolution4
I0218 21:03:21.306807 31980 net.cpp:405] Scale4 -> Convolution4 (in-place)
I0218 21:03:21.306838 31980 layer_factory.hpp:77] Creating layer Scale4
I0218 21:03:21.306923 31980 net.cpp:150] Setting up Scale4
I0218 21:03:21.306929 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.306931 31980 net.cpp:165] Memory required for data: 68770400
I0218 21:03:21.306936 31980 layer_factory.hpp:77] Creating layer ReLU4
I0218 21:03:21.306942 31980 net.cpp:100] Creating Layer ReLU4
I0218 21:03:21.306946 31980 net.cpp:444] ReLU4 <- Convolution4
I0218 21:03:21.306948 31980 net.cpp:405] ReLU4 -> Convolution4 (in-place)
I0218 21:03:21.307444 31980 net.cpp:150] Setting up ReLU4
I0218 21:03:21.307456 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.307458 31980 net.cpp:165] Memory required for data: 72156000
I0218 21:03:21.307461 31980 layer_factory.hpp:77] Creating layer Convolution5
I0218 21:03:21.307471 31980 net.cpp:100] Creating Layer Convolution5
I0218 21:03:21.307474 31980 net.cpp:444] Convolution5 <- Convolution4
I0218 21:03:21.307479 31980 net.cpp:418] Convolution5 -> Convolution5
I0218 21:03:21.308801 31980 net.cpp:150] Setting up Convolution5
I0218 21:03:21.308815 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.308817 31980 net.cpp:165] Memory required for data: 75541600
I0218 21:03:21.308823 31980 layer_factory.hpp:77] Creating layer BatchNorm5
I0218 21:03:21.308830 31980 net.cpp:100] Creating Layer BatchNorm5
I0218 21:03:21.308833 31980 net.cpp:444] BatchNorm5 <- Convolution5
I0218 21:03:21.308838 31980 net.cpp:405] BatchNorm5 -> Convolution5 (in-place)
I0218 21:03:21.308982 31980 net.cpp:150] Setting up BatchNorm5
I0218 21:03:21.308989 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.308991 31980 net.cpp:165] Memory required for data: 78927200
I0218 21:03:21.309000 31980 layer_factory.hpp:77] Creating layer Scale5
I0218 21:03:21.309005 31980 net.cpp:100] Creating Layer Scale5
I0218 21:03:21.309007 31980 net.cpp:444] Scale5 <- Convolution5
I0218 21:03:21.309012 31980 net.cpp:405] Scale5 -> Convolution5 (in-place)
I0218 21:03:21.309043 31980 layer_factory.hpp:77] Creating layer Scale5
I0218 21:03:21.309128 31980 net.cpp:150] Setting up Scale5
I0218 21:03:21.309134 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.309137 31980 net.cpp:165] Memory required for data: 82312800
I0218 21:03:21.309141 31980 layer_factory.hpp:77] Creating layer Eltwise2
I0218 21:03:21.309146 31980 net.cpp:100] Creating Layer Eltwise2
I0218 21:03:21.309149 31980 net.cpp:444] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I0218 21:03:21.309154 31980 net.cpp:444] Eltwise2 <- Convolution5
I0218 21:03:21.309159 31980 net.cpp:418] Eltwise2 -> Eltwise2
I0218 21:03:21.309175 31980 net.cpp:150] Setting up Eltwise2
I0218 21:03:21.309180 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.309183 31980 net.cpp:165] Memory required for data: 85698400
I0218 21:03:21.309186 31980 layer_factory.hpp:77] Creating layer ReLU5
I0218 21:03:21.309190 31980 net.cpp:100] Creating Layer ReLU5
I0218 21:03:21.309192 31980 net.cpp:444] ReLU5 <- Eltwise2
I0218 21:03:21.309197 31980 net.cpp:405] ReLU5 -> Eltwise2 (in-place)
I0218 21:03:21.309329 31980 net.cpp:150] Setting up ReLU5
I0218 21:03:21.309335 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.309339 31980 net.cpp:165] Memory required for data: 89084000
I0218 21:03:21.309341 31980 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I0218 21:03:21.309346 31980 net.cpp:100] Creating Layer Eltwise2_ReLU5_0_split
I0218 21:03:21.309350 31980 net.cpp:444] Eltwise2_ReLU5_0_split <- Eltwise2
I0218 21:03:21.309355 31980 net.cpp:418] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I0218 21:03:21.309360 31980 net.cpp:418] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I0218 21:03:21.309391 31980 net.cpp:150] Setting up Eltwise2_ReLU5_0_split
I0218 21:03:21.309396 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.309406 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.309409 31980 net.cpp:165] Memory required for data: 95855200
I0218 21:03:21.309412 31980 layer_factory.hpp:77] Creating layer Convolution6
I0218 21:03:21.309419 31980 net.cpp:100] Creating Layer Convolution6
I0218 21:03:21.309423 31980 net.cpp:444] Convolution6 <- Eltwise2_ReLU5_0_split_0
I0218 21:03:21.309429 31980 net.cpp:418] Convolution6 -> Convolution6
I0218 21:03:21.310748 31980 net.cpp:150] Setting up Convolution6
I0218 21:03:21.310760 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.310763 31980 net.cpp:165] Memory required for data: 99240800
I0218 21:03:21.310770 31980 layer_factory.hpp:77] Creating layer BatchNorm6
I0218 21:03:21.310775 31980 net.cpp:100] Creating Layer BatchNorm6
I0218 21:03:21.310780 31980 net.cpp:444] BatchNorm6 <- Convolution6
I0218 21:03:21.310783 31980 net.cpp:405] BatchNorm6 -> Convolution6 (in-place)
I0218 21:03:21.310926 31980 net.cpp:150] Setting up BatchNorm6
I0218 21:03:21.310932 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.310935 31980 net.cpp:165] Memory required for data: 102626400
I0218 21:03:21.310940 31980 layer_factory.hpp:77] Creating layer Scale6
I0218 21:03:21.310946 31980 net.cpp:100] Creating Layer Scale6
I0218 21:03:21.310950 31980 net.cpp:444] Scale6 <- Convolution6
I0218 21:03:21.310953 31980 net.cpp:405] Scale6 -> Convolution6 (in-place)
I0218 21:03:21.310983 31980 layer_factory.hpp:77] Creating layer Scale6
I0218 21:03:21.311069 31980 net.cpp:150] Setting up Scale6
I0218 21:03:21.311076 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.311079 31980 net.cpp:165] Memory required for data: 106012000
I0218 21:03:21.311084 31980 layer_factory.hpp:77] Creating layer ReLU6
I0218 21:03:21.311089 31980 net.cpp:100] Creating Layer ReLU6
I0218 21:03:21.311091 31980 net.cpp:444] ReLU6 <- Convolution6
I0218 21:03:21.311095 31980 net.cpp:405] ReLU6 -> Convolution6 (in-place)
I0218 21:03:21.311594 31980 net.cpp:150] Setting up ReLU6
I0218 21:03:21.311607 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.311610 31980 net.cpp:165] Memory required for data: 109397600
I0218 21:03:21.311614 31980 layer_factory.hpp:77] Creating layer Convolution7
I0218 21:03:21.311622 31980 net.cpp:100] Creating Layer Convolution7
I0218 21:03:21.311625 31980 net.cpp:444] Convolution7 <- Convolution6
I0218 21:03:21.311631 31980 net.cpp:418] Convolution7 -> Convolution7
I0218 21:03:21.312603 31980 net.cpp:150] Setting up Convolution7
I0218 21:03:21.312618 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.312620 31980 net.cpp:165] Memory required for data: 112783200
I0218 21:03:21.312626 31980 layer_factory.hpp:77] Creating layer BatchNorm7
I0218 21:03:21.312631 31980 net.cpp:100] Creating Layer BatchNorm7
I0218 21:03:21.312634 31980 net.cpp:444] BatchNorm7 <- Convolution7
I0218 21:03:21.312639 31980 net.cpp:405] BatchNorm7 -> Convolution7 (in-place)
I0218 21:03:21.312788 31980 net.cpp:150] Setting up BatchNorm7
I0218 21:03:21.312793 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.312796 31980 net.cpp:165] Memory required for data: 116168800
I0218 21:03:21.312801 31980 layer_factory.hpp:77] Creating layer Scale7
I0218 21:03:21.312809 31980 net.cpp:100] Creating Layer Scale7
I0218 21:03:21.312813 31980 net.cpp:444] Scale7 <- Convolution7
I0218 21:03:21.312816 31980 net.cpp:405] Scale7 -> Convolution7 (in-place)
I0218 21:03:21.312847 31980 layer_factory.hpp:77] Creating layer Scale7
I0218 21:03:21.312938 31980 net.cpp:150] Setting up Scale7
I0218 21:03:21.312945 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.312948 31980 net.cpp:165] Memory required for data: 119554400
I0218 21:03:21.312952 31980 layer_factory.hpp:77] Creating layer Eltwise3
I0218 21:03:21.312958 31980 net.cpp:100] Creating Layer Eltwise3
I0218 21:03:21.312961 31980 net.cpp:444] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I0218 21:03:21.312964 31980 net.cpp:444] Eltwise3 <- Convolution7
I0218 21:03:21.312973 31980 net.cpp:418] Eltwise3 -> Eltwise3
I0218 21:03:21.312999 31980 net.cpp:150] Setting up Eltwise3
I0218 21:03:21.313004 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.313005 31980 net.cpp:165] Memory required for data: 122940000
I0218 21:03:21.313009 31980 layer_factory.hpp:77] Creating layer ReLU7
I0218 21:03:21.313014 31980 net.cpp:100] Creating Layer ReLU7
I0218 21:03:21.313017 31980 net.cpp:444] ReLU7 <- Eltwise3
I0218 21:03:21.313020 31980 net.cpp:405] ReLU7 -> Eltwise3 (in-place)
I0218 21:03:21.313519 31980 net.cpp:150] Setting up ReLU7
I0218 21:03:21.313531 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.313534 31980 net.cpp:165] Memory required for data: 126325600
I0218 21:03:21.313536 31980 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I0218 21:03:21.313542 31980 net.cpp:100] Creating Layer Eltwise3_ReLU7_0_split
I0218 21:03:21.313545 31980 net.cpp:444] Eltwise3_ReLU7_0_split <- Eltwise3
I0218 21:03:21.313551 31980 net.cpp:418] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I0218 21:03:21.313557 31980 net.cpp:418] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I0218 21:03:21.313591 31980 net.cpp:150] Setting up Eltwise3_ReLU7_0_split
I0218 21:03:21.313596 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.313599 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.313601 31980 net.cpp:165] Memory required for data: 133096800
I0218 21:03:21.313604 31980 layer_factory.hpp:77] Creating layer Convolution8
I0218 21:03:21.313613 31980 net.cpp:100] Creating Layer Convolution8
I0218 21:03:21.313616 31980 net.cpp:444] Convolution8 <- Eltwise3_ReLU7_0_split_0
I0218 21:03:21.313621 31980 net.cpp:418] Convolution8 -> Convolution8
I0218 21:03:21.314954 31980 net.cpp:150] Setting up Convolution8
I0218 21:03:21.314966 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.314970 31980 net.cpp:165] Memory required for data: 136482400
I0218 21:03:21.314975 31980 layer_factory.hpp:77] Creating layer BatchNorm8
I0218 21:03:21.314983 31980 net.cpp:100] Creating Layer BatchNorm8
I0218 21:03:21.314986 31980 net.cpp:444] BatchNorm8 <- Convolution8
I0218 21:03:21.314992 31980 net.cpp:405] BatchNorm8 -> Convolution8 (in-place)
I0218 21:03:21.315137 31980 net.cpp:150] Setting up BatchNorm8
I0218 21:03:21.315143 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.315146 31980 net.cpp:165] Memory required for data: 139868000
I0218 21:03:21.315152 31980 layer_factory.hpp:77] Creating layer Scale8
I0218 21:03:21.315156 31980 net.cpp:100] Creating Layer Scale8
I0218 21:03:21.315160 31980 net.cpp:444] Scale8 <- Convolution8
I0218 21:03:21.315163 31980 net.cpp:405] Scale8 -> Convolution8 (in-place)
I0218 21:03:21.315194 31980 layer_factory.hpp:77] Creating layer Scale8
I0218 21:03:21.315282 31980 net.cpp:150] Setting up Scale8
I0218 21:03:21.315289 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.315292 31980 net.cpp:165] Memory required for data: 143253600
I0218 21:03:21.315296 31980 layer_factory.hpp:77] Creating layer ReLU8
I0218 21:03:21.315300 31980 net.cpp:100] Creating Layer ReLU8
I0218 21:03:21.315304 31980 net.cpp:444] ReLU8 <- Convolution8
I0218 21:03:21.315307 31980 net.cpp:405] ReLU8 -> Convolution8 (in-place)
I0218 21:03:21.315807 31980 net.cpp:150] Setting up ReLU8
I0218 21:03:21.315819 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.315822 31980 net.cpp:165] Memory required for data: 146639200
I0218 21:03:21.315825 31980 layer_factory.hpp:77] Creating layer Convolution9
I0218 21:03:21.315834 31980 net.cpp:100] Creating Layer Convolution9
I0218 21:03:21.315838 31980 net.cpp:444] Convolution9 <- Convolution8
I0218 21:03:21.315845 31980 net.cpp:418] Convolution9 -> Convolution9
I0218 21:03:21.317179 31980 net.cpp:150] Setting up Convolution9
I0218 21:03:21.317193 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.317195 31980 net.cpp:165] Memory required for data: 150024800
I0218 21:03:21.317200 31980 layer_factory.hpp:77] Creating layer BatchNorm9
I0218 21:03:21.317210 31980 net.cpp:100] Creating Layer BatchNorm9
I0218 21:03:21.317219 31980 net.cpp:444] BatchNorm9 <- Convolution9
I0218 21:03:21.317225 31980 net.cpp:405] BatchNorm9 -> Convolution9 (in-place)
I0218 21:03:21.317374 31980 net.cpp:150] Setting up BatchNorm9
I0218 21:03:21.317380 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.317384 31980 net.cpp:165] Memory required for data: 153410400
I0218 21:03:21.317389 31980 layer_factory.hpp:77] Creating layer Scale9
I0218 21:03:21.317394 31980 net.cpp:100] Creating Layer Scale9
I0218 21:03:21.317396 31980 net.cpp:444] Scale9 <- Convolution9
I0218 21:03:21.317401 31980 net.cpp:405] Scale9 -> Convolution9 (in-place)
I0218 21:03:21.317430 31980 layer_factory.hpp:77] Creating layer Scale9
I0218 21:03:21.317517 31980 net.cpp:150] Setting up Scale9
I0218 21:03:21.317523 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.317526 31980 net.cpp:165] Memory required for data: 156796000
I0218 21:03:21.317530 31980 layer_factory.hpp:77] Creating layer Eltwise4
I0218 21:03:21.317535 31980 net.cpp:100] Creating Layer Eltwise4
I0218 21:03:21.317539 31980 net.cpp:444] Eltwise4 <- Eltwise3_ReLU7_0_split_1
I0218 21:03:21.317543 31980 net.cpp:444] Eltwise4 <- Convolution9
I0218 21:03:21.317548 31980 net.cpp:418] Eltwise4 -> Eltwise4
I0218 21:03:21.317567 31980 net.cpp:150] Setting up Eltwise4
I0218 21:03:21.317572 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.317575 31980 net.cpp:165] Memory required for data: 160181600
I0218 21:03:21.317577 31980 layer_factory.hpp:77] Creating layer ReLU9
I0218 21:03:21.317581 31980 net.cpp:100] Creating Layer ReLU9
I0218 21:03:21.317585 31980 net.cpp:444] ReLU9 <- Eltwise4
I0218 21:03:21.317589 31980 net.cpp:405] ReLU9 -> Eltwise4 (in-place)
I0218 21:03:21.318086 31980 net.cpp:150] Setting up ReLU9
I0218 21:03:21.318097 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.318101 31980 net.cpp:165] Memory required for data: 163567200
I0218 21:03:21.318104 31980 layer_factory.hpp:77] Creating layer Eltwise4_ReLU9_0_split
I0218 21:03:21.318109 31980 net.cpp:100] Creating Layer Eltwise4_ReLU9_0_split
I0218 21:03:21.318112 31980 net.cpp:444] Eltwise4_ReLU9_0_split <- Eltwise4
I0218 21:03:21.318118 31980 net.cpp:418] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_0
I0218 21:03:21.318125 31980 net.cpp:418] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_1
I0218 21:03:21.318158 31980 net.cpp:150] Setting up Eltwise4_ReLU9_0_split
I0218 21:03:21.318163 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.318167 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.318169 31980 net.cpp:165] Memory required for data: 170338400
I0218 21:03:21.318172 31980 layer_factory.hpp:77] Creating layer Convolution10
I0218 21:03:21.318179 31980 net.cpp:100] Creating Layer Convolution10
I0218 21:03:21.318183 31980 net.cpp:444] Convolution10 <- Eltwise4_ReLU9_0_split_0
I0218 21:03:21.318189 31980 net.cpp:418] Convolution10 -> Convolution10
I0218 21:03:21.319159 31980 net.cpp:150] Setting up Convolution10
I0218 21:03:21.319171 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.319175 31980 net.cpp:165] Memory required for data: 173724000
I0218 21:03:21.319188 31980 layer_factory.hpp:77] Creating layer BatchNorm10
I0218 21:03:21.319195 31980 net.cpp:100] Creating Layer BatchNorm10
I0218 21:03:21.319197 31980 net.cpp:444] BatchNorm10 <- Convolution10
I0218 21:03:21.319203 31980 net.cpp:405] BatchNorm10 -> Convolution10 (in-place)
I0218 21:03:21.319351 31980 net.cpp:150] Setting up BatchNorm10
I0218 21:03:21.319357 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.319360 31980 net.cpp:165] Memory required for data: 177109600
I0218 21:03:21.319366 31980 layer_factory.hpp:77] Creating layer Scale10
I0218 21:03:21.319372 31980 net.cpp:100] Creating Layer Scale10
I0218 21:03:21.319375 31980 net.cpp:444] Scale10 <- Convolution10
I0218 21:03:21.319378 31980 net.cpp:405] Scale10 -> Convolution10 (in-place)
I0218 21:03:21.319411 31980 layer_factory.hpp:77] Creating layer Scale10
I0218 21:03:21.319505 31980 net.cpp:150] Setting up Scale10
I0218 21:03:21.319517 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.319519 31980 net.cpp:165] Memory required for data: 180495200
I0218 21:03:21.319525 31980 layer_factory.hpp:77] Creating layer ReLU10
I0218 21:03:21.319533 31980 net.cpp:100] Creating Layer ReLU10
I0218 21:03:21.319537 31980 net.cpp:444] ReLU10 <- Convolution10
I0218 21:03:21.319542 31980 net.cpp:405] ReLU10 -> Convolution10 (in-place)
I0218 21:03:21.320044 31980 net.cpp:150] Setting up ReLU10
I0218 21:03:21.320055 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.320058 31980 net.cpp:165] Memory required for data: 183880800
I0218 21:03:21.320061 31980 layer_factory.hpp:77] Creating layer Convolution11
I0218 21:03:21.320070 31980 net.cpp:100] Creating Layer Convolution11
I0218 21:03:21.320073 31980 net.cpp:444] Convolution11 <- Convolution10
I0218 21:03:21.320080 31980 net.cpp:418] Convolution11 -> Convolution11
I0218 21:03:21.321782 31980 net.cpp:150] Setting up Convolution11
I0218 21:03:21.321795 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.321799 31980 net.cpp:165] Memory required for data: 187266400
I0218 21:03:21.321805 31980 layer_factory.hpp:77] Creating layer BatchNorm11
I0218 21:03:21.321810 31980 net.cpp:100] Creating Layer BatchNorm11
I0218 21:03:21.321813 31980 net.cpp:444] BatchNorm11 <- Convolution11
I0218 21:03:21.321818 31980 net.cpp:405] BatchNorm11 -> Convolution11 (in-place)
I0218 21:03:21.321969 31980 net.cpp:150] Setting up BatchNorm11
I0218 21:03:21.321974 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.321977 31980 net.cpp:165] Memory required for data: 190652000
I0218 21:03:21.321982 31980 layer_factory.hpp:77] Creating layer Scale11
I0218 21:03:21.321987 31980 net.cpp:100] Creating Layer Scale11
I0218 21:03:21.321990 31980 net.cpp:444] Scale11 <- Convolution11
I0218 21:03:21.321996 31980 net.cpp:405] Scale11 -> Convolution11 (in-place)
I0218 21:03:21.322027 31980 layer_factory.hpp:77] Creating layer Scale11
I0218 21:03:21.322118 31980 net.cpp:150] Setting up Scale11
I0218 21:03:21.322124 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.322127 31980 net.cpp:165] Memory required for data: 194037600
I0218 21:03:21.322132 31980 layer_factory.hpp:77] Creating layer Eltwise5
I0218 21:03:21.322140 31980 net.cpp:100] Creating Layer Eltwise5
I0218 21:03:21.322144 31980 net.cpp:444] Eltwise5 <- Eltwise4_ReLU9_0_split_1
I0218 21:03:21.322147 31980 net.cpp:444] Eltwise5 <- Convolution11
I0218 21:03:21.322151 31980 net.cpp:418] Eltwise5 -> Eltwise5
I0218 21:03:21.322172 31980 net.cpp:150] Setting up Eltwise5
I0218 21:03:21.322177 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.322180 31980 net.cpp:165] Memory required for data: 197423200
I0218 21:03:21.322183 31980 layer_factory.hpp:77] Creating layer ReLU11
I0218 21:03:21.322187 31980 net.cpp:100] Creating Layer ReLU11
I0218 21:03:21.322190 31980 net.cpp:444] ReLU11 <- Eltwise5
I0218 21:03:21.322194 31980 net.cpp:405] ReLU11 -> Eltwise5 (in-place)
I0218 21:03:21.322330 31980 net.cpp:150] Setting up ReLU11
I0218 21:03:21.322338 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.322341 31980 net.cpp:165] Memory required for data: 200808800
I0218 21:03:21.322345 31980 layer_factory.hpp:77] Creating layer Eltwise5_ReLU11_0_split
I0218 21:03:21.322351 31980 net.cpp:100] Creating Layer Eltwise5_ReLU11_0_split
I0218 21:03:21.322355 31980 net.cpp:444] Eltwise5_ReLU11_0_split <- Eltwise5
I0218 21:03:21.322358 31980 net.cpp:418] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_0
I0218 21:03:21.322365 31980 net.cpp:418] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_1
I0218 21:03:21.322371 31980 net.cpp:418] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_2
I0218 21:03:21.322412 31980 net.cpp:150] Setting up Eltwise5_ReLU11_0_split
I0218 21:03:21.322417 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.322420 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.322427 31980 net.cpp:157] Top shape: 100 16 23 23 (846400)
I0218 21:03:21.322435 31980 net.cpp:165] Memory required for data: 210965600
I0218 21:03:21.322438 31980 layer_factory.hpp:77] Creating layer Convolution18
I0218 21:03:21.322448 31980 net.cpp:100] Creating Layer Convolution18
I0218 21:03:21.322450 31980 net.cpp:444] Convolution18 <- Eltwise5_ReLU11_0_split_0
I0218 21:03:21.322455 31980 net.cpp:418] Convolution18 -> Convolution18
I0218 21:03:21.324162 31980 net.cpp:150] Setting up Convolution18
I0218 21:03:21.324175 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.324178 31980 net.cpp:165] Memory required for data: 212808800
I0218 21:03:21.324183 31980 layer_factory.hpp:77] Creating layer BatchNorm18
I0218 21:03:21.324190 31980 net.cpp:100] Creating Layer BatchNorm18
I0218 21:03:21.324194 31980 net.cpp:444] BatchNorm18 <- Convolution18
I0218 21:03:21.324199 31980 net.cpp:405] BatchNorm18 -> Convolution18 (in-place)
I0218 21:03:21.324348 31980 net.cpp:150] Setting up BatchNorm18
I0218 21:03:21.324354 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.324357 31980 net.cpp:165] Memory required for data: 214652000
I0218 21:03:21.324363 31980 layer_factory.hpp:77] Creating layer Scale18
I0218 21:03:21.324369 31980 net.cpp:100] Creating Layer Scale18
I0218 21:03:21.324373 31980 net.cpp:444] Scale18 <- Convolution18
I0218 21:03:21.324376 31980 net.cpp:405] Scale18 -> Convolution18 (in-place)
I0218 21:03:21.324407 31980 layer_factory.hpp:77] Creating layer Scale18
I0218 21:03:21.324496 31980 net.cpp:150] Setting up Scale18
I0218 21:03:21.324501 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.324504 31980 net.cpp:165] Memory required for data: 216495200
I0218 21:03:21.324509 31980 layer_factory.hpp:77] Creating layer Convolution19
I0218 21:03:21.324517 31980 net.cpp:100] Creating Layer Convolution19
I0218 21:03:21.324520 31980 net.cpp:444] Convolution19 <- Eltwise5_ReLU11_0_split_1
I0218 21:03:21.324527 31980 net.cpp:418] Convolution19 -> Convolution19
I0218 21:03:21.326206 31980 net.cpp:150] Setting up Convolution19
I0218 21:03:21.326220 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.326222 31980 net.cpp:165] Memory required for data: 218338400
I0218 21:03:21.326228 31980 layer_factory.hpp:77] Creating layer BatchNorm19
I0218 21:03:21.326234 31980 net.cpp:100] Creating Layer BatchNorm19
I0218 21:03:21.326237 31980 net.cpp:444] BatchNorm19 <- Convolution19
I0218 21:03:21.326243 31980 net.cpp:405] BatchNorm19 -> Convolution19 (in-place)
I0218 21:03:21.326391 31980 net.cpp:150] Setting up BatchNorm19
I0218 21:03:21.326398 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.326400 31980 net.cpp:165] Memory required for data: 220181600
I0218 21:03:21.326406 31980 layer_factory.hpp:77] Creating layer Scale19
I0218 21:03:21.326411 31980 net.cpp:100] Creating Layer Scale19
I0218 21:03:21.326414 31980 net.cpp:444] Scale19 <- Convolution19
I0218 21:03:21.326418 31980 net.cpp:405] Scale19 -> Convolution19 (in-place)
I0218 21:03:21.326449 31980 layer_factory.hpp:77] Creating layer Scale19
I0218 21:03:21.326535 31980 net.cpp:150] Setting up Scale19
I0218 21:03:21.326541 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.326545 31980 net.cpp:165] Memory required for data: 222024800
I0218 21:03:21.326548 31980 layer_factory.hpp:77] Creating layer ReLU18
I0218 21:03:21.326555 31980 net.cpp:100] Creating Layer ReLU18
I0218 21:03:21.326557 31980 net.cpp:444] ReLU18 <- Convolution19
I0218 21:03:21.326561 31980 net.cpp:405] ReLU18 -> Convolution19 (in-place)
I0218 21:03:21.326697 31980 net.cpp:150] Setting up ReLU18
I0218 21:03:21.326705 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.326709 31980 net.cpp:165] Memory required for data: 223868000
I0218 21:03:21.326710 31980 layer_factory.hpp:77] Creating layer Convolution20
I0218 21:03:21.326719 31980 net.cpp:100] Creating Layer Convolution20
I0218 21:03:21.326723 31980 net.cpp:444] Convolution20 <- Convolution19
I0218 21:03:21.326728 31980 net.cpp:418] Convolution20 -> Convolution20
I0218 21:03:21.328202 31980 net.cpp:150] Setting up Convolution20
I0218 21:03:21.328224 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.328228 31980 net.cpp:165] Memory required for data: 225711200
I0218 21:03:21.328233 31980 layer_factory.hpp:77] Creating layer BatchNorm20
I0218 21:03:21.328243 31980 net.cpp:100] Creating Layer BatchNorm20
I0218 21:03:21.328248 31980 net.cpp:444] BatchNorm20 <- Convolution20
I0218 21:03:21.328253 31980 net.cpp:405] BatchNorm20 -> Convolution20 (in-place)
I0218 21:03:21.328405 31980 net.cpp:150] Setting up BatchNorm20
I0218 21:03:21.328413 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.328414 31980 net.cpp:165] Memory required for data: 227554400
I0218 21:03:21.328421 31980 layer_factory.hpp:77] Creating layer Scale20
I0218 21:03:21.328428 31980 net.cpp:100] Creating Layer Scale20
I0218 21:03:21.328430 31980 net.cpp:444] Scale20 <- Convolution20
I0218 21:03:21.328434 31980 net.cpp:405] Scale20 -> Convolution20 (in-place)
I0218 21:03:21.328469 31980 layer_factory.hpp:77] Creating layer Scale20
I0218 21:03:21.328559 31980 net.cpp:150] Setting up Scale20
I0218 21:03:21.328567 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.328568 31980 net.cpp:165] Memory required for data: 229397600
I0218 21:03:21.328573 31980 layer_factory.hpp:77] Creating layer Eltwise9
I0218 21:03:21.328579 31980 net.cpp:100] Creating Layer Eltwise9
I0218 21:03:21.328583 31980 net.cpp:444] Eltwise9 <- Convolution18
I0218 21:03:21.328585 31980 net.cpp:444] Eltwise9 <- Convolution20
I0218 21:03:21.328590 31980 net.cpp:418] Eltwise9 -> Eltwise9
I0218 21:03:21.328611 31980 net.cpp:150] Setting up Eltwise9
I0218 21:03:21.328616 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.328619 31980 net.cpp:165] Memory required for data: 231240800
I0218 21:03:21.328622 31980 layer_factory.hpp:77] Creating layer ReLU19
I0218 21:03:21.328626 31980 net.cpp:100] Creating Layer ReLU19
I0218 21:03:21.328629 31980 net.cpp:444] ReLU19 <- Eltwise9
I0218 21:03:21.328634 31980 net.cpp:405] ReLU19 -> Eltwise9 (in-place)
I0218 21:03:21.329139 31980 net.cpp:150] Setting up ReLU19
I0218 21:03:21.329150 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.329154 31980 net.cpp:165] Memory required for data: 233084000
I0218 21:03:21.329156 31980 layer_factory.hpp:77] Creating layer Eltwise9_ReLU19_0_split
I0218 21:03:21.329162 31980 net.cpp:100] Creating Layer Eltwise9_ReLU19_0_split
I0218 21:03:21.329165 31980 net.cpp:444] Eltwise9_ReLU19_0_split <- Eltwise9
I0218 21:03:21.329171 31980 net.cpp:418] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_0
I0218 21:03:21.329177 31980 net.cpp:418] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_1
I0218 21:03:21.329213 31980 net.cpp:150] Setting up Eltwise9_ReLU19_0_split
I0218 21:03:21.329219 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.329222 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.329224 31980 net.cpp:165] Memory required for data: 236770400
I0218 21:03:21.329227 31980 layer_factory.hpp:77] Creating layer Convolution21
I0218 21:03:21.329236 31980 net.cpp:100] Creating Layer Convolution21
I0218 21:03:21.329239 31980 net.cpp:444] Convolution21 <- Eltwise9_ReLU19_0_split_0
I0218 21:03:21.329244 31980 net.cpp:418] Convolution21 -> Convolution21
I0218 21:03:21.330293 31980 net.cpp:150] Setting up Convolution21
I0218 21:03:21.330307 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.330309 31980 net.cpp:165] Memory required for data: 238613600
I0218 21:03:21.330314 31980 layer_factory.hpp:77] Creating layer BatchNorm21
I0218 21:03:21.330322 31980 net.cpp:100] Creating Layer BatchNorm21
I0218 21:03:21.330324 31980 net.cpp:444] BatchNorm21 <- Convolution21
I0218 21:03:21.330328 31980 net.cpp:405] BatchNorm21 -> Convolution21 (in-place)
I0218 21:03:21.330480 31980 net.cpp:150] Setting up BatchNorm21
I0218 21:03:21.330487 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.330490 31980 net.cpp:165] Memory required for data: 240456800
I0218 21:03:21.330499 31980 layer_factory.hpp:77] Creating layer Scale21
I0218 21:03:21.330508 31980 net.cpp:100] Creating Layer Scale21
I0218 21:03:21.330513 31980 net.cpp:444] Scale21 <- Convolution21
I0218 21:03:21.330515 31980 net.cpp:405] Scale21 -> Convolution21 (in-place)
I0218 21:03:21.330551 31980 layer_factory.hpp:77] Creating layer Scale21
I0218 21:03:21.330642 31980 net.cpp:150] Setting up Scale21
I0218 21:03:21.330649 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.330651 31980 net.cpp:165] Memory required for data: 242300000
I0218 21:03:21.330657 31980 layer_factory.hpp:77] Creating layer ReLU20
I0218 21:03:21.330662 31980 net.cpp:100] Creating Layer ReLU20
I0218 21:03:21.330665 31980 net.cpp:444] ReLU20 <- Convolution21
I0218 21:03:21.330668 31980 net.cpp:405] ReLU20 -> Convolution21 (in-place)
I0218 21:03:21.331168 31980 net.cpp:150] Setting up ReLU20
I0218 21:03:21.331180 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.331183 31980 net.cpp:165] Memory required for data: 244143200
I0218 21:03:21.331187 31980 layer_factory.hpp:77] Creating layer Convolution22
I0218 21:03:21.331197 31980 net.cpp:100] Creating Layer Convolution22
I0218 21:03:21.331200 31980 net.cpp:444] Convolution22 <- Convolution21
I0218 21:03:21.331205 31980 net.cpp:418] Convolution22 -> Convolution22
I0218 21:03:21.332649 31980 net.cpp:150] Setting up Convolution22
I0218 21:03:21.332662 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.332665 31980 net.cpp:165] Memory required for data: 245986400
I0218 21:03:21.332672 31980 layer_factory.hpp:77] Creating layer BatchNorm22
I0218 21:03:21.332679 31980 net.cpp:100] Creating Layer BatchNorm22
I0218 21:03:21.332681 31980 net.cpp:444] BatchNorm22 <- Convolution22
I0218 21:03:21.332687 31980 net.cpp:405] BatchNorm22 -> Convolution22 (in-place)
I0218 21:03:21.332842 31980 net.cpp:150] Setting up BatchNorm22
I0218 21:03:21.332849 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.332851 31980 net.cpp:165] Memory required for data: 247829600
I0218 21:03:21.332856 31980 layer_factory.hpp:77] Creating layer Scale22
I0218 21:03:21.332861 31980 net.cpp:100] Creating Layer Scale22
I0218 21:03:21.332864 31980 net.cpp:444] Scale22 <- Convolution22
I0218 21:03:21.332868 31980 net.cpp:405] Scale22 -> Convolution22 (in-place)
I0218 21:03:21.332901 31980 layer_factory.hpp:77] Creating layer Scale22
I0218 21:03:21.332991 31980 net.cpp:150] Setting up Scale22
I0218 21:03:21.332998 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.333000 31980 net.cpp:165] Memory required for data: 249672800
I0218 21:03:21.333004 31980 layer_factory.hpp:77] Creating layer Eltwise10
I0218 21:03:21.333010 31980 net.cpp:100] Creating Layer Eltwise10
I0218 21:03:21.333014 31980 net.cpp:444] Eltwise10 <- Eltwise9_ReLU19_0_split_1
I0218 21:03:21.333016 31980 net.cpp:444] Eltwise10 <- Convolution22
I0218 21:03:21.333021 31980 net.cpp:418] Eltwise10 -> Eltwise10
I0218 21:03:21.333042 31980 net.cpp:150] Setting up Eltwise10
I0218 21:03:21.333050 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.333052 31980 net.cpp:165] Memory required for data: 251516000
I0218 21:03:21.333055 31980 layer_factory.hpp:77] Creating layer ReLU21
I0218 21:03:21.333060 31980 net.cpp:100] Creating Layer ReLU21
I0218 21:03:21.333061 31980 net.cpp:444] ReLU21 <- Eltwise10
I0218 21:03:21.333065 31980 net.cpp:405] ReLU21 -> Eltwise10 (in-place)
I0218 21:03:21.333200 31980 net.cpp:150] Setting up ReLU21
I0218 21:03:21.333211 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.333214 31980 net.cpp:165] Memory required for data: 253359200
I0218 21:03:21.333216 31980 layer_factory.hpp:77] Creating layer Eltwise10_ReLU21_0_split
I0218 21:03:21.333221 31980 net.cpp:100] Creating Layer Eltwise10_ReLU21_0_split
I0218 21:03:21.333225 31980 net.cpp:444] Eltwise10_ReLU21_0_split <- Eltwise10
I0218 21:03:21.333230 31980 net.cpp:418] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_0
I0218 21:03:21.333235 31980 net.cpp:418] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_1
I0218 21:03:21.333278 31980 net.cpp:150] Setting up Eltwise10_ReLU21_0_split
I0218 21:03:21.333284 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.333287 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.333289 31980 net.cpp:165] Memory required for data: 257045600
I0218 21:03:21.333292 31980 layer_factory.hpp:77] Creating layer Convolution23
I0218 21:03:21.333302 31980 net.cpp:100] Creating Layer Convolution23
I0218 21:03:21.333305 31980 net.cpp:444] Convolution23 <- Eltwise10_ReLU21_0_split_0
I0218 21:03:21.333310 31980 net.cpp:418] Convolution23 -> Convolution23
I0218 21:03:21.335091 31980 net.cpp:150] Setting up Convolution23
I0218 21:03:21.335105 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.335108 31980 net.cpp:165] Memory required for data: 258888800
I0218 21:03:21.335114 31980 layer_factory.hpp:77] Creating layer BatchNorm23
I0218 21:03:21.335120 31980 net.cpp:100] Creating Layer BatchNorm23
I0218 21:03:21.335124 31980 net.cpp:444] BatchNorm23 <- Convolution23
I0218 21:03:21.335129 31980 net.cpp:405] BatchNorm23 -> Convolution23 (in-place)
I0218 21:03:21.335284 31980 net.cpp:150] Setting up BatchNorm23
I0218 21:03:21.335290 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.335294 31980 net.cpp:165] Memory required for data: 260732000
I0218 21:03:21.335299 31980 layer_factory.hpp:77] Creating layer Scale23
I0218 21:03:21.335304 31980 net.cpp:100] Creating Layer Scale23
I0218 21:03:21.335307 31980 net.cpp:444] Scale23 <- Convolution23
I0218 21:03:21.335311 31980 net.cpp:405] Scale23 -> Convolution23 (in-place)
I0218 21:03:21.335343 31980 layer_factory.hpp:77] Creating layer Scale23
I0218 21:03:21.335436 31980 net.cpp:150] Setting up Scale23
I0218 21:03:21.335443 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.335445 31980 net.cpp:165] Memory required for data: 262575200
I0218 21:03:21.335450 31980 layer_factory.hpp:77] Creating layer ReLU22
I0218 21:03:21.335455 31980 net.cpp:100] Creating Layer ReLU22
I0218 21:03:21.335458 31980 net.cpp:444] ReLU22 <- Convolution23
I0218 21:03:21.335463 31980 net.cpp:405] ReLU22 -> Convolution23 (in-place)
I0218 21:03:21.335974 31980 net.cpp:150] Setting up ReLU22
I0218 21:03:21.335988 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.335990 31980 net.cpp:165] Memory required for data: 264418400
I0218 21:03:21.335994 31980 layer_factory.hpp:77] Creating layer Convolution24
I0218 21:03:21.336002 31980 net.cpp:100] Creating Layer Convolution24
I0218 21:03:21.336006 31980 net.cpp:444] Convolution24 <- Convolution23
I0218 21:03:21.336012 31980 net.cpp:418] Convolution24 -> Convolution24
I0218 21:03:21.337429 31980 net.cpp:150] Setting up Convolution24
I0218 21:03:21.337441 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.337445 31980 net.cpp:165] Memory required for data: 266261600
I0218 21:03:21.337450 31980 layer_factory.hpp:77] Creating layer BatchNorm24
I0218 21:03:21.337456 31980 net.cpp:100] Creating Layer BatchNorm24
I0218 21:03:21.337460 31980 net.cpp:444] BatchNorm24 <- Convolution24
I0218 21:03:21.337465 31980 net.cpp:405] BatchNorm24 -> Convolution24 (in-place)
I0218 21:03:21.337625 31980 net.cpp:150] Setting up BatchNorm24
I0218 21:03:21.337631 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.337635 31980 net.cpp:165] Memory required for data: 268104800
I0218 21:03:21.337640 31980 layer_factory.hpp:77] Creating layer Scale24
I0218 21:03:21.337644 31980 net.cpp:100] Creating Layer Scale24
I0218 21:03:21.337647 31980 net.cpp:444] Scale24 <- Convolution24
I0218 21:03:21.337651 31980 net.cpp:405] Scale24 -> Convolution24 (in-place)
I0218 21:03:21.337683 31980 layer_factory.hpp:77] Creating layer Scale24
I0218 21:03:21.337775 31980 net.cpp:150] Setting up Scale24
I0218 21:03:21.337782 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.337785 31980 net.cpp:165] Memory required for data: 269948000
I0218 21:03:21.337790 31980 layer_factory.hpp:77] Creating layer Eltwise11
I0218 21:03:21.337800 31980 net.cpp:100] Creating Layer Eltwise11
I0218 21:03:21.337808 31980 net.cpp:444] Eltwise11 <- Eltwise10_ReLU21_0_split_1
I0218 21:03:21.337812 31980 net.cpp:444] Eltwise11 <- Convolution24
I0218 21:03:21.337816 31980 net.cpp:418] Eltwise11 -> Eltwise11
I0218 21:03:21.337839 31980 net.cpp:150] Setting up Eltwise11
I0218 21:03:21.337846 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.337847 31980 net.cpp:165] Memory required for data: 271791200
I0218 21:03:21.337851 31980 layer_factory.hpp:77] Creating layer ReLU23
I0218 21:03:21.337854 31980 net.cpp:100] Creating Layer ReLU23
I0218 21:03:21.337857 31980 net.cpp:444] ReLU23 <- Eltwise11
I0218 21:03:21.337862 31980 net.cpp:405] ReLU23 -> Eltwise11 (in-place)
I0218 21:03:21.338363 31980 net.cpp:150] Setting up ReLU23
I0218 21:03:21.338374 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.338377 31980 net.cpp:165] Memory required for data: 273634400
I0218 21:03:21.338380 31980 layer_factory.hpp:77] Creating layer Eltwise11_ReLU23_0_split
I0218 21:03:21.338385 31980 net.cpp:100] Creating Layer Eltwise11_ReLU23_0_split
I0218 21:03:21.338388 31980 net.cpp:444] Eltwise11_ReLU23_0_split <- Eltwise11
I0218 21:03:21.338394 31980 net.cpp:418] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_0
I0218 21:03:21.338402 31980 net.cpp:418] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_1
I0218 21:03:21.338438 31980 net.cpp:150] Setting up Eltwise11_ReLU23_0_split
I0218 21:03:21.338443 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.338448 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.338449 31980 net.cpp:165] Memory required for data: 277320800
I0218 21:03:21.338452 31980 layer_factory.hpp:77] Creating layer Convolution25
I0218 21:03:21.338460 31980 net.cpp:100] Creating Layer Convolution25
I0218 21:03:21.338464 31980 net.cpp:444] Convolution25 <- Eltwise11_ReLU23_0_split_0
I0218 21:03:21.338469 31980 net.cpp:418] Convolution25 -> Convolution25
I0218 21:03:21.339891 31980 net.cpp:150] Setting up Convolution25
I0218 21:03:21.339905 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.339908 31980 net.cpp:165] Memory required for data: 279164000
I0218 21:03:21.339915 31980 layer_factory.hpp:77] Creating layer BatchNorm25
I0218 21:03:21.339920 31980 net.cpp:100] Creating Layer BatchNorm25
I0218 21:03:21.339922 31980 net.cpp:444] BatchNorm25 <- Convolution25
I0218 21:03:21.339928 31980 net.cpp:405] BatchNorm25 -> Convolution25 (in-place)
I0218 21:03:21.340086 31980 net.cpp:150] Setting up BatchNorm25
I0218 21:03:21.340093 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.340095 31980 net.cpp:165] Memory required for data: 281007200
I0218 21:03:21.340108 31980 layer_factory.hpp:77] Creating layer Scale25
I0218 21:03:21.340114 31980 net.cpp:100] Creating Layer Scale25
I0218 21:03:21.340117 31980 net.cpp:444] Scale25 <- Convolution25
I0218 21:03:21.340121 31980 net.cpp:405] Scale25 -> Convolution25 (in-place)
I0218 21:03:21.340157 31980 layer_factory.hpp:77] Creating layer Scale25
I0218 21:03:21.340250 31980 net.cpp:150] Setting up Scale25
I0218 21:03:21.340256 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.340258 31980 net.cpp:165] Memory required for data: 282850400
I0218 21:03:21.340263 31980 layer_factory.hpp:77] Creating layer ReLU24
I0218 21:03:21.340270 31980 net.cpp:100] Creating Layer ReLU24
I0218 21:03:21.340272 31980 net.cpp:444] ReLU24 <- Convolution25
I0218 21:03:21.340276 31980 net.cpp:405] ReLU24 -> Convolution25 (in-place)
I0218 21:03:21.340415 31980 net.cpp:150] Setting up ReLU24
I0218 21:03:21.340423 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.340426 31980 net.cpp:165] Memory required for data: 284693600
I0218 21:03:21.340428 31980 layer_factory.hpp:77] Creating layer Convolution26
I0218 21:03:21.340437 31980 net.cpp:100] Creating Layer Convolution26
I0218 21:03:21.340440 31980 net.cpp:444] Convolution26 <- Convolution25
I0218 21:03:21.340445 31980 net.cpp:418] Convolution26 -> Convolution26
I0218 21:03:21.341873 31980 net.cpp:150] Setting up Convolution26
I0218 21:03:21.341893 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.341897 31980 net.cpp:165] Memory required for data: 286536800
I0218 21:03:21.341902 31980 layer_factory.hpp:77] Creating layer BatchNorm26
I0218 21:03:21.341908 31980 net.cpp:100] Creating Layer BatchNorm26
I0218 21:03:21.341912 31980 net.cpp:444] BatchNorm26 <- Convolution26
I0218 21:03:21.341917 31980 net.cpp:405] BatchNorm26 -> Convolution26 (in-place)
I0218 21:03:21.342077 31980 net.cpp:150] Setting up BatchNorm26
I0218 21:03:21.342083 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.342087 31980 net.cpp:165] Memory required for data: 288380000
I0218 21:03:21.342092 31980 layer_factory.hpp:77] Creating layer Scale26
I0218 21:03:21.342098 31980 net.cpp:100] Creating Layer Scale26
I0218 21:03:21.342103 31980 net.cpp:444] Scale26 <- Convolution26
I0218 21:03:21.342106 31980 net.cpp:405] Scale26 -> Convolution26 (in-place)
I0218 21:03:21.342140 31980 layer_factory.hpp:77] Creating layer Scale26
I0218 21:03:21.342234 31980 net.cpp:150] Setting up Scale26
I0218 21:03:21.342242 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.342244 31980 net.cpp:165] Memory required for data: 290223200
I0218 21:03:21.342249 31980 layer_factory.hpp:77] Creating layer Eltwise12
I0218 21:03:21.342255 31980 net.cpp:100] Creating Layer Eltwise12
I0218 21:03:21.342259 31980 net.cpp:444] Eltwise12 <- Eltwise11_ReLU23_0_split_1
I0218 21:03:21.342263 31980 net.cpp:444] Eltwise12 <- Convolution26
I0218 21:03:21.342268 31980 net.cpp:418] Eltwise12 -> Eltwise12
I0218 21:03:21.342289 31980 net.cpp:150] Setting up Eltwise12
I0218 21:03:21.342294 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.342298 31980 net.cpp:165] Memory required for data: 292066400
I0218 21:03:21.342300 31980 layer_factory.hpp:77] Creating layer ReLU25
I0218 21:03:21.342305 31980 net.cpp:100] Creating Layer ReLU25
I0218 21:03:21.342308 31980 net.cpp:444] ReLU25 <- Eltwise12
I0218 21:03:21.342312 31980 net.cpp:405] ReLU25 -> Eltwise12 (in-place)
I0218 21:03:21.342819 31980 net.cpp:150] Setting up ReLU25
I0218 21:03:21.342830 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.342833 31980 net.cpp:165] Memory required for data: 293909600
I0218 21:03:21.342836 31980 layer_factory.hpp:77] Creating layer Eltwise12_ReLU25_0_split
I0218 21:03:21.342844 31980 net.cpp:100] Creating Layer Eltwise12_ReLU25_0_split
I0218 21:03:21.342846 31980 net.cpp:444] Eltwise12_ReLU25_0_split <- Eltwise12
I0218 21:03:21.342851 31980 net.cpp:418] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_0
I0218 21:03:21.342859 31980 net.cpp:418] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_1
I0218 21:03:21.342895 31980 net.cpp:150] Setting up Eltwise12_ReLU25_0_split
I0218 21:03:21.342901 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.342905 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.342907 31980 net.cpp:165] Memory required for data: 297596000
I0218 21:03:21.342909 31980 layer_factory.hpp:77] Creating layer Convolution27
I0218 21:03:21.342919 31980 net.cpp:100] Creating Layer Convolution27
I0218 21:03:21.342922 31980 net.cpp:444] Convolution27 <- Eltwise12_ReLU25_0_split_0
I0218 21:03:21.342928 31980 net.cpp:418] Convolution27 -> Convolution27
I0218 21:03:21.343994 31980 net.cpp:150] Setting up Convolution27
I0218 21:03:21.344007 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.344009 31980 net.cpp:165] Memory required for data: 299439200
I0218 21:03:21.344017 31980 layer_factory.hpp:77] Creating layer BatchNorm27
I0218 21:03:21.344022 31980 net.cpp:100] Creating Layer BatchNorm27
I0218 21:03:21.344027 31980 net.cpp:444] BatchNorm27 <- Convolution27
I0218 21:03:21.344031 31980 net.cpp:405] BatchNorm27 -> Convolution27 (in-place)
I0218 21:03:21.344192 31980 net.cpp:150] Setting up BatchNorm27
I0218 21:03:21.344197 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.344199 31980 net.cpp:165] Memory required for data: 301282400
I0218 21:03:21.344209 31980 layer_factory.hpp:77] Creating layer Scale27
I0218 21:03:21.344220 31980 net.cpp:100] Creating Layer Scale27
I0218 21:03:21.344223 31980 net.cpp:444] Scale27 <- Convolution27
I0218 21:03:21.344228 31980 net.cpp:405] Scale27 -> Convolution27 (in-place)
I0218 21:03:21.344261 31980 layer_factory.hpp:77] Creating layer Scale27
I0218 21:03:21.344357 31980 net.cpp:150] Setting up Scale27
I0218 21:03:21.344363 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.344365 31980 net.cpp:165] Memory required for data: 303125600
I0218 21:03:21.344370 31980 layer_factory.hpp:77] Creating layer ReLU26
I0218 21:03:21.344374 31980 net.cpp:100] Creating Layer ReLU26
I0218 21:03:21.344377 31980 net.cpp:444] ReLU26 <- Convolution27
I0218 21:03:21.344383 31980 net.cpp:405] ReLU26 -> Convolution27 (in-place)
I0218 21:03:21.344885 31980 net.cpp:150] Setting up ReLU26
I0218 21:03:21.344897 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.344899 31980 net.cpp:165] Memory required for data: 304968800
I0218 21:03:21.344902 31980 layer_factory.hpp:77] Creating layer Convolution28
I0218 21:03:21.344911 31980 net.cpp:100] Creating Layer Convolution28
I0218 21:03:21.344915 31980 net.cpp:444] Convolution28 <- Convolution27
I0218 21:03:21.344921 31980 net.cpp:418] Convolution28 -> Convolution28
I0218 21:03:21.346352 31980 net.cpp:150] Setting up Convolution28
I0218 21:03:21.346365 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.346369 31980 net.cpp:165] Memory required for data: 306812000
I0218 21:03:21.346374 31980 layer_factory.hpp:77] Creating layer BatchNorm28
I0218 21:03:21.346380 31980 net.cpp:100] Creating Layer BatchNorm28
I0218 21:03:21.346384 31980 net.cpp:444] BatchNorm28 <- Convolution28
I0218 21:03:21.346388 31980 net.cpp:405] BatchNorm28 -> Convolution28 (in-place)
I0218 21:03:21.346549 31980 net.cpp:150] Setting up BatchNorm28
I0218 21:03:21.346554 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.346556 31980 net.cpp:165] Memory required for data: 308655200
I0218 21:03:21.346562 31980 layer_factory.hpp:77] Creating layer Scale28
I0218 21:03:21.346567 31980 net.cpp:100] Creating Layer Scale28
I0218 21:03:21.346570 31980 net.cpp:444] Scale28 <- Convolution28
I0218 21:03:21.346573 31980 net.cpp:405] Scale28 -> Convolution28 (in-place)
I0218 21:03:21.346608 31980 layer_factory.hpp:77] Creating layer Scale28
I0218 21:03:21.346702 31980 net.cpp:150] Setting up Scale28
I0218 21:03:21.346709 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.346710 31980 net.cpp:165] Memory required for data: 310498400
I0218 21:03:21.346715 31980 layer_factory.hpp:77] Creating layer Eltwise13
I0218 21:03:21.346721 31980 net.cpp:100] Creating Layer Eltwise13
I0218 21:03:21.346724 31980 net.cpp:444] Eltwise13 <- Eltwise12_ReLU25_0_split_1
I0218 21:03:21.346729 31980 net.cpp:444] Eltwise13 <- Convolution28
I0218 21:03:21.346732 31980 net.cpp:418] Eltwise13 -> Eltwise13
I0218 21:03:21.346755 31980 net.cpp:150] Setting up Eltwise13
I0218 21:03:21.346760 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.346761 31980 net.cpp:165] Memory required for data: 312341600
I0218 21:03:21.346765 31980 layer_factory.hpp:77] Creating layer ReLU27
I0218 21:03:21.346770 31980 net.cpp:100] Creating Layer ReLU27
I0218 21:03:21.346772 31980 net.cpp:444] ReLU27 <- Eltwise13
I0218 21:03:21.346776 31980 net.cpp:405] ReLU27 -> Eltwise13 (in-place)
I0218 21:03:21.346915 31980 net.cpp:150] Setting up ReLU27
I0218 21:03:21.346923 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.346926 31980 net.cpp:165] Memory required for data: 314184800
I0218 21:03:21.346930 31980 layer_factory.hpp:77] Creating layer Eltwise13_ReLU27_0_split
I0218 21:03:21.346935 31980 net.cpp:100] Creating Layer Eltwise13_ReLU27_0_split
I0218 21:03:21.346938 31980 net.cpp:444] Eltwise13_ReLU27_0_split <- Eltwise13
I0218 21:03:21.346942 31980 net.cpp:418] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_0
I0218 21:03:21.346948 31980 net.cpp:418] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_1
I0218 21:03:21.346958 31980 net.cpp:418] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_2
I0218 21:03:21.347009 31980 net.cpp:150] Setting up Eltwise13_ReLU27_0_split
I0218 21:03:21.347015 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.347018 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.347023 31980 net.cpp:157] Top shape: 100 32 12 12 (460800)
I0218 21:03:21.347024 31980 net.cpp:165] Memory required for data: 319714400
I0218 21:03:21.347028 31980 layer_factory.hpp:77] Creating layer Convolution35
I0218 21:03:21.347036 31980 net.cpp:100] Creating Layer Convolution35
I0218 21:03:21.347040 31980 net.cpp:444] Convolution35 <- Eltwise13_ReLU27_0_split_0
I0218 21:03:21.347045 31980 net.cpp:418] Convolution35 -> Convolution35
I0218 21:03:21.348424 31980 net.cpp:150] Setting up Convolution35
I0218 21:03:21.348438 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.348440 31980 net.cpp:165] Memory required for data: 320636000
I0218 21:03:21.348446 31980 layer_factory.hpp:77] Creating layer BatchNorm35
I0218 21:03:21.348453 31980 net.cpp:100] Creating Layer BatchNorm35
I0218 21:03:21.348456 31980 net.cpp:444] BatchNorm35 <- Convolution35
I0218 21:03:21.348461 31980 net.cpp:405] BatchNorm35 -> Convolution35 (in-place)
I0218 21:03:21.348621 31980 net.cpp:150] Setting up BatchNorm35
I0218 21:03:21.348628 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.348631 31980 net.cpp:165] Memory required for data: 321557600
I0218 21:03:21.348637 31980 layer_factory.hpp:77] Creating layer Scale35
I0218 21:03:21.348642 31980 net.cpp:100] Creating Layer Scale35
I0218 21:03:21.348645 31980 net.cpp:444] Scale35 <- Convolution35
I0218 21:03:21.348649 31980 net.cpp:405] Scale35 -> Convolution35 (in-place)
I0218 21:03:21.348685 31980 layer_factory.hpp:77] Creating layer Scale35
I0218 21:03:21.348778 31980 net.cpp:150] Setting up Scale35
I0218 21:03:21.348784 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.348788 31980 net.cpp:165] Memory required for data: 322479200
I0218 21:03:21.348793 31980 layer_factory.hpp:77] Creating layer Convolution36
I0218 21:03:21.348803 31980 net.cpp:100] Creating Layer Convolution36
I0218 21:03:21.348806 31980 net.cpp:444] Convolution36 <- Eltwise13_ReLU27_0_split_1
I0218 21:03:21.348811 31980 net.cpp:418] Convolution36 -> Convolution36
I0218 21:03:21.350984 31980 net.cpp:150] Setting up Convolution36
I0218 21:03:21.350999 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.351002 31980 net.cpp:165] Memory required for data: 323400800
I0218 21:03:21.351008 31980 layer_factory.hpp:77] Creating layer BatchNorm36
I0218 21:03:21.351014 31980 net.cpp:100] Creating Layer BatchNorm36
I0218 21:03:21.351017 31980 net.cpp:444] BatchNorm36 <- Convolution36
I0218 21:03:21.351022 31980 net.cpp:405] BatchNorm36 -> Convolution36 (in-place)
I0218 21:03:21.351191 31980 net.cpp:150] Setting up BatchNorm36
I0218 21:03:21.351197 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.351199 31980 net.cpp:165] Memory required for data: 324322400
I0218 21:03:21.351205 31980 layer_factory.hpp:77] Creating layer Scale36
I0218 21:03:21.351210 31980 net.cpp:100] Creating Layer Scale36
I0218 21:03:21.351213 31980 net.cpp:444] Scale36 <- Convolution36
I0218 21:03:21.351218 31980 net.cpp:405] Scale36 -> Convolution36 (in-place)
I0218 21:03:21.351251 31980 layer_factory.hpp:77] Creating layer Scale36
I0218 21:03:21.351346 31980 net.cpp:150] Setting up Scale36
I0218 21:03:21.351353 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.351356 31980 net.cpp:165] Memory required for data: 325244000
I0218 21:03:21.351361 31980 layer_factory.hpp:77] Creating layer ReLU34
I0218 21:03:21.351364 31980 net.cpp:100] Creating Layer ReLU34
I0218 21:03:21.351367 31980 net.cpp:444] ReLU34 <- Convolution36
I0218 21:03:21.351372 31980 net.cpp:405] ReLU34 -> Convolution36 (in-place)
I0218 21:03:21.351517 31980 net.cpp:150] Setting up ReLU34
I0218 21:03:21.351526 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.351538 31980 net.cpp:165] Memory required for data: 326165600
I0218 21:03:21.351547 31980 layer_factory.hpp:77] Creating layer Convolution37
I0218 21:03:21.351558 31980 net.cpp:100] Creating Layer Convolution37
I0218 21:03:21.351562 31980 net.cpp:444] Convolution37 <- Convolution36
I0218 21:03:21.351568 31980 net.cpp:418] Convolution37 -> Convolution37
I0218 21:03:21.353927 31980 net.cpp:150] Setting up Convolution37
I0218 21:03:21.353941 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.353945 31980 net.cpp:165] Memory required for data: 327087200
I0218 21:03:21.353950 31980 layer_factory.hpp:77] Creating layer BatchNorm37
I0218 21:03:21.353956 31980 net.cpp:100] Creating Layer BatchNorm37
I0218 21:03:21.353960 31980 net.cpp:444] BatchNorm37 <- Convolution37
I0218 21:03:21.353965 31980 net.cpp:405] BatchNorm37 -> Convolution37 (in-place)
I0218 21:03:21.354135 31980 net.cpp:150] Setting up BatchNorm37
I0218 21:03:21.354140 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.354143 31980 net.cpp:165] Memory required for data: 328008800
I0218 21:03:21.354148 31980 layer_factory.hpp:77] Creating layer Scale37
I0218 21:03:21.354154 31980 net.cpp:100] Creating Layer Scale37
I0218 21:03:21.354156 31980 net.cpp:444] Scale37 <- Convolution37
I0218 21:03:21.354161 31980 net.cpp:405] Scale37 -> Convolution37 (in-place)
I0218 21:03:21.354197 31980 layer_factory.hpp:77] Creating layer Scale37
I0218 21:03:21.354293 31980 net.cpp:150] Setting up Scale37
I0218 21:03:21.354300 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.354302 31980 net.cpp:165] Memory required for data: 328930400
I0218 21:03:21.354306 31980 layer_factory.hpp:77] Creating layer Eltwise17
I0218 21:03:21.354312 31980 net.cpp:100] Creating Layer Eltwise17
I0218 21:03:21.354315 31980 net.cpp:444] Eltwise17 <- Convolution35
I0218 21:03:21.354319 31980 net.cpp:444] Eltwise17 <- Convolution37
I0218 21:03:21.354323 31980 net.cpp:418] Eltwise17 -> Eltwise17
I0218 21:03:21.354346 31980 net.cpp:150] Setting up Eltwise17
I0218 21:03:21.354351 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.354353 31980 net.cpp:165] Memory required for data: 329852000
I0218 21:03:21.354357 31980 layer_factory.hpp:77] Creating layer ReLU35
I0218 21:03:21.354360 31980 net.cpp:100] Creating Layer ReLU35
I0218 21:03:21.354363 31980 net.cpp:444] ReLU35 <- Eltwise17
I0218 21:03:21.354367 31980 net.cpp:405] ReLU35 -> Eltwise17 (in-place)
I0218 21:03:21.354884 31980 net.cpp:150] Setting up ReLU35
I0218 21:03:21.354895 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.354898 31980 net.cpp:165] Memory required for data: 330773600
I0218 21:03:21.354902 31980 layer_factory.hpp:77] Creating layer Eltwise17_ReLU35_0_split
I0218 21:03:21.354907 31980 net.cpp:100] Creating Layer Eltwise17_ReLU35_0_split
I0218 21:03:21.354910 31980 net.cpp:444] Eltwise17_ReLU35_0_split <- Eltwise17
I0218 21:03:21.354916 31980 net.cpp:418] Eltwise17_ReLU35_0_split -> Eltwise17_ReLU35_0_split_0
I0218 21:03:21.354923 31980 net.cpp:418] Eltwise17_ReLU35_0_split -> Eltwise17_ReLU35_0_split_1
I0218 21:03:21.354961 31980 net.cpp:150] Setting up Eltwise17_ReLU35_0_split
I0218 21:03:21.354967 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.354970 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.354972 31980 net.cpp:165] Memory required for data: 332616800
I0218 21:03:21.354975 31980 layer_factory.hpp:77] Creating layer Convolution38
I0218 21:03:21.354984 31980 net.cpp:100] Creating Layer Convolution38
I0218 21:03:21.354987 31980 net.cpp:444] Convolution38 <- Eltwise17_ReLU35_0_split_0
I0218 21:03:21.354995 31980 net.cpp:418] Convolution38 -> Convolution38
I0218 21:03:21.357005 31980 net.cpp:150] Setting up Convolution38
I0218 21:03:21.357019 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.357023 31980 net.cpp:165] Memory required for data: 333538400
I0218 21:03:21.357028 31980 layer_factory.hpp:77] Creating layer BatchNorm38
I0218 21:03:21.357034 31980 net.cpp:100] Creating Layer BatchNorm38
I0218 21:03:21.357043 31980 net.cpp:444] BatchNorm38 <- Convolution38
I0218 21:03:21.357053 31980 net.cpp:405] BatchNorm38 -> Convolution38 (in-place)
I0218 21:03:21.357224 31980 net.cpp:150] Setting up BatchNorm38
I0218 21:03:21.357231 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.357234 31980 net.cpp:165] Memory required for data: 334460000
I0218 21:03:21.357240 31980 layer_factory.hpp:77] Creating layer Scale38
I0218 21:03:21.357246 31980 net.cpp:100] Creating Layer Scale38
I0218 21:03:21.357249 31980 net.cpp:444] Scale38 <- Convolution38
I0218 21:03:21.357254 31980 net.cpp:405] Scale38 -> Convolution38 (in-place)
I0218 21:03:21.357290 31980 layer_factory.hpp:77] Creating layer Scale38
I0218 21:03:21.357388 31980 net.cpp:150] Setting up Scale38
I0218 21:03:21.357393 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.357396 31980 net.cpp:165] Memory required for data: 335381600
I0218 21:03:21.357401 31980 layer_factory.hpp:77] Creating layer ReLU36
I0218 21:03:21.357405 31980 net.cpp:100] Creating Layer ReLU36
I0218 21:03:21.357409 31980 net.cpp:444] ReLU36 <- Convolution38
I0218 21:03:21.357414 31980 net.cpp:405] ReLU36 -> Convolution38 (in-place)
I0218 21:03:21.357560 31980 net.cpp:150] Setting up ReLU36
I0218 21:03:21.357569 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.357571 31980 net.cpp:165] Memory required for data: 336303200
I0218 21:03:21.357574 31980 layer_factory.hpp:77] Creating layer Convolution39
I0218 21:03:21.357583 31980 net.cpp:100] Creating Layer Convolution39
I0218 21:03:21.357586 31980 net.cpp:444] Convolution39 <- Convolution38
I0218 21:03:21.357591 31980 net.cpp:418] Convolution39 -> Convolution39
I0218 21:03:21.359611 31980 net.cpp:150] Setting up Convolution39
I0218 21:03:21.359624 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.359627 31980 net.cpp:165] Memory required for data: 337224800
I0218 21:03:21.359633 31980 layer_factory.hpp:77] Creating layer BatchNorm39
I0218 21:03:21.359640 31980 net.cpp:100] Creating Layer BatchNorm39
I0218 21:03:21.359644 31980 net.cpp:444] BatchNorm39 <- Convolution39
I0218 21:03:21.359648 31980 net.cpp:405] BatchNorm39 -> Convolution39 (in-place)
I0218 21:03:21.359822 31980 net.cpp:150] Setting up BatchNorm39
I0218 21:03:21.359829 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.359832 31980 net.cpp:165] Memory required for data: 338146400
I0218 21:03:21.359836 31980 layer_factory.hpp:77] Creating layer Scale39
I0218 21:03:21.359846 31980 net.cpp:100] Creating Layer Scale39
I0218 21:03:21.359850 31980 net.cpp:444] Scale39 <- Convolution39
I0218 21:03:21.359854 31980 net.cpp:405] Scale39 -> Convolution39 (in-place)
I0218 21:03:21.359890 31980 layer_factory.hpp:77] Creating layer Scale39
I0218 21:03:21.359992 31980 net.cpp:150] Setting up Scale39
I0218 21:03:21.360000 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.360002 31980 net.cpp:165] Memory required for data: 339068000
I0218 21:03:21.360008 31980 layer_factory.hpp:77] Creating layer Eltwise18
I0218 21:03:21.360013 31980 net.cpp:100] Creating Layer Eltwise18
I0218 21:03:21.360018 31980 net.cpp:444] Eltwise18 <- Eltwise17_ReLU35_0_split_1
I0218 21:03:21.360020 31980 net.cpp:444] Eltwise18 <- Convolution39
I0218 21:03:21.360024 31980 net.cpp:418] Eltwise18 -> Eltwise18
I0218 21:03:21.360047 31980 net.cpp:150] Setting up Eltwise18
I0218 21:03:21.360052 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.360055 31980 net.cpp:165] Memory required for data: 339989600
I0218 21:03:21.360057 31980 layer_factory.hpp:77] Creating layer ReLU37
I0218 21:03:21.360064 31980 net.cpp:100] Creating Layer ReLU37
I0218 21:03:21.360066 31980 net.cpp:444] ReLU37 <- Eltwise18
I0218 21:03:21.360070 31980 net.cpp:405] ReLU37 -> Eltwise18 (in-place)
I0218 21:03:21.360219 31980 net.cpp:150] Setting up ReLU37
I0218 21:03:21.360227 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.360230 31980 net.cpp:165] Memory required for data: 340911200
I0218 21:03:21.360234 31980 layer_factory.hpp:77] Creating layer Eltwise18_ReLU37_0_split
I0218 21:03:21.360242 31980 net.cpp:100] Creating Layer Eltwise18_ReLU37_0_split
I0218 21:03:21.360250 31980 net.cpp:444] Eltwise18_ReLU37_0_split <- Eltwise18
I0218 21:03:21.360256 31980 net.cpp:418] Eltwise18_ReLU37_0_split -> Eltwise18_ReLU37_0_split_0
I0218 21:03:21.360262 31980 net.cpp:418] Eltwise18_ReLU37_0_split -> Eltwise18_ReLU37_0_split_1
I0218 21:03:21.360299 31980 net.cpp:150] Setting up Eltwise18_ReLU37_0_split
I0218 21:03:21.360306 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.360311 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.360312 31980 net.cpp:165] Memory required for data: 342754400
I0218 21:03:21.360316 31980 layer_factory.hpp:77] Creating layer Convolution40
I0218 21:03:21.360323 31980 net.cpp:100] Creating Layer Convolution40
I0218 21:03:21.360327 31980 net.cpp:444] Convolution40 <- Eltwise18_ReLU37_0_split_0
I0218 21:03:21.360332 31980 net.cpp:418] Convolution40 -> Convolution40
I0218 21:03:21.362335 31980 net.cpp:150] Setting up Convolution40
I0218 21:03:21.362347 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.362351 31980 net.cpp:165] Memory required for data: 343676000
I0218 21:03:21.362356 31980 layer_factory.hpp:77] Creating layer BatchNorm40
I0218 21:03:21.362363 31980 net.cpp:100] Creating Layer BatchNorm40
I0218 21:03:21.362366 31980 net.cpp:444] BatchNorm40 <- Convolution40
I0218 21:03:21.362371 31980 net.cpp:405] BatchNorm40 -> Convolution40 (in-place)
I0218 21:03:21.362545 31980 net.cpp:150] Setting up BatchNorm40
I0218 21:03:21.362550 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.362552 31980 net.cpp:165] Memory required for data: 344597600
I0218 21:03:21.362558 31980 layer_factory.hpp:77] Creating layer Scale40
I0218 21:03:21.362563 31980 net.cpp:100] Creating Layer Scale40
I0218 21:03:21.362566 31980 net.cpp:444] Scale40 <- Convolution40
I0218 21:03:21.362570 31980 net.cpp:405] Scale40 -> Convolution40 (in-place)
I0218 21:03:21.362608 31980 layer_factory.hpp:77] Creating layer Scale40
I0218 21:03:21.362711 31980 net.cpp:150] Setting up Scale40
I0218 21:03:21.362718 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.362720 31980 net.cpp:165] Memory required for data: 345519200
I0218 21:03:21.362725 31980 layer_factory.hpp:77] Creating layer ReLU38
I0218 21:03:21.362730 31980 net.cpp:100] Creating Layer ReLU38
I0218 21:03:21.362733 31980 net.cpp:444] ReLU38 <- Convolution40
I0218 21:03:21.362736 31980 net.cpp:405] ReLU38 -> Convolution40 (in-place)
I0218 21:03:21.363256 31980 net.cpp:150] Setting up ReLU38
I0218 21:03:21.363267 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.363270 31980 net.cpp:165] Memory required for data: 346440800
I0218 21:03:21.363273 31980 layer_factory.hpp:77] Creating layer Convolution41
I0218 21:03:21.363283 31980 net.cpp:100] Creating Layer Convolution41
I0218 21:03:21.363286 31980 net.cpp:444] Convolution41 <- Convolution40
I0218 21:03:21.363292 31980 net.cpp:418] Convolution41 -> Convolution41
I0218 21:03:21.365317 31980 net.cpp:150] Setting up Convolution41
I0218 21:03:21.365332 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.365335 31980 net.cpp:165] Memory required for data: 347362400
I0218 21:03:21.365341 31980 layer_factory.hpp:77] Creating layer BatchNorm41
I0218 21:03:21.365346 31980 net.cpp:100] Creating Layer BatchNorm41
I0218 21:03:21.365350 31980 net.cpp:444] BatchNorm41 <- Convolution41
I0218 21:03:21.365356 31980 net.cpp:405] BatchNorm41 -> Convolution41 (in-place)
I0218 21:03:21.365528 31980 net.cpp:150] Setting up BatchNorm41
I0218 21:03:21.365535 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.365537 31980 net.cpp:165] Memory required for data: 348284000
I0218 21:03:21.365543 31980 layer_factory.hpp:77] Creating layer Scale41
I0218 21:03:21.365550 31980 net.cpp:100] Creating Layer Scale41
I0218 21:03:21.365552 31980 net.cpp:444] Scale41 <- Convolution41
I0218 21:03:21.365556 31980 net.cpp:405] Scale41 -> Convolution41 (in-place)
I0218 21:03:21.365592 31980 layer_factory.hpp:77] Creating layer Scale41
I0218 21:03:21.365698 31980 net.cpp:150] Setting up Scale41
I0218 21:03:21.365712 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.365715 31980 net.cpp:165] Memory required for data: 349205600
I0218 21:03:21.365720 31980 layer_factory.hpp:77] Creating layer Eltwise19
I0218 21:03:21.365726 31980 net.cpp:100] Creating Layer Eltwise19
I0218 21:03:21.365731 31980 net.cpp:444] Eltwise19 <- Eltwise18_ReLU37_0_split_1
I0218 21:03:21.365734 31980 net.cpp:444] Eltwise19 <- Convolution41
I0218 21:03:21.365738 31980 net.cpp:418] Eltwise19 -> Eltwise19
I0218 21:03:21.365762 31980 net.cpp:150] Setting up Eltwise19
I0218 21:03:21.365768 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.365772 31980 net.cpp:165] Memory required for data: 350127200
I0218 21:03:21.365773 31980 layer_factory.hpp:77] Creating layer ReLU39
I0218 21:03:21.365778 31980 net.cpp:100] Creating Layer ReLU39
I0218 21:03:21.365780 31980 net.cpp:444] ReLU39 <- Eltwise19
I0218 21:03:21.365784 31980 net.cpp:405] ReLU39 -> Eltwise19 (in-place)
I0218 21:03:21.365933 31980 net.cpp:150] Setting up ReLU39
I0218 21:03:21.365942 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.365944 31980 net.cpp:165] Memory required for data: 351048800
I0218 21:03:21.365947 31980 layer_factory.hpp:77] Creating layer Eltwise19_ReLU39_0_split
I0218 21:03:21.365952 31980 net.cpp:100] Creating Layer Eltwise19_ReLU39_0_split
I0218 21:03:21.365957 31980 net.cpp:444] Eltwise19_ReLU39_0_split <- Eltwise19
I0218 21:03:21.365962 31980 net.cpp:418] Eltwise19_ReLU39_0_split -> Eltwise19_ReLU39_0_split_0
I0218 21:03:21.365967 31980 net.cpp:418] Eltwise19_ReLU39_0_split -> Eltwise19_ReLU39_0_split_1
I0218 21:03:21.366005 31980 net.cpp:150] Setting up Eltwise19_ReLU39_0_split
I0218 21:03:21.366011 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.366014 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.366017 31980 net.cpp:165] Memory required for data: 352892000
I0218 21:03:21.366019 31980 layer_factory.hpp:77] Creating layer Convolution42
I0218 21:03:21.366027 31980 net.cpp:100] Creating Layer Convolution42
I0218 21:03:21.366030 31980 net.cpp:444] Convolution42 <- Eltwise19_ReLU39_0_split_0
I0218 21:03:21.366037 31980 net.cpp:418] Convolution42 -> Convolution42
I0218 21:03:21.368088 31980 net.cpp:150] Setting up Convolution42
I0218 21:03:21.368101 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.368104 31980 net.cpp:165] Memory required for data: 353813600
I0218 21:03:21.368110 31980 layer_factory.hpp:77] Creating layer BatchNorm42
I0218 21:03:21.368118 31980 net.cpp:100] Creating Layer BatchNorm42
I0218 21:03:21.368120 31980 net.cpp:444] BatchNorm42 <- Convolution42
I0218 21:03:21.368124 31980 net.cpp:405] BatchNorm42 -> Convolution42 (in-place)
I0218 21:03:21.368302 31980 net.cpp:150] Setting up BatchNorm42
I0218 21:03:21.368309 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.368312 31980 net.cpp:165] Memory required for data: 354735200
I0218 21:03:21.368317 31980 layer_factory.hpp:77] Creating layer Scale42
I0218 21:03:21.368324 31980 net.cpp:100] Creating Layer Scale42
I0218 21:03:21.368326 31980 net.cpp:444] Scale42 <- Convolution42
I0218 21:03:21.368330 31980 net.cpp:405] Scale42 -> Convolution42 (in-place)
I0218 21:03:21.368367 31980 layer_factory.hpp:77] Creating layer Scale42
I0218 21:03:21.368468 31980 net.cpp:150] Setting up Scale42
I0218 21:03:21.368474 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.368476 31980 net.cpp:165] Memory required for data: 355656800
I0218 21:03:21.368481 31980 layer_factory.hpp:77] Creating layer ReLU40
I0218 21:03:21.368487 31980 net.cpp:100] Creating Layer ReLU40
I0218 21:03:21.368490 31980 net.cpp:444] ReLU40 <- Convolution42
I0218 21:03:21.368494 31980 net.cpp:405] ReLU40 -> Convolution42 (in-place)
I0218 21:03:21.368644 31980 net.cpp:150] Setting up ReLU40
I0218 21:03:21.368652 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.368655 31980 net.cpp:165] Memory required for data: 356578400
I0218 21:03:21.368661 31980 layer_factory.hpp:77] Creating layer Convolution43
I0218 21:03:21.368675 31980 net.cpp:100] Creating Layer Convolution43
I0218 21:03:21.368680 31980 net.cpp:444] Convolution43 <- Convolution42
I0218 21:03:21.368685 31980 net.cpp:418] Convolution43 -> Convolution43
I0218 21:03:21.371026 31980 net.cpp:150] Setting up Convolution43
I0218 21:03:21.371039 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.371042 31980 net.cpp:165] Memory required for data: 357500000
I0218 21:03:21.371048 31980 layer_factory.hpp:77] Creating layer BatchNorm43
I0218 21:03:21.371055 31980 net.cpp:100] Creating Layer BatchNorm43
I0218 21:03:21.371058 31980 net.cpp:444] BatchNorm43 <- Convolution43
I0218 21:03:21.371064 31980 net.cpp:405] BatchNorm43 -> Convolution43 (in-place)
I0218 21:03:21.371243 31980 net.cpp:150] Setting up BatchNorm43
I0218 21:03:21.371250 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.371253 31980 net.cpp:165] Memory required for data: 358421600
I0218 21:03:21.371258 31980 layer_factory.hpp:77] Creating layer Scale43
I0218 21:03:21.371263 31980 net.cpp:100] Creating Layer Scale43
I0218 21:03:21.371268 31980 net.cpp:444] Scale43 <- Convolution43
I0218 21:03:21.371271 31980 net.cpp:405] Scale43 -> Convolution43 (in-place)
I0218 21:03:21.371309 31980 layer_factory.hpp:77] Creating layer Scale43
I0218 21:03:21.371412 31980 net.cpp:150] Setting up Scale43
I0218 21:03:21.371417 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.371420 31980 net.cpp:165] Memory required for data: 359343200
I0218 21:03:21.371425 31980 layer_factory.hpp:77] Creating layer Eltwise20
I0218 21:03:21.371430 31980 net.cpp:100] Creating Layer Eltwise20
I0218 21:03:21.371433 31980 net.cpp:444] Eltwise20 <- Eltwise19_ReLU39_0_split_1
I0218 21:03:21.371436 31980 net.cpp:444] Eltwise20 <- Convolution43
I0218 21:03:21.371443 31980 net.cpp:418] Eltwise20 -> Eltwise20
I0218 21:03:21.371464 31980 net.cpp:150] Setting up Eltwise20
I0218 21:03:21.371471 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.371474 31980 net.cpp:165] Memory required for data: 360264800
I0218 21:03:21.371476 31980 layer_factory.hpp:77] Creating layer ReLU41
I0218 21:03:21.371481 31980 net.cpp:100] Creating Layer ReLU41
I0218 21:03:21.371484 31980 net.cpp:444] ReLU41 <- Eltwise20
I0218 21:03:21.371487 31980 net.cpp:405] ReLU41 -> Eltwise20 (in-place)
I0218 21:03:21.372011 31980 net.cpp:150] Setting up ReLU41
I0218 21:03:21.372023 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.372026 31980 net.cpp:165] Memory required for data: 361186400
I0218 21:03:21.372030 31980 layer_factory.hpp:77] Creating layer Eltwise20_ReLU41_0_split
I0218 21:03:21.372036 31980 net.cpp:100] Creating Layer Eltwise20_ReLU41_0_split
I0218 21:03:21.372040 31980 net.cpp:444] Eltwise20_ReLU41_0_split <- Eltwise20
I0218 21:03:21.372045 31980 net.cpp:418] Eltwise20_ReLU41_0_split -> Eltwise20_ReLU41_0_split_0
I0218 21:03:21.372051 31980 net.cpp:418] Eltwise20_ReLU41_0_split -> Eltwise20_ReLU41_0_split_1
I0218 21:03:21.372092 31980 net.cpp:150] Setting up Eltwise20_ReLU41_0_split
I0218 21:03:21.372099 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.372103 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.372105 31980 net.cpp:165] Memory required for data: 363029600
I0218 21:03:21.372108 31980 layer_factory.hpp:77] Creating layer Convolution44
I0218 21:03:21.372117 31980 net.cpp:100] Creating Layer Convolution44
I0218 21:03:21.372120 31980 net.cpp:444] Convolution44 <- Eltwise20_ReLU41_0_split_0
I0218 21:03:21.372125 31980 net.cpp:418] Convolution44 -> Convolution44
I0218 21:03:21.374176 31980 net.cpp:150] Setting up Convolution44
I0218 21:03:21.374189 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.374192 31980 net.cpp:165] Memory required for data: 363951200
I0218 21:03:21.374198 31980 layer_factory.hpp:77] Creating layer BatchNorm44
I0218 21:03:21.374203 31980 net.cpp:100] Creating Layer BatchNorm44
I0218 21:03:21.374207 31980 net.cpp:444] BatchNorm44 <- Convolution44
I0218 21:03:21.374215 31980 net.cpp:405] BatchNorm44 -> Convolution44 (in-place)
I0218 21:03:21.374398 31980 net.cpp:150] Setting up BatchNorm44
I0218 21:03:21.374405 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.374408 31980 net.cpp:165] Memory required for data: 364872800
I0218 21:03:21.374413 31980 layer_factory.hpp:77] Creating layer Scale44
I0218 21:03:21.374418 31980 net.cpp:100] Creating Layer Scale44
I0218 21:03:21.374421 31980 net.cpp:444] Scale44 <- Convolution44
I0218 21:03:21.374426 31980 net.cpp:405] Scale44 -> Convolution44 (in-place)
I0218 21:03:21.374464 31980 layer_factory.hpp:77] Creating layer Scale44
I0218 21:03:21.374569 31980 net.cpp:150] Setting up Scale44
I0218 21:03:21.374577 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.374579 31980 net.cpp:165] Memory required for data: 365794400
I0218 21:03:21.374584 31980 layer_factory.hpp:77] Creating layer ReLU42
I0218 21:03:21.374588 31980 net.cpp:100] Creating Layer ReLU42
I0218 21:03:21.374593 31980 net.cpp:444] ReLU42 <- Convolution44
I0218 21:03:21.374598 31980 net.cpp:405] ReLU42 -> Convolution44 (in-place)
I0218 21:03:21.374747 31980 net.cpp:150] Setting up ReLU42
I0218 21:03:21.374755 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.374758 31980 net.cpp:165] Memory required for data: 366716000
I0218 21:03:21.374761 31980 layer_factory.hpp:77] Creating layer Convolution45
I0218 21:03:21.374769 31980 net.cpp:100] Creating Layer Convolution45
I0218 21:03:21.374773 31980 net.cpp:444] Convolution45 <- Convolution44
I0218 21:03:21.374779 31980 net.cpp:418] Convolution45 -> Convolution45
I0218 21:03:21.377164 31980 net.cpp:150] Setting up Convolution45
I0218 21:03:21.377178 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.377182 31980 net.cpp:165] Memory required for data: 367637600
I0218 21:03:21.377188 31980 layer_factory.hpp:77] Creating layer BatchNorm45
I0218 21:03:21.377193 31980 net.cpp:100] Creating Layer BatchNorm45
I0218 21:03:21.377197 31980 net.cpp:444] BatchNorm45 <- Convolution45
I0218 21:03:21.377202 31980 net.cpp:405] BatchNorm45 -> Convolution45 (in-place)
I0218 21:03:21.377383 31980 net.cpp:150] Setting up BatchNorm45
I0218 21:03:21.377389 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.377393 31980 net.cpp:165] Memory required for data: 368559200
I0218 21:03:21.377398 31980 layer_factory.hpp:77] Creating layer Scale45
I0218 21:03:21.377404 31980 net.cpp:100] Creating Layer Scale45
I0218 21:03:21.377408 31980 net.cpp:444] Scale45 <- Convolution45
I0218 21:03:21.377410 31980 net.cpp:405] Scale45 -> Convolution45 (in-place)
I0218 21:03:21.377449 31980 layer_factory.hpp:77] Creating layer Scale45
I0218 21:03:21.377553 31980 net.cpp:150] Setting up Scale45
I0218 21:03:21.377560 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.377562 31980 net.cpp:165] Memory required for data: 369480800
I0218 21:03:21.377568 31980 layer_factory.hpp:77] Creating layer Eltwise21
I0218 21:03:21.377573 31980 net.cpp:100] Creating Layer Eltwise21
I0218 21:03:21.377576 31980 net.cpp:444] Eltwise21 <- Eltwise20_ReLU41_0_split_1
I0218 21:03:21.377580 31980 net.cpp:444] Eltwise21 <- Convolution45
I0218 21:03:21.377584 31980 net.cpp:418] Eltwise21 -> Eltwise21
I0218 21:03:21.377609 31980 net.cpp:150] Setting up Eltwise21
I0218 21:03:21.377614 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.377616 31980 net.cpp:165] Memory required for data: 370402400
I0218 21:03:21.377619 31980 layer_factory.hpp:77] Creating layer Convolution_eltwise5
I0218 21:03:21.377626 31980 net.cpp:100] Creating Layer Convolution_eltwise5
I0218 21:03:21.377630 31980 net.cpp:444] Convolution_eltwise5 <- Eltwise5_ReLU11_0_split_2
I0218 21:03:21.377636 31980 net.cpp:418] Convolution_eltwise5 -> Convolution_eltwise5
I0218 21:03:21.379101 31980 net.cpp:150] Setting up Convolution_eltwise5
I0218 21:03:21.379114 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.379117 31980 net.cpp:165] Memory required for data: 371324000
I0218 21:03:21.379122 31980 layer_factory.hpp:77] Creating layer BatchNorm_Convolution_eltwise5
I0218 21:03:21.379132 31980 net.cpp:100] Creating Layer BatchNorm_Convolution_eltwise5
I0218 21:03:21.379142 31980 net.cpp:444] BatchNorm_Convolution_eltwise5 <- Convolution_eltwise5
I0218 21:03:21.379145 31980 net.cpp:405] BatchNorm_Convolution_eltwise5 -> Convolution_eltwise5 (in-place)
I0218 21:03:21.379326 31980 net.cpp:150] Setting up BatchNorm_Convolution_eltwise5
I0218 21:03:21.379333 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.379335 31980 net.cpp:165] Memory required for data: 372245600
I0218 21:03:21.379341 31980 layer_factory.hpp:77] Creating layer Scale_Convolution_eltwise5
I0218 21:03:21.379348 31980 net.cpp:100] Creating Layer Scale_Convolution_eltwise5
I0218 21:03:21.379350 31980 net.cpp:444] Scale_Convolution_eltwise5 <- Convolution_eltwise5
I0218 21:03:21.379354 31980 net.cpp:405] Scale_Convolution_eltwise5 -> Convolution_eltwise5 (in-place)
I0218 21:03:21.379393 31980 layer_factory.hpp:77] Creating layer Scale_Convolution_eltwise5
I0218 21:03:21.379500 31980 net.cpp:150] Setting up Scale_Convolution_eltwise5
I0218 21:03:21.379506 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.379509 31980 net.cpp:165] Memory required for data: 373167200
I0218 21:03:21.379514 31980 layer_factory.hpp:77] Creating layer Convolution_eltwise13
I0218 21:03:21.379523 31980 net.cpp:100] Creating Layer Convolution_eltwise13
I0218 21:03:21.379526 31980 net.cpp:444] Convolution_eltwise13 <- Eltwise13_ReLU27_0_split_2
I0218 21:03:21.379542 31980 net.cpp:418] Convolution_eltwise13 -> Convolution_eltwise13
I0218 21:03:21.381055 31980 net.cpp:150] Setting up Convolution_eltwise13
I0218 21:03:21.381068 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.381072 31980 net.cpp:165] Memory required for data: 374088800
I0218 21:03:21.381078 31980 layer_factory.hpp:77] Creating layer BatchNorm_Convolution_eltwise13
I0218 21:03:21.381083 31980 net.cpp:100] Creating Layer BatchNorm_Convolution_eltwise13
I0218 21:03:21.381086 31980 net.cpp:444] BatchNorm_Convolution_eltwise13 <- Convolution_eltwise13
I0218 21:03:21.381091 31980 net.cpp:405] BatchNorm_Convolution_eltwise13 -> Convolution_eltwise13 (in-place)
I0218 21:03:21.381270 31980 net.cpp:150] Setting up BatchNorm_Convolution_eltwise13
I0218 21:03:21.381276 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.381279 31980 net.cpp:165] Memory required for data: 375010400
I0218 21:03:21.381284 31980 layer_factory.hpp:77] Creating layer Scale_Convolution_eltwise13
I0218 21:03:21.381289 31980 net.cpp:100] Creating Layer Scale_Convolution_eltwise13
I0218 21:03:21.381292 31980 net.cpp:444] Scale_Convolution_eltwise13 <- Convolution_eltwise13
I0218 21:03:21.381297 31980 net.cpp:405] Scale_Convolution_eltwise13 -> Convolution_eltwise13 (in-place)
I0218 21:03:21.381337 31980 layer_factory.hpp:77] Creating layer Scale_Convolution_eltwise13
I0218 21:03:21.381445 31980 net.cpp:150] Setting up Scale_Convolution_eltwise13
I0218 21:03:21.381453 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.381454 31980 net.cpp:165] Memory required for data: 375932000
I0218 21:03:21.381459 31980 layer_factory.hpp:77] Creating layer fuse1
I0218 21:03:21.381466 31980 net.cpp:100] Creating Layer fuse1
I0218 21:03:21.381469 31980 net.cpp:444] fuse1 <- Convolution_eltwise5
I0218 21:03:21.381474 31980 net.cpp:444] fuse1 <- Convolution_eltwise13
I0218 21:03:21.381479 31980 net.cpp:418] fuse1 -> fuse1
I0218 21:03:21.381501 31980 net.cpp:150] Setting up fuse1
I0218 21:03:21.381507 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.381510 31980 net.cpp:165] Memory required for data: 376853600
I0218 21:03:21.381512 31980 layer_factory.hpp:77] Creating layer fuse2
I0218 21:03:21.381518 31980 net.cpp:100] Creating Layer fuse2
I0218 21:03:21.381521 31980 net.cpp:444] fuse2 <- fuse1
I0218 21:03:21.381525 31980 net.cpp:444] fuse2 <- Eltwise21
I0218 21:03:21.381527 31980 net.cpp:418] fuse2 -> fuse2
I0218 21:03:21.381549 31980 net.cpp:150] Setting up fuse2
I0218 21:03:21.381554 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.381562 31980 net.cpp:165] Memory required for data: 377775200
I0218 21:03:21.381569 31980 layer_factory.hpp:77] Creating layer ReLU49
I0218 21:03:21.381574 31980 net.cpp:100] Creating Layer ReLU49
I0218 21:03:21.381577 31980 net.cpp:444] ReLU49 <- fuse2
I0218 21:03:21.381582 31980 net.cpp:405] ReLU49 -> fuse2 (in-place)
I0218 21:03:21.381729 31980 net.cpp:150] Setting up ReLU49
I0218 21:03:21.381738 31980 net.cpp:157] Top shape: 100 64 6 6 (230400)
I0218 21:03:21.381742 31980 net.cpp:165] Memory required for data: 378696800
I0218 21:03:21.381744 31980 layer_factory.hpp:77] Creating layer Pooling1
I0218 21:03:21.381752 31980 net.cpp:100] Creating Layer Pooling1
I0218 21:03:21.381754 31980 net.cpp:444] Pooling1 <- fuse2
I0218 21:03:21.381758 31980 net.cpp:418] Pooling1 -> Pooling1
I0218 21:03:21.382280 31980 net.cpp:150] Setting up Pooling1
I0218 21:03:21.382292 31980 net.cpp:157] Top shape: 100 64 1 1 (6400)
I0218 21:03:21.382295 31980 net.cpp:165] Memory required for data: 378722400
I0218 21:03:21.382299 31980 layer_factory.hpp:77] Creating layer InnerProduct1
I0218 21:03:21.382308 31980 net.cpp:100] Creating Layer InnerProduct1
I0218 21:03:21.382310 31980 net.cpp:444] InnerProduct1 <- Pooling1
I0218 21:03:21.382318 31980 net.cpp:418] InnerProduct1 -> InnerProduct1
I0218 21:03:21.382431 31980 net.cpp:150] Setting up InnerProduct1
I0218 21:03:21.382438 31980 net.cpp:157] Top shape: 100 9 (900)
I0218 21:03:21.382441 31980 net.cpp:165] Memory required for data: 378726000
I0218 21:03:21.382447 31980 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0218 21:03:21.382452 31980 net.cpp:100] Creating Layer SoftmaxWithLoss1
I0218 21:03:21.382454 31980 net.cpp:444] SoftmaxWithLoss1 <- InnerProduct1
I0218 21:03:21.382458 31980 net.cpp:444] SoftmaxWithLoss1 <- label
I0218 21:03:21.382463 31980 net.cpp:418] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0218 21:03:21.382472 31980 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0218 21:03:21.382710 31980 net.cpp:150] Setting up SoftmaxWithLoss1
I0218 21:03:21.382719 31980 net.cpp:157] Top shape: (1)
I0218 21:03:21.382721 31980 net.cpp:160]     with loss weight 1
I0218 21:03:21.382740 31980 net.cpp:165] Memory required for data: 378726004
I0218 21:03:21.382743 31980 net.cpp:226] SoftmaxWithLoss1 needs backward computation.
I0218 21:03:21.382750 31980 net.cpp:226] InnerProduct1 needs backward computation.
I0218 21:03:21.382753 31980 net.cpp:226] Pooling1 needs backward computation.
I0218 21:03:21.382756 31980 net.cpp:226] ReLU49 needs backward computation.
I0218 21:03:21.382758 31980 net.cpp:226] fuse2 needs backward computation.
I0218 21:03:21.382761 31980 net.cpp:226] fuse1 needs backward computation.
I0218 21:03:21.382766 31980 net.cpp:226] Scale_Convolution_eltwise13 needs backward computation.
I0218 21:03:21.382767 31980 net.cpp:226] BatchNorm_Convolution_eltwise13 needs backward computation.
I0218 21:03:21.382771 31980 net.cpp:226] Convolution_eltwise13 needs backward computation.
I0218 21:03:21.382773 31980 net.cpp:226] Scale_Convolution_eltwise5 needs backward computation.
I0218 21:03:21.382776 31980 net.cpp:226] BatchNorm_Convolution_eltwise5 needs backward computation.
I0218 21:03:21.382779 31980 net.cpp:226] Convolution_eltwise5 needs backward computation.
I0218 21:03:21.382781 31980 net.cpp:226] Eltwise21 needs backward computation.
I0218 21:03:21.382786 31980 net.cpp:226] Scale45 needs backward computation.
I0218 21:03:21.382788 31980 net.cpp:226] BatchNorm45 needs backward computation.
I0218 21:03:21.382791 31980 net.cpp:226] Convolution45 needs backward computation.
I0218 21:03:21.382793 31980 net.cpp:226] ReLU42 needs backward computation.
I0218 21:03:21.382795 31980 net.cpp:226] Scale44 needs backward computation.
I0218 21:03:21.382798 31980 net.cpp:226] BatchNorm44 needs backward computation.
I0218 21:03:21.382802 31980 net.cpp:226] Convolution44 needs backward computation.
I0218 21:03:21.382803 31980 net.cpp:226] Eltwise20_ReLU41_0_split needs backward computation.
I0218 21:03:21.382807 31980 net.cpp:226] ReLU41 needs backward computation.
I0218 21:03:21.382813 31980 net.cpp:226] Eltwise20 needs backward computation.
I0218 21:03:21.382820 31980 net.cpp:226] Scale43 needs backward computation.
I0218 21:03:21.382823 31980 net.cpp:226] BatchNorm43 needs backward computation.
I0218 21:03:21.382825 31980 net.cpp:226] Convolution43 needs backward computation.
I0218 21:03:21.382828 31980 net.cpp:226] ReLU40 needs backward computation.
I0218 21:03:21.382831 31980 net.cpp:226] Scale42 needs backward computation.
I0218 21:03:21.382833 31980 net.cpp:226] BatchNorm42 needs backward computation.
I0218 21:03:21.382836 31980 net.cpp:226] Convolution42 needs backward computation.
I0218 21:03:21.382839 31980 net.cpp:226] Eltwise19_ReLU39_0_split needs backward computation.
I0218 21:03:21.382843 31980 net.cpp:226] ReLU39 needs backward computation.
I0218 21:03:21.382845 31980 net.cpp:226] Eltwise19 needs backward computation.
I0218 21:03:21.382849 31980 net.cpp:226] Scale41 needs backward computation.
I0218 21:03:21.382853 31980 net.cpp:226] BatchNorm41 needs backward computation.
I0218 21:03:21.382855 31980 net.cpp:226] Convolution41 needs backward computation.
I0218 21:03:21.382858 31980 net.cpp:226] ReLU38 needs backward computation.
I0218 21:03:21.382860 31980 net.cpp:226] Scale40 needs backward computation.
I0218 21:03:21.382863 31980 net.cpp:226] BatchNorm40 needs backward computation.
I0218 21:03:21.382865 31980 net.cpp:226] Convolution40 needs backward computation.
I0218 21:03:21.382869 31980 net.cpp:226] Eltwise18_ReLU37_0_split needs backward computation.
I0218 21:03:21.382871 31980 net.cpp:226] ReLU37 needs backward computation.
I0218 21:03:21.382874 31980 net.cpp:226] Eltwise18 needs backward computation.
I0218 21:03:21.382877 31980 net.cpp:226] Scale39 needs backward computation.
I0218 21:03:21.382879 31980 net.cpp:226] BatchNorm39 needs backward computation.
I0218 21:03:21.382882 31980 net.cpp:226] Convolution39 needs backward computation.
I0218 21:03:21.382885 31980 net.cpp:226] ReLU36 needs backward computation.
I0218 21:03:21.382887 31980 net.cpp:226] Scale38 needs backward computation.
I0218 21:03:21.382890 31980 net.cpp:226] BatchNorm38 needs backward computation.
I0218 21:03:21.382892 31980 net.cpp:226] Convolution38 needs backward computation.
I0218 21:03:21.382896 31980 net.cpp:226] Eltwise17_ReLU35_0_split needs backward computation.
I0218 21:03:21.382899 31980 net.cpp:226] ReLU35 needs backward computation.
I0218 21:03:21.382901 31980 net.cpp:226] Eltwise17 needs backward computation.
I0218 21:03:21.382905 31980 net.cpp:226] Scale37 needs backward computation.
I0218 21:03:21.382907 31980 net.cpp:226] BatchNorm37 needs backward computation.
I0218 21:03:21.382910 31980 net.cpp:226] Convolution37 needs backward computation.
I0218 21:03:21.382912 31980 net.cpp:226] ReLU34 needs backward computation.
I0218 21:03:21.382915 31980 net.cpp:226] Scale36 needs backward computation.
I0218 21:03:21.382918 31980 net.cpp:226] BatchNorm36 needs backward computation.
I0218 21:03:21.382920 31980 net.cpp:226] Convolution36 needs backward computation.
I0218 21:03:21.382923 31980 net.cpp:226] Scale35 needs backward computation.
I0218 21:03:21.382925 31980 net.cpp:226] BatchNorm35 needs backward computation.
I0218 21:03:21.382928 31980 net.cpp:226] Convolution35 needs backward computation.
I0218 21:03:21.382931 31980 net.cpp:226] Eltwise13_ReLU27_0_split needs backward computation.
I0218 21:03:21.382935 31980 net.cpp:226] ReLU27 needs backward computation.
I0218 21:03:21.382937 31980 net.cpp:226] Eltwise13 needs backward computation.
I0218 21:03:21.382941 31980 net.cpp:226] Scale28 needs backward computation.
I0218 21:03:21.382943 31980 net.cpp:226] BatchNorm28 needs backward computation.
I0218 21:03:21.382946 31980 net.cpp:226] Convolution28 needs backward computation.
I0218 21:03:21.382948 31980 net.cpp:226] ReLU26 needs backward computation.
I0218 21:03:21.382951 31980 net.cpp:226] Scale27 needs backward computation.
I0218 21:03:21.382953 31980 net.cpp:226] BatchNorm27 needs backward computation.
I0218 21:03:21.382956 31980 net.cpp:226] Convolution27 needs backward computation.
I0218 21:03:21.382961 31980 net.cpp:226] Eltwise12_ReLU25_0_split needs backward computation.
I0218 21:03:21.382968 31980 net.cpp:226] ReLU25 needs backward computation.
I0218 21:03:21.382972 31980 net.cpp:226] Eltwise12 needs backward computation.
I0218 21:03:21.382974 31980 net.cpp:226] Scale26 needs backward computation.
I0218 21:03:21.382977 31980 net.cpp:226] BatchNorm26 needs backward computation.
I0218 21:03:21.382980 31980 net.cpp:226] Convolution26 needs backward computation.
I0218 21:03:21.382982 31980 net.cpp:226] ReLU24 needs backward computation.
I0218 21:03:21.382985 31980 net.cpp:226] Scale25 needs backward computation.
I0218 21:03:21.382988 31980 net.cpp:226] BatchNorm25 needs backward computation.
I0218 21:03:21.382992 31980 net.cpp:226] Convolution25 needs backward computation.
I0218 21:03:21.382993 31980 net.cpp:226] Eltwise11_ReLU23_0_split needs backward computation.
I0218 21:03:21.382997 31980 net.cpp:226] ReLU23 needs backward computation.
I0218 21:03:21.382999 31980 net.cpp:226] Eltwise11 needs backward computation.
I0218 21:03:21.383002 31980 net.cpp:226] Scale24 needs backward computation.
I0218 21:03:21.383005 31980 net.cpp:226] BatchNorm24 needs backward computation.
I0218 21:03:21.383008 31980 net.cpp:226] Convolution24 needs backward computation.
I0218 21:03:21.383010 31980 net.cpp:226] ReLU22 needs backward computation.
I0218 21:03:21.383013 31980 net.cpp:226] Scale23 needs backward computation.
I0218 21:03:21.383016 31980 net.cpp:226] BatchNorm23 needs backward computation.
I0218 21:03:21.383018 31980 net.cpp:226] Convolution23 needs backward computation.
I0218 21:03:21.383021 31980 net.cpp:226] Eltwise10_ReLU21_0_split needs backward computation.
I0218 21:03:21.383024 31980 net.cpp:226] ReLU21 needs backward computation.
I0218 21:03:21.383028 31980 net.cpp:226] Eltwise10 needs backward computation.
I0218 21:03:21.383030 31980 net.cpp:226] Scale22 needs backward computation.
I0218 21:03:21.383033 31980 net.cpp:226] BatchNorm22 needs backward computation.
I0218 21:03:21.383035 31980 net.cpp:226] Convolution22 needs backward computation.
I0218 21:03:21.383038 31980 net.cpp:226] ReLU20 needs backward computation.
I0218 21:03:21.383040 31980 net.cpp:226] Scale21 needs backward computation.
I0218 21:03:21.383044 31980 net.cpp:226] BatchNorm21 needs backward computation.
I0218 21:03:21.383046 31980 net.cpp:226] Convolution21 needs backward computation.
I0218 21:03:21.383049 31980 net.cpp:226] Eltwise9_ReLU19_0_split needs backward computation.
I0218 21:03:21.383052 31980 net.cpp:226] ReLU19 needs backward computation.
I0218 21:03:21.383054 31980 net.cpp:226] Eltwise9 needs backward computation.
I0218 21:03:21.383059 31980 net.cpp:226] Scale20 needs backward computation.
I0218 21:03:21.383061 31980 net.cpp:226] BatchNorm20 needs backward computation.
I0218 21:03:21.383064 31980 net.cpp:226] Convolution20 needs backward computation.
I0218 21:03:21.383066 31980 net.cpp:226] ReLU18 needs backward computation.
I0218 21:03:21.383069 31980 net.cpp:226] Scale19 needs backward computation.
I0218 21:03:21.383071 31980 net.cpp:226] BatchNorm19 needs backward computation.
I0218 21:03:21.383074 31980 net.cpp:226] Convolution19 needs backward computation.
I0218 21:03:21.383077 31980 net.cpp:226] Scale18 needs backward computation.
I0218 21:03:21.383080 31980 net.cpp:226] BatchNorm18 needs backward computation.
I0218 21:03:21.383083 31980 net.cpp:226] Convolution18 needs backward computation.
I0218 21:03:21.383085 31980 net.cpp:226] Eltwise5_ReLU11_0_split needs backward computation.
I0218 21:03:21.383088 31980 net.cpp:226] ReLU11 needs backward computation.
I0218 21:03:21.383092 31980 net.cpp:226] Eltwise5 needs backward computation.
I0218 21:03:21.383097 31980 net.cpp:226] Scale11 needs backward computation.
I0218 21:03:21.383100 31980 net.cpp:226] BatchNorm11 needs backward computation.
I0218 21:03:21.383102 31980 net.cpp:226] Convolution11 needs backward computation.
I0218 21:03:21.383105 31980 net.cpp:226] ReLU10 needs backward computation.
I0218 21:03:21.383108 31980 net.cpp:226] Scale10 needs backward computation.
I0218 21:03:21.383112 31980 net.cpp:226] BatchNorm10 needs backward computation.
I0218 21:03:21.383118 31980 net.cpp:226] Convolution10 needs backward computation.
I0218 21:03:21.383122 31980 net.cpp:226] Eltwise4_ReLU9_0_split needs backward computation.
I0218 21:03:21.383126 31980 net.cpp:226] ReLU9 needs backward computation.
I0218 21:03:21.383128 31980 net.cpp:226] Eltwise4 needs backward computation.
I0218 21:03:21.383131 31980 net.cpp:226] Scale9 needs backward computation.
I0218 21:03:21.383136 31980 net.cpp:226] BatchNorm9 needs backward computation.
I0218 21:03:21.383137 31980 net.cpp:226] Convolution9 needs backward computation.
I0218 21:03:21.383141 31980 net.cpp:226] ReLU8 needs backward computation.
I0218 21:03:21.383142 31980 net.cpp:226] Scale8 needs backward computation.
I0218 21:03:21.383147 31980 net.cpp:226] BatchNorm8 needs backward computation.
I0218 21:03:21.383148 31980 net.cpp:226] Convolution8 needs backward computation.
I0218 21:03:21.383152 31980 net.cpp:226] Eltwise3_ReLU7_0_split needs backward computation.
I0218 21:03:21.383154 31980 net.cpp:226] ReLU7 needs backward computation.
I0218 21:03:21.383157 31980 net.cpp:226] Eltwise3 needs backward computation.
I0218 21:03:21.383162 31980 net.cpp:226] Scale7 needs backward computation.
I0218 21:03:21.383163 31980 net.cpp:226] BatchNorm7 needs backward computation.
I0218 21:03:21.383167 31980 net.cpp:226] Convolution7 needs backward computation.
I0218 21:03:21.383169 31980 net.cpp:226] ReLU6 needs backward computation.
I0218 21:03:21.383172 31980 net.cpp:226] Scale6 needs backward computation.
I0218 21:03:21.383174 31980 net.cpp:226] BatchNorm6 needs backward computation.
I0218 21:03:21.383177 31980 net.cpp:226] Convolution6 needs backward computation.
I0218 21:03:21.383180 31980 net.cpp:226] Eltwise2_ReLU5_0_split needs backward computation.
I0218 21:03:21.383183 31980 net.cpp:226] ReLU5 needs backward computation.
I0218 21:03:21.383186 31980 net.cpp:226] Eltwise2 needs backward computation.
I0218 21:03:21.383189 31980 net.cpp:226] Scale5 needs backward computation.
I0218 21:03:21.383193 31980 net.cpp:226] BatchNorm5 needs backward computation.
I0218 21:03:21.383195 31980 net.cpp:226] Convolution5 needs backward computation.
I0218 21:03:21.383198 31980 net.cpp:226] ReLU4 needs backward computation.
I0218 21:03:21.383200 31980 net.cpp:226] Scale4 needs backward computation.
I0218 21:03:21.383203 31980 net.cpp:226] BatchNorm4 needs backward computation.
I0218 21:03:21.383206 31980 net.cpp:226] Convolution4 needs backward computation.
I0218 21:03:21.383208 31980 net.cpp:226] Eltwise1_ReLU3_0_split needs backward computation.
I0218 21:03:21.383211 31980 net.cpp:226] ReLU3 needs backward computation.
I0218 21:03:21.383216 31980 net.cpp:226] Eltwise1 needs backward computation.
I0218 21:03:21.383219 31980 net.cpp:226] Scale3 needs backward computation.
I0218 21:03:21.383222 31980 net.cpp:226] BatchNorm3 needs backward computation.
I0218 21:03:21.383225 31980 net.cpp:226] Convolution3 needs backward computation.
I0218 21:03:21.383229 31980 net.cpp:226] ReLU2 needs backward computation.
I0218 21:03:21.383231 31980 net.cpp:226] Scale2 needs backward computation.
I0218 21:03:21.383234 31980 net.cpp:226] BatchNorm2 needs backward computation.
I0218 21:03:21.383236 31980 net.cpp:226] Convolution2 needs backward computation.
I0218 21:03:21.383240 31980 net.cpp:226] Convolution1_ReLU1_0_split needs backward computation.
I0218 21:03:21.383244 31980 net.cpp:226] ReLU1 needs backward computation.
I0218 21:03:21.383246 31980 net.cpp:226] Scale1 needs backward computation.
I0218 21:03:21.383249 31980 net.cpp:226] BatchNorm1 needs backward computation.
I0218 21:03:21.383251 31980 net.cpp:226] Convolution1 needs backward computation.
I0218 21:03:21.383255 31980 net.cpp:228] paviau does not need backward computation.
I0218 21:03:21.383257 31980 net.cpp:270] This network produces output SoftmaxWithLoss1
I0218 21:03:21.383322 31980 net.cpp:283] Network initialization done.
I0218 21:03:21.384277 31980 solver.cpp:181] Creating test net (#0) specified by net file: ./prototxt_files/train_paviau.prototxt
I0218 21:03:21.384382 31980 net.cpp:332] The NetState phase (1) differed from the phase (0) specified by a rule in layer paviau
I0218 21:03:21.384985 31980 net.cpp:58] Initializing net from parameters: 
name: "DFFN_paviau"
state {
  phase: TEST
}
layer {
  name: "paviau"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "samples/paviau/test.txt"
    batch_size: 20
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "data"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution10"
  top: "Convolution10"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution19"
  top: "Convolution19"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Convolution19"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Convolution18"
  bottom: "Convolution20"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU20"
  type: "ReLU"
  bottom: "Convolution21"
  top: "Convolution21"
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Eltwise9"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "Convolution23"
  top: "Convolution23"
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution24"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "Eltwise11"
  top: "Eltwise11"
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU24"
  type: "ReLU"
  bottom: "Convolution25"
  top: "Convolution25"
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Convolution25"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Eltwise11"
  bottom: "Convolution26"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "Eltwise12"
  top: "Eltwise12"
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Eltwise12"
  top: "Convolution27"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU26"
  type: "ReLU"
  bottom: "Convolution27"
  top: "Convolution27"
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Convolution27"
  top: "Convolution28"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm28"
  type: "BatchNorm"
  bottom: "Convolution28"
  top: "Convolution28"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale28"
  type: "Scale"
  bottom: "Convolution28"
  top: "Convolution28"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise13"
  type: "Eltwise"
  bottom: "Eltwise12"
  bottom: "Convolution28"
  top: "Eltwise13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU27"
  type: "ReLU"
  bottom: "Eltwise13"
  top: "Eltwise13"
}
layer {
  name: "Convolution35"
  type: "Convolution"
  bottom: "Eltwise13"
  top: "Convolution35"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm35"
  type: "BatchNorm"
  bottom: "Convolution35"
  top: "Convolution35"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale35"
  type: "Scale"
  bottom: "Convolution35"
  top: "Convolution35"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution36"
  type: "Convolution"
  bottom: "Eltwise13"
  top: "Convolution36"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm36"
  type: "BatchNorm"
  bottom: "Convolution36"
  top: "Convolution36"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale36"
  type: "Scale"
  bottom: "Convolution36"
  top: "Convolution36"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU34"
  type: "ReLU"
  bottom: "Convolution36"
  top: "Convolution36"
}
layer {
  name: "Convolution37"
  type: "Convolution"
  bottom: "Convolution36"
  top: "Convolution37"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm37"
  type: "BatchNorm"
  bottom: "Convolution37"
  top: "Convolution37"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale37"
  type: "Scale"
  bottom: "Convolution37"
  top: "Convolution37"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise17"
  type: "Eltwise"
  bottom: "Convolution35"
  bottom: "Convolution37"
  top: "Eltwise17"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU35"
  type: "ReLU"
  bottom: "Eltwise17"
  top: "Eltwise17"
}
layer {
  name: "Convolution38"
  type: "Convolution"
  bottom: "Eltwise17"
  top: "Convolution38"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm38"
  type: "BatchNorm"
  bottom: "Convolution38"
  top: "Convolution38"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale38"
  type: "Scale"
  bottom: "Convolution38"
  top: "Convolution38"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU36"
  type: "ReLU"
  bottom: "Convolution38"
  top: "Convolution38"
}
layer {
  name: "Convolution39"
  type: "Convolution"
  bottom: "Convolution38"
  top: "Convolution39"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm39"
  type: "BatchNorm"
  bottom: "Convolution39"
  top: "Convolution39"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale39"
  type: "Scale"
  bottom: "Convolution39"
  top: "Convolution39"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise18"
  type: "Eltwise"
  bottom: "Eltwise17"
  bottom: "Convolution39"
  top: "Eltwise18"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU37"
  type: "ReLU"
  bottom: "Eltwise18"
  top: "Eltwise18"
}
layer {
  name: "Convolution40"
  type: "Convolution"
  bottom: "Eltwise18"
  top: "Convolution40"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm40"
  type: "BatchNorm"
  bottom: "Convolution40"
  top: "Convolution40"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale40"
  type: "Scale"
  bottom: "Convolution40"
  top: "Convolution40"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU38"
  type: "ReLU"
  bottom: "Convolution40"
  top: "Convolution40"
}
layer {
  name: "Convolution41"
  type: "Convolution"
  bottom: "Convolution40"
  top: "Convolution41"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm41"
  type: "BatchNorm"
  bottom: "Convolution41"
  top: "Convolution41"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale41"
  type: "Scale"
  bottom: "Convolution41"
  top: "Convolution41"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise19"
  type: "Eltwise"
  bottom: "Eltwise18"
  bottom: "Convolution41"
  top: "Eltwise19"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU39"
  type: "ReLU"
  bottom: "Eltwise19"
  top: "Eltwise19"
}
layer {
  name: "Convolution42"
  type: "Convolution"
  bottom: "Eltwise19"
  top: "Convolution42"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm42"
  type: "BatchNorm"
  bottom: "Convolution42"
  top: "Convolution42"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale42"
  type: "Scale"
  bottom: "Convolution42"
  top: "Convolution42"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU40"
  type: "ReLU"
  bottom: "Convolution42"
  top: "Convolution42"
}
layer {
  name: "Convolution43"
  type: "Convolution"
  bottom: "Convolution42"
  top: "Convolution43"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm43"
  type: "BatchNorm"
  bottom: "Convolution43"
  top: "Convolution43"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale43"
  type: "Scale"
  bottom: "Convolution43"
  top: "Convolution43"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise20"
  type: "Eltwise"
  bottom: "Eltwise19"
  bottom: "Convolution43"
  top: "Eltwise20"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU41"
  type: "ReLU"
  bottom: "Eltwise20"
  top: "Eltwise20"
}
layer {
  name: "Convolution44"
  type: "Convolution"
  bottom: "Eltwise20"
  top: "Convolution44"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm44"
  type: "BatchNorm"
  bottom: "Convolution44"
  top: "Convolution44"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
 
I0218 21:03:21.385340 31980 layer_factory.hpp:77] Creating layer paviau
I0218 21:03:21.385351 31980 net.cpp:100] Creating Layer paviau
I0218 21:03:21.385354 31980 net.cpp:418] paviau -> data
I0218 21:03:21.385361 31980 net.cpp:418] paviau -> label
I0218 21:03:21.385366 31980 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: samples/paviau/test.txt
I0218 21:03:21.385385 31980 hdf5_data_layer.cpp:93] Number of HDF5 files: 5
I0218 21:03:21.430788 31980 net.cpp:150] Setting up paviau
I0218 21:03:21.430827 31980 net.cpp:157] Top shape: 20 5 23 23 (52900)
I0218 21:03:21.430832 31980 net.cpp:157] Top shape: 20 1 (20)
I0218 21:03:21.430835 31980 net.cpp:165] Memory required for data: 211680
I0218 21:03:21.430841 31980 layer_factory.hpp:77] Creating layer label_paviau_1_split
I0218 21:03:21.430852 31980 net.cpp:100] Creating Layer label_paviau_1_split
I0218 21:03:21.430856 31980 net.cpp:444] label_paviau_1_split <- label
I0218 21:03:21.430863 31980 net.cpp:418] label_paviau_1_split -> label_paviau_1_split_0
I0218 21:03:21.430872 31980 net.cpp:418] label_paviau_1_split -> label_paviau_1_split_1
I0218 21:03:21.430910 31980 net.cpp:150] Setting up label_paviau_1_split
I0218 21:03:21.430915 31980 net.cpp:157] Top shape: 20 1 (20)
I0218 21:03:21.430919 31980 net.cpp:157] Top shape: 20 1 (20)
I0218 21:03:21.430922 31980 net.cpp:165] Memory required for data: 211840
I0218 21:03:21.430924 31980 layer_factory.hpp:77] Creating layer Convolution1
I0218 21:03:21.430935 31980 net.cpp:100] Creating Layer Convolution1
I0218 21:03:21.430938 31980 net.cpp:444] Convolution1 <- data
I0218 21:03:21.430943 31980 net.cpp:418] Convolution1 -> Convolution1
I0218 21:03:21.432539 31980 net.cpp:150] Setting up Convolution1
I0218 21:03:21.432554 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.432557 31980 net.cpp:165] Memory required for data: 888960
I0218 21:03:21.432567 31980 layer_factory.hpp:77] Creating layer BatchNorm1
I0218 21:03:21.432574 31980 net.cpp:100] Creating Layer BatchNorm1
I0218 21:03:21.432577 31980 net.cpp:444] BatchNorm1 <- Convolution1
I0218 21:03:21.432581 31980 net.cpp:405] BatchNorm1 -> Convolution1 (in-place)
I0218 21:03:21.432767 31980 net.cpp:150] Setting up BatchNorm1
I0218 21:03:21.432775 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.432776 31980 net.cpp:165] Memory required for data: 1566080
I0218 21:03:21.432785 31980 layer_factory.hpp:77] Creating layer Scale1
I0218 21:03:21.432791 31980 net.cpp:100] Creating Layer Scale1
I0218 21:03:21.432795 31980 net.cpp:444] Scale1 <- Convolution1
I0218 21:03:21.432806 31980 net.cpp:405] Scale1 -> Convolution1 (in-place)
I0218 21:03:21.432854 31980 layer_factory.hpp:77] Creating layer Scale1
I0218 21:03:21.432963 31980 net.cpp:150] Setting up Scale1
I0218 21:03:21.432970 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.432972 31980 net.cpp:165] Memory required for data: 2243200
I0218 21:03:21.432977 31980 layer_factory.hpp:77] Creating layer ReLU1
I0218 21:03:21.432982 31980 net.cpp:100] Creating Layer ReLU1
I0218 21:03:21.432986 31980 net.cpp:444] ReLU1 <- Convolution1
I0218 21:03:21.432989 31980 net.cpp:405] ReLU1 -> Convolution1 (in-place)
I0218 21:03:21.433135 31980 net.cpp:150] Setting up ReLU1
I0218 21:03:21.433142 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.433145 31980 net.cpp:165] Memory required for data: 2920320
I0218 21:03:21.433147 31980 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I0218 21:03:21.433153 31980 net.cpp:100] Creating Layer Convolution1_ReLU1_0_split
I0218 21:03:21.433156 31980 net.cpp:444] Convolution1_ReLU1_0_split <- Convolution1
I0218 21:03:21.433161 31980 net.cpp:418] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I0218 21:03:21.433166 31980 net.cpp:418] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I0218 21:03:21.433205 31980 net.cpp:150] Setting up Convolution1_ReLU1_0_split
I0218 21:03:21.433210 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.433213 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.433217 31980 net.cpp:165] Memory required for data: 4274560
I0218 21:03:21.433219 31980 layer_factory.hpp:77] Creating layer Convolution2
I0218 21:03:21.433226 31980 net.cpp:100] Creating Layer Convolution2
I0218 21:03:21.433229 31980 net.cpp:444] Convolution2 <- Convolution1_ReLU1_0_split_0
I0218 21:03:21.433234 31980 net.cpp:418] Convolution2 -> Convolution2
I0218 21:03:21.434998 31980 net.cpp:150] Setting up Convolution2
I0218 21:03:21.435010 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.435014 31980 net.cpp:165] Memory required for data: 4951680
I0218 21:03:21.435021 31980 layer_factory.hpp:77] Creating layer BatchNorm2
I0218 21:03:21.435029 31980 net.cpp:100] Creating Layer BatchNorm2
I0218 21:03:21.435031 31980 net.cpp:444] BatchNorm2 <- Convolution2
I0218 21:03:21.435036 31980 net.cpp:405] BatchNorm2 -> Convolution2 (in-place)
I0218 21:03:21.435214 31980 net.cpp:150] Setting up BatchNorm2
I0218 21:03:21.435221 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.435225 31980 net.cpp:165] Memory required for data: 5628800
I0218 21:03:21.435230 31980 layer_factory.hpp:77] Creating layer Scale2
I0218 21:03:21.435235 31980 net.cpp:100] Creating Layer Scale2
I0218 21:03:21.435238 31980 net.cpp:444] Scale2 <- Convolution2
I0218 21:03:21.435241 31980 net.cpp:405] Scale2 -> Convolution2 (in-place)
I0218 21:03:21.435278 31980 layer_factory.hpp:77] Creating layer Scale2
I0218 21:03:21.435382 31980 net.cpp:150] Setting up Scale2
I0218 21:03:21.435389 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.435391 31980 net.cpp:165] Memory required for data: 6305920
I0218 21:03:21.435396 31980 layer_factory.hpp:77] Creating layer ReLU2
I0218 21:03:21.435400 31980 net.cpp:100] Creating Layer ReLU2
I0218 21:03:21.435403 31980 net.cpp:444] ReLU2 <- Convolution2
I0218 21:03:21.435407 31980 net.cpp:405] ReLU2 -> Convolution2 (in-place)
I0218 21:03:21.435931 31980 net.cpp:150] Setting up ReLU2
I0218 21:03:21.435943 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.435946 31980 net.cpp:165] Memory required for data: 6983040
I0218 21:03:21.435950 31980 layer_factory.hpp:77] Creating layer Convolution3
I0218 21:03:21.435957 31980 net.cpp:100] Creating Layer Convolution3
I0218 21:03:21.435961 31980 net.cpp:444] Convolution3 <- Convolution2
I0218 21:03:21.435966 31980 net.cpp:418] Convolution3 -> Convolution3
I0218 21:03:21.437361 31980 net.cpp:150] Setting up Convolution3
I0218 21:03:21.437374 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.437377 31980 net.cpp:165] Memory required for data: 7660160
I0218 21:03:21.437387 31980 layer_factory.hpp:77] Creating layer BatchNorm3
I0218 21:03:21.437398 31980 net.cpp:100] Creating Layer BatchNorm3
I0218 21:03:21.437402 31980 net.cpp:444] BatchNorm3 <- Convolution3
I0218 21:03:21.437405 31980 net.cpp:405] BatchNorm3 -> Convolution3 (in-place)
I0218 21:03:21.437580 31980 net.cpp:150] Setting up BatchNorm3
I0218 21:03:21.437587 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.437589 31980 net.cpp:165] Memory required for data: 8337280
I0218 21:03:21.437597 31980 layer_factory.hpp:77] Creating layer Scale3
I0218 21:03:21.437602 31980 net.cpp:100] Creating Layer Scale3
I0218 21:03:21.437605 31980 net.cpp:444] Scale3 <- Convolution3
I0218 21:03:21.437609 31980 net.cpp:405] Scale3 -> Convolution3 (in-place)
I0218 21:03:21.437645 31980 layer_factory.hpp:77] Creating layer Scale3
I0218 21:03:21.437749 31980 net.cpp:150] Setting up Scale3
I0218 21:03:21.437755 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.437758 31980 net.cpp:165] Memory required for data: 9014400
I0218 21:03:21.437762 31980 layer_factory.hpp:77] Creating layer Eltwise1
I0218 21:03:21.437768 31980 net.cpp:100] Creating Layer Eltwise1
I0218 21:03:21.437772 31980 net.cpp:444] Eltwise1 <- Convolution1_ReLU1_0_split_1
I0218 21:03:21.437775 31980 net.cpp:444] Eltwise1 <- Convolution3
I0218 21:03:21.437779 31980 net.cpp:418] Eltwise1 -> Eltwise1
I0218 21:03:21.437803 31980 net.cpp:150] Setting up Eltwise1
I0218 21:03:21.437808 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.437811 31980 net.cpp:165] Memory required for data: 9691520
I0218 21:03:21.437813 31980 layer_factory.hpp:77] Creating layer ReLU3
I0218 21:03:21.437819 31980 net.cpp:100] Creating Layer ReLU3
I0218 21:03:21.437820 31980 net.cpp:444] ReLU3 <- Eltwise1
I0218 21:03:21.437824 31980 net.cpp:405] ReLU3 -> Eltwise1 (in-place)
I0218 21:03:21.437964 31980 net.cpp:150] Setting up ReLU3
I0218 21:03:21.437973 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.437975 31980 net.cpp:165] Memory required for data: 10368640
I0218 21:03:21.437978 31980 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I0218 21:03:21.437984 31980 net.cpp:100] Creating Layer Eltwise1_ReLU3_0_split
I0218 21:03:21.437988 31980 net.cpp:444] Eltwise1_ReLU3_0_split <- Eltwise1
I0218 21:03:21.437991 31980 net.cpp:418] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I0218 21:03:21.437996 31980 net.cpp:418] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I0218 21:03:21.438035 31980 net.cpp:150] Setting up Eltwise1_ReLU3_0_split
I0218 21:03:21.438040 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.438043 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.438045 31980 net.cpp:165] Memory required for data: 11722880
I0218 21:03:21.438048 31980 layer_factory.hpp:77] Creating layer Convolution4
I0218 21:03:21.438055 31980 net.cpp:100] Creating Layer Convolution4
I0218 21:03:21.438058 31980 net.cpp:444] Convolution4 <- Eltwise1_ReLU3_0_split_0
I0218 21:03:21.438063 31980 net.cpp:418] Convolution4 -> Convolution4
I0218 21:03:21.439492 31980 net.cpp:150] Setting up Convolution4
I0218 21:03:21.439507 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.439509 31980 net.cpp:165] Memory required for data: 12400000
I0218 21:03:21.439514 31980 layer_factory.hpp:77] Creating layer BatchNorm4
I0218 21:03:21.439522 31980 net.cpp:100] Creating Layer BatchNorm4
I0218 21:03:21.439524 31980 net.cpp:444] BatchNorm4 <- Convolution4
I0218 21:03:21.439537 31980 net.cpp:405] BatchNorm4 -> Convolution4 (in-place)
I0218 21:03:21.439725 31980 net.cpp:150] Setting up BatchNorm4
I0218 21:03:21.439733 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.439734 31980 net.cpp:165] Memory required for data: 13077120
I0218 21:03:21.439741 31980 layer_factory.hpp:77] Creating layer Scale4
I0218 21:03:21.439748 31980 net.cpp:100] Creating Layer Scale4
I0218 21:03:21.439750 31980 net.cpp:444] Scale4 <- Convolution4
I0218 21:03:21.439754 31980 net.cpp:405] Scale4 -> Convolution4 (in-place)
I0218 21:03:21.439798 31980 layer_factory.hpp:77] Creating layer Scale4
I0218 21:03:21.439920 31980 net.cpp:150] Setting up Scale4
I0218 21:03:21.439927 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.439930 31980 net.cpp:165] Memory required for data: 13754240
I0218 21:03:21.439935 31980 layer_factory.hpp:77] Creating layer ReLU4
I0218 21:03:21.439941 31980 net.cpp:100] Creating Layer ReLU4
I0218 21:03:21.439944 31980 net.cpp:444] ReLU4 <- Convolution4
I0218 21:03:21.439947 31980 net.cpp:405] ReLU4 -> Convolution4 (in-place)
I0218 21:03:21.440098 31980 net.cpp:150] Setting up ReLU4
I0218 21:03:21.440105 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.440109 31980 net.cpp:165] Memory required for data: 14431360
I0218 21:03:21.440110 31980 layer_factory.hpp:77] Creating layer Convolution5
I0218 21:03:21.440120 31980 net.cpp:100] Creating Layer Convolution5
I0218 21:03:21.440124 31980 net.cpp:444] Convolution5 <- Convolution4
I0218 21:03:21.440129 31980 net.cpp:418] Convolution5 -> Convolution5
I0218 21:03:21.441567 31980 net.cpp:150] Setting up Convolution5
I0218 21:03:21.441581 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.441584 31980 net.cpp:165] Memory required for data: 15108480
I0218 21:03:21.441591 31980 layer_factory.hpp:77] Creating layer BatchNorm5
I0218 21:03:21.441596 31980 net.cpp:100] Creating Layer BatchNorm5
I0218 21:03:21.441598 31980 net.cpp:444] BatchNorm5 <- Convolution5
I0218 21:03:21.441604 31980 net.cpp:405] BatchNorm5 -> Convolution5 (in-place)
I0218 21:03:21.441793 31980 net.cpp:150] Setting up BatchNorm5
I0218 21:03:21.441799 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.441802 31980 net.cpp:165] Memory required for data: 15785600
I0218 21:03:21.441812 31980 layer_factory.hpp:77] Creating layer Scale5
I0218 21:03:21.441817 31980 net.cpp:100] Creating Layer Scale5
I0218 21:03:21.441819 31980 net.cpp:444] Scale5 <- Convolution5
I0218 21:03:21.441823 31980 net.cpp:405] Scale5 -> Convolution5 (in-place)
I0218 21:03:21.441864 31980 layer_factory.hpp:77] Creating layer Scale5
I0218 21:03:21.441978 31980 net.cpp:150] Setting up Scale5
I0218 21:03:21.441985 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.441988 31980 net.cpp:165] Memory required for data: 16462720
I0218 21:03:21.441992 31980 layer_factory.hpp:77] Creating layer Eltwise2
I0218 21:03:21.441998 31980 net.cpp:100] Creating Layer Eltwise2
I0218 21:03:21.442001 31980 net.cpp:444] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I0218 21:03:21.442005 31980 net.cpp:444] Eltwise2 <- Convolution5
I0218 21:03:21.442009 31980 net.cpp:418] Eltwise2 -> Eltwise2
I0218 21:03:21.442034 31980 net.cpp:150] Setting up Eltwise2
I0218 21:03:21.442039 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.442042 31980 net.cpp:165] Memory required for data: 17139840
I0218 21:03:21.442045 31980 layer_factory.hpp:77] Creating layer ReLU5
I0218 21:03:21.442049 31980 net.cpp:100] Creating Layer ReLU5
I0218 21:03:21.442052 31980 net.cpp:444] ReLU5 <- Eltwise2
I0218 21:03:21.442056 31980 net.cpp:405] ReLU5 -> Eltwise2 (in-place)
I0218 21:03:21.442582 31980 net.cpp:150] Setting up ReLU5
I0218 21:03:21.442593 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.442596 31980 net.cpp:165] Memory required for data: 17816960
I0218 21:03:21.442600 31980 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I0218 21:03:21.442605 31980 net.cpp:100] Creating Layer Eltwise2_ReLU5_0_split
I0218 21:03:21.442608 31980 net.cpp:444] Eltwise2_ReLU5_0_split <- Eltwise2
I0218 21:03:21.442613 31980 net.cpp:418] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I0218 21:03:21.442620 31980 net.cpp:418] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I0218 21:03:21.442663 31980 net.cpp:150] Setting up Eltwise2_ReLU5_0_split
I0218 21:03:21.442670 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.442673 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.442677 31980 net.cpp:165] Memory required for data: 19171200
I0218 21:03:21.442682 31980 layer_factory.hpp:77] Creating layer Convolution6
I0218 21:03:21.442695 31980 net.cpp:100] Creating Layer Convolution6
I0218 21:03:21.442699 31980 net.cpp:444] Convolution6 <- Eltwise2_ReLU5_0_split_0
I0218 21:03:21.442704 31980 net.cpp:418] Convolution6 -> Convolution6
I0218 21:03:21.444535 31980 net.cpp:150] Setting up Convolution6
I0218 21:03:21.444548 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.444551 31980 net.cpp:165] Memory required for data: 19848320
I0218 21:03:21.444557 31980 layer_factory.hpp:77] Creating layer BatchNorm6
I0218 21:03:21.444563 31980 net.cpp:100] Creating Layer BatchNorm6
I0218 21:03:21.444567 31980 net.cpp:444] BatchNorm6 <- Convolution6
I0218 21:03:21.444571 31980 net.cpp:405] BatchNorm6 -> Convolution6 (in-place)
I0218 21:03:21.444761 31980 net.cpp:150] Setting up BatchNorm6
I0218 21:03:21.444768 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.444772 31980 net.cpp:165] Memory required for data: 20525440
I0218 21:03:21.444777 31980 layer_factory.hpp:77] Creating layer Scale6
I0218 21:03:21.444782 31980 net.cpp:100] Creating Layer Scale6
I0218 21:03:21.444785 31980 net.cpp:444] Scale6 <- Convolution6
I0218 21:03:21.444788 31980 net.cpp:405] Scale6 -> Convolution6 (in-place)
I0218 21:03:21.444830 31980 layer_factory.hpp:77] Creating layer Scale6
I0218 21:03:21.444947 31980 net.cpp:150] Setting up Scale6
I0218 21:03:21.444953 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.444957 31980 net.cpp:165] Memory required for data: 21202560
I0218 21:03:21.444960 31980 layer_factory.hpp:77] Creating layer ReLU6
I0218 21:03:21.444967 31980 net.cpp:100] Creating Layer ReLU6
I0218 21:03:21.444969 31980 net.cpp:444] ReLU6 <- Convolution6
I0218 21:03:21.444973 31980 net.cpp:405] ReLU6 -> Convolution6 (in-place)
I0218 21:03:21.445122 31980 net.cpp:150] Setting up ReLU6
I0218 21:03:21.445132 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.445134 31980 net.cpp:165] Memory required for data: 21879680
I0218 21:03:21.445137 31980 layer_factory.hpp:77] Creating layer Convolution7
I0218 21:03:21.445145 31980 net.cpp:100] Creating Layer Convolution7
I0218 21:03:21.445148 31980 net.cpp:444] Convolution7 <- Convolution6
I0218 21:03:21.445153 31980 net.cpp:418] Convolution7 -> Convolution7
I0218 21:03:21.446606 31980 net.cpp:150] Setting up Convolution7
I0218 21:03:21.446619 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.446624 31980 net.cpp:165] Memory required for data: 22556800
I0218 21:03:21.446629 31980 layer_factory.hpp:77] Creating layer BatchNorm7
I0218 21:03:21.446640 31980 net.cpp:100] Creating Layer BatchNorm7
I0218 21:03:21.446642 31980 net.cpp:444] BatchNorm7 <- Convolution7
I0218 21:03:21.446647 31980 net.cpp:405] BatchNorm7 -> Convolution7 (in-place)
I0218 21:03:21.446835 31980 net.cpp:150] Setting up BatchNorm7
I0218 21:03:21.446841 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.446843 31980 net.cpp:165] Memory required for data: 23233920
I0218 21:03:21.446851 31980 layer_factory.hpp:77] Creating layer Scale7
I0218 21:03:21.446854 31980 net.cpp:100] Creating Layer Scale7
I0218 21:03:21.446857 31980 net.cpp:444] Scale7 <- Convolution7
I0218 21:03:21.446861 31980 net.cpp:405] Scale7 -> Convolution7 (in-place)
I0218 21:03:21.446902 31980 layer_factory.hpp:77] Creating layer Scale7
I0218 21:03:21.447019 31980 net.cpp:150] Setting up Scale7
I0218 21:03:21.447026 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.447028 31980 net.cpp:165] Memory required for data: 23911040
I0218 21:03:21.447033 31980 layer_factory.hpp:77] Creating layer Eltwise3
I0218 21:03:21.447038 31980 net.cpp:100] Creating Layer Eltwise3
I0218 21:03:21.447041 31980 net.cpp:444] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I0218 21:03:21.447044 31980 net.cpp:444] Eltwise3 <- Convolution7
I0218 21:03:21.447051 31980 net.cpp:418] Eltwise3 -> Eltwise3
I0218 21:03:21.447074 31980 net.cpp:150] Setting up Eltwise3
I0218 21:03:21.447080 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.447088 31980 net.cpp:165] Memory required for data: 24588160
I0218 21:03:21.447094 31980 layer_factory.hpp:77] Creating layer ReLU7
I0218 21:03:21.447099 31980 net.cpp:100] Creating Layer ReLU7
I0218 21:03:21.447103 31980 net.cpp:444] ReLU7 <- Eltwise3
I0218 21:03:21.447105 31980 net.cpp:405] ReLU7 -> Eltwise3 (in-place)
I0218 21:03:21.447257 31980 net.cpp:150] Setting up ReLU7
I0218 21:03:21.447268 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.447270 31980 net.cpp:165] Memory required for data: 25265280
I0218 21:03:21.447273 31980 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I0218 21:03:21.447278 31980 net.cpp:100] Creating Layer Eltwise3_ReLU7_0_split
I0218 21:03:21.447281 31980 net.cpp:444] Eltwise3_ReLU7_0_split <- Eltwise3
I0218 21:03:21.447286 31980 net.cpp:418] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I0218 21:03:21.447291 31980 net.cpp:418] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I0218 21:03:21.447333 31980 net.cpp:150] Setting up Eltwise3_ReLU7_0_split
I0218 21:03:21.447338 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.447342 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.447345 31980 net.cpp:165] Memory required for data: 26619520
I0218 21:03:21.447347 31980 layer_factory.hpp:77] Creating layer Convolution8
I0218 21:03:21.447356 31980 net.cpp:100] Creating Layer Convolution8
I0218 21:03:21.447360 31980 net.cpp:444] Convolution8 <- Eltwise3_ReLU7_0_split_0
I0218 21:03:21.447363 31980 net.cpp:418] Convolution8 -> Convolution8
I0218 21:03:21.448828 31980 net.cpp:150] Setting up Convolution8
I0218 21:03:21.448843 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.448845 31980 net.cpp:165] Memory required for data: 27296640
I0218 21:03:21.448851 31980 layer_factory.hpp:77] Creating layer BatchNorm8
I0218 21:03:21.448856 31980 net.cpp:100] Creating Layer BatchNorm8
I0218 21:03:21.448860 31980 net.cpp:444] BatchNorm8 <- Convolution8
I0218 21:03:21.448866 31980 net.cpp:405] BatchNorm8 -> Convolution8 (in-place)
I0218 21:03:21.449057 31980 net.cpp:150] Setting up BatchNorm8
I0218 21:03:21.449064 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.449067 31980 net.cpp:165] Memory required for data: 27973760
I0218 21:03:21.449072 31980 layer_factory.hpp:77] Creating layer Scale8
I0218 21:03:21.449077 31980 net.cpp:100] Creating Layer Scale8
I0218 21:03:21.449080 31980 net.cpp:444] Scale8 <- Convolution8
I0218 21:03:21.449085 31980 net.cpp:405] Scale8 -> Convolution8 (in-place)
I0218 21:03:21.449124 31980 layer_factory.hpp:77] Creating layer Scale8
I0218 21:03:21.449239 31980 net.cpp:150] Setting up Scale8
I0218 21:03:21.449246 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.449249 31980 net.cpp:165] Memory required for data: 28650880
I0218 21:03:21.449254 31980 layer_factory.hpp:77] Creating layer ReLU8
I0218 21:03:21.449259 31980 net.cpp:100] Creating Layer ReLU8
I0218 21:03:21.449261 31980 net.cpp:444] ReLU8 <- Convolution8
I0218 21:03:21.449266 31980 net.cpp:405] ReLU8 -> Convolution8 (in-place)
I0218 21:03:21.449795 31980 net.cpp:150] Setting up ReLU8
I0218 21:03:21.449805 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.449810 31980 net.cpp:165] Memory required for data: 29328000
I0218 21:03:21.449812 31980 layer_factory.hpp:77] Creating layer Convolution9
I0218 21:03:21.449820 31980 net.cpp:100] Creating Layer Convolution9
I0218 21:03:21.449825 31980 net.cpp:444] Convolution9 <- Convolution8
I0218 21:03:21.449831 31980 net.cpp:418] Convolution9 -> Convolution9
I0218 21:03:21.451294 31980 net.cpp:150] Setting up Convolution9
I0218 21:03:21.451308 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.451310 31980 net.cpp:165] Memory required for data: 30005120
I0218 21:03:21.451316 31980 layer_factory.hpp:77] Creating layer BatchNorm9
I0218 21:03:21.451321 31980 net.cpp:100] Creating Layer BatchNorm9
I0218 21:03:21.451324 31980 net.cpp:444] BatchNorm9 <- Convolution9
I0218 21:03:21.451329 31980 net.cpp:405] BatchNorm9 -> Convolution9 (in-place)
I0218 21:03:21.451527 31980 net.cpp:150] Setting up BatchNorm9
I0218 21:03:21.451545 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.451548 31980 net.cpp:165] Memory required for data: 30682240
I0218 21:03:21.451555 31980 layer_factory.hpp:77] Creating layer Scale9
I0218 21:03:21.451560 31980 net.cpp:100] Creating Layer Scale9
I0218 21:03:21.451563 31980 net.cpp:444] Scale9 <- Convolution9
I0218 21:03:21.451568 31980 net.cpp:405] Scale9 -> Convolution9 (in-place)
I0218 21:03:21.451611 31980 layer_factory.hpp:77] Creating layer Scale9
I0218 21:03:21.451731 31980 net.cpp:150] Setting up Scale9
I0218 21:03:21.451738 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.451740 31980 net.cpp:165] Memory required for data: 31359360
I0218 21:03:21.451745 31980 layer_factory.hpp:77] Creating layer Eltwise4
I0218 21:03:21.451750 31980 net.cpp:100] Creating Layer Eltwise4
I0218 21:03:21.451753 31980 net.cpp:444] Eltwise4 <- Eltwise3_ReLU7_0_split_1
I0218 21:03:21.451757 31980 net.cpp:444] Eltwise4 <- Convolution9
I0218 21:03:21.451762 31980 net.cpp:418] Eltwise4 -> Eltwise4
I0218 21:03:21.451789 31980 net.cpp:150] Setting up Eltwise4
I0218 21:03:21.451794 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.451797 31980 net.cpp:165] Memory required for data: 32036480
I0218 21:03:21.451799 31980 layer_factory.hpp:77] Creating layer ReLU9
I0218 21:03:21.451804 31980 net.cpp:100] Creating Layer ReLU9
I0218 21:03:21.451807 31980 net.cpp:444] ReLU9 <- Eltwise4
I0218 21:03:21.451812 31980 net.cpp:405] ReLU9 -> Eltwise4 (in-place)
I0218 21:03:21.451962 31980 net.cpp:150] Setting up ReLU9
I0218 21:03:21.451972 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.451973 31980 net.cpp:165] Memory required for data: 32713600
I0218 21:03:21.451977 31980 layer_factory.hpp:77] Creating layer Eltwise4_ReLU9_0_split
I0218 21:03:21.451982 31980 net.cpp:100] Creating Layer Eltwise4_ReLU9_0_split
I0218 21:03:21.451984 31980 net.cpp:444] Eltwise4_ReLU9_0_split <- Eltwise4
I0218 21:03:21.451989 31980 net.cpp:418] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_0
I0218 21:03:21.451995 31980 net.cpp:418] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_1
I0218 21:03:21.452039 31980 net.cpp:150] Setting up Eltwise4_ReLU9_0_split
I0218 21:03:21.452044 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.452047 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.452050 31980 net.cpp:165] Memory required for data: 34067840
I0218 21:03:21.452052 31980 layer_factory.hpp:77] Creating layer Convolution10
I0218 21:03:21.452061 31980 net.cpp:100] Creating Layer Convolution10
I0218 21:03:21.452064 31980 net.cpp:444] Convolution10 <- Eltwise4_ReLU9_0_split_0
I0218 21:03:21.452069 31980 net.cpp:418] Convolution10 -> Convolution10
I0218 21:03:21.453536 31980 net.cpp:150] Setting up Convolution10
I0218 21:03:21.453548 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.453552 31980 net.cpp:165] Memory required for data: 34744960
I0218 21:03:21.453564 31980 layer_factory.hpp:77] Creating layer BatchNorm10
I0218 21:03:21.453570 31980 net.cpp:100] Creating Layer BatchNorm10
I0218 21:03:21.453575 31980 net.cpp:444] BatchNorm10 <- Convolution10
I0218 21:03:21.453579 31980 net.cpp:405] BatchNorm10 -> Convolution10 (in-place)
I0218 21:03:21.453778 31980 net.cpp:150] Setting up BatchNorm10
I0218 21:03:21.453785 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.453788 31980 net.cpp:165] Memory required for data: 35422080
I0218 21:03:21.453794 31980 layer_factory.hpp:77] Creating layer Scale10
I0218 21:03:21.453800 31980 net.cpp:100] Creating Layer Scale10
I0218 21:03:21.453804 31980 net.cpp:444] Scale10 <- Convolution10
I0218 21:03:21.453807 31980 net.cpp:405] Scale10 -> Convolution10 (in-place)
I0218 21:03:21.453848 31980 layer_factory.hpp:77] Creating layer Scale10
I0218 21:03:21.453968 31980 net.cpp:150] Setting up Scale10
I0218 21:03:21.453974 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.453976 31980 net.cpp:165] Memory required for data: 36099200
I0218 21:03:21.453984 31980 layer_factory.hpp:77] Creating layer ReLU10
I0218 21:03:21.453994 31980 net.cpp:100] Creating Layer ReLU10
I0218 21:03:21.453997 31980 net.cpp:444] ReLU10 <- Convolution10
I0218 21:03:21.454002 31980 net.cpp:405] ReLU10 -> Convolution10 (in-place)
I0218 21:03:21.454155 31980 net.cpp:150] Setting up ReLU10
I0218 21:03:21.454164 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.454165 31980 net.cpp:165] Memory required for data: 36776320
I0218 21:03:21.454169 31980 layer_factory.hpp:77] Creating layer Convolution11
I0218 21:03:21.454177 31980 net.cpp:100] Creating Layer Convolution11
I0218 21:03:21.454180 31980 net.cpp:444] Convolution11 <- Convolution10
I0218 21:03:21.454186 31980 net.cpp:418] Convolution11 -> Convolution11
I0218 21:03:21.455665 31980 net.cpp:150] Setting up Convolution11
I0218 21:03:21.455678 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.455682 31980 net.cpp:165] Memory required for data: 37453440
I0218 21:03:21.455687 31980 layer_factory.hpp:77] Creating layer BatchNorm11
I0218 21:03:21.455695 31980 net.cpp:100] Creating Layer BatchNorm11
I0218 21:03:21.455699 31980 net.cpp:444] BatchNorm11 <- Convolution11
I0218 21:03:21.455703 31980 net.cpp:405] BatchNorm11 -> Convolution11 (in-place)
I0218 21:03:21.455899 31980 net.cpp:150] Setting up BatchNorm11
I0218 21:03:21.455906 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.455909 31980 net.cpp:165] Memory required for data: 38130560
I0218 21:03:21.455914 31980 layer_factory.hpp:77] Creating layer Scale11
I0218 21:03:21.455919 31980 net.cpp:100] Creating Layer Scale11
I0218 21:03:21.455924 31980 net.cpp:444] Scale11 <- Convolution11
I0218 21:03:21.455926 31980 net.cpp:405] Scale11 -> Convolution11 (in-place)
I0218 21:03:21.455967 31980 layer_factory.hpp:77] Creating layer Scale11
I0218 21:03:21.456086 31980 net.cpp:150] Setting up Scale11
I0218 21:03:21.456094 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.456096 31980 net.cpp:165] Memory required for data: 38807680
I0218 21:03:21.456101 31980 layer_factory.hpp:77] Creating layer Eltwise5
I0218 21:03:21.456107 31980 net.cpp:100] Creating Layer Eltwise5
I0218 21:03:21.456110 31980 net.cpp:444] Eltwise5 <- Eltwise4_ReLU9_0_split_1
I0218 21:03:21.456115 31980 net.cpp:444] Eltwise5 <- Convolution11
I0218 21:03:21.456118 31980 net.cpp:418] Eltwise5 -> Eltwise5
I0218 21:03:21.456145 31980 net.cpp:150] Setting up Eltwise5
I0218 21:03:21.456151 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.456152 31980 net.cpp:165] Memory required for data: 39484800
I0218 21:03:21.456156 31980 layer_factory.hpp:77] Creating layer ReLU11
I0218 21:03:21.456159 31980 net.cpp:100] Creating Layer ReLU11
I0218 21:03:21.456162 31980 net.cpp:444] ReLU11 <- Eltwise5
I0218 21:03:21.456169 31980 net.cpp:405] ReLU11 -> Eltwise5 (in-place)
I0218 21:03:21.456697 31980 net.cpp:150] Setting up ReLU11
I0218 21:03:21.456709 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.456712 31980 net.cpp:165] Memory required for data: 40161920
I0218 21:03:21.456715 31980 layer_factory.hpp:77] Creating layer Eltwise5_ReLU11_0_split
I0218 21:03:21.456722 31980 net.cpp:100] Creating Layer Eltwise5_ReLU11_0_split
I0218 21:03:21.456725 31980 net.cpp:444] Eltwise5_ReLU11_0_split <- Eltwise5
I0218 21:03:21.456730 31980 net.cpp:418] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_0
I0218 21:03:21.456737 31980 net.cpp:418] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_1
I0218 21:03:21.456743 31980 net.cpp:418] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_2
I0218 21:03:21.456800 31980 net.cpp:150] Setting up Eltwise5_ReLU11_0_split
I0218 21:03:21.456807 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.456810 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.456813 31980 net.cpp:157] Top shape: 20 16 23 23 (169280)
I0218 21:03:21.456816 31980 net.cpp:165] Memory required for data: 42193280
I0218 21:03:21.456820 31980 layer_factory.hpp:77] Creating layer Convolution18
I0218 21:03:21.456828 31980 net.cpp:100] Creating Layer Convolution18
I0218 21:03:21.456840 31980 net.cpp:444] Convolution18 <- Eltwise5_ReLU11_0_split_0
I0218 21:03:21.456845 31980 net.cpp:418] Convolution18 -> Convolution18
I0218 21:03:21.458333 31980 net.cpp:150] Setting up Convolution18
I0218 21:03:21.458345 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.458348 31980 net.cpp:165] Memory required for data: 42561920
I0218 21:03:21.458353 31980 layer_factory.hpp:77] Creating layer BatchNorm18
I0218 21:03:21.458360 31980 net.cpp:100] Creating Layer BatchNorm18
I0218 21:03:21.458364 31980 net.cpp:444] BatchNorm18 <- Convolution18
I0218 21:03:21.458369 31980 net.cpp:405] BatchNorm18 -> Convolution18 (in-place)
I0218 21:03:21.458562 31980 net.cpp:150] Setting up BatchNorm18
I0218 21:03:21.458570 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.458572 31980 net.cpp:165] Memory required for data: 42930560
I0218 21:03:21.458577 31980 layer_factory.hpp:77] Creating layer Scale18
I0218 21:03:21.458582 31980 net.cpp:100] Creating Layer Scale18
I0218 21:03:21.458586 31980 net.cpp:444] Scale18 <- Convolution18
I0218 21:03:21.458590 31980 net.cpp:405] Scale18 -> Convolution18 (in-place)
I0218 21:03:21.458631 31980 layer_factory.hpp:77] Creating layer Scale18
I0218 21:03:21.458745 31980 net.cpp:150] Setting up Scale18
I0218 21:03:21.458753 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.458755 31980 net.cpp:165] Memory required for data: 43299200
I0218 21:03:21.458760 31980 layer_factory.hpp:77] Creating layer Convolution19
I0218 21:03:21.458768 31980 net.cpp:100] Creating Layer Convolution19
I0218 21:03:21.458772 31980 net.cpp:444] Convolution19 <- Eltwise5_ReLU11_0_split_1
I0218 21:03:21.458777 31980 net.cpp:418] Convolution19 -> Convolution19
I0218 21:03:21.459930 31980 net.cpp:150] Setting up Convolution19
I0218 21:03:21.459944 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.459947 31980 net.cpp:165] Memory required for data: 43667840
I0218 21:03:21.459952 31980 layer_factory.hpp:77] Creating layer BatchNorm19
I0218 21:03:21.459959 31980 net.cpp:100] Creating Layer BatchNorm19
I0218 21:03:21.459962 31980 net.cpp:444] BatchNorm19 <- Convolution19
I0218 21:03:21.459969 31980 net.cpp:405] BatchNorm19 -> Convolution19 (in-place)
I0218 21:03:21.460494 31980 net.cpp:150] Setting up BatchNorm19
I0218 21:03:21.460505 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.460507 31980 net.cpp:165] Memory required for data: 44036480
I0218 21:03:21.460515 31980 layer_factory.hpp:77] Creating layer Scale19
I0218 21:03:21.460520 31980 net.cpp:100] Creating Layer Scale19
I0218 21:03:21.460523 31980 net.cpp:444] Scale19 <- Convolution19
I0218 21:03:21.460527 31980 net.cpp:405] Scale19 -> Convolution19 (in-place)
I0218 21:03:21.460561 31980 layer_factory.hpp:77] Creating layer Scale19
I0218 21:03:21.460641 31980 net.cpp:150] Setting up Scale19
I0218 21:03:21.460647 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.460649 31980 net.cpp:165] Memory required for data: 44405120
I0218 21:03:21.460654 31980 layer_factory.hpp:77] Creating layer ReLU18
I0218 21:03:21.460659 31980 net.cpp:100] Creating Layer ReLU18
I0218 21:03:21.460662 31980 net.cpp:444] ReLU18 <- Convolution19
I0218 21:03:21.460665 31980 net.cpp:405] ReLU18 -> Convolution19 (in-place)
I0218 21:03:21.461199 31980 net.cpp:150] Setting up ReLU18
I0218 21:03:21.461211 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.461213 31980 net.cpp:165] Memory required for data: 44773760
I0218 21:03:21.461216 31980 layer_factory.hpp:77] Creating layer Convolution20
I0218 21:03:21.461228 31980 net.cpp:100] Creating Layer Convolution20
I0218 21:03:21.461232 31980 net.cpp:444] Convolution20 <- Convolution19
I0218 21:03:21.461238 31980 net.cpp:418] Convolution20 -> Convolution20
I0218 21:03:21.463423 31980 net.cpp:150] Setting up Convolution20
I0218 21:03:21.463436 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.463439 31980 net.cpp:165] Memory required for data: 45142400
I0218 21:03:21.463445 31980 layer_factory.hpp:77] Creating layer BatchNorm20
I0218 21:03:21.463459 31980 net.cpp:100] Creating Layer BatchNorm20
I0218 21:03:21.463464 31980 net.cpp:444] BatchNorm20 <- Convolution20
I0218 21:03:21.463469 31980 net.cpp:405] BatchNorm20 -> Convolution20 (in-place)
I0218 21:03:21.463618 31980 net.cpp:150] Setting up BatchNorm20
I0218 21:03:21.463625 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.463629 31980 net.cpp:165] Memory required for data: 45511040
I0218 21:03:21.463634 31980 layer_factory.hpp:77] Creating layer Scale20
I0218 21:03:21.463639 31980 net.cpp:100] Creating Layer Scale20
I0218 21:03:21.463642 31980 net.cpp:444] Scale20 <- Convolution20
I0218 21:03:21.463646 31980 net.cpp:405] Scale20 -> Convolution20 (in-place)
I0218 21:03:21.463675 31980 layer_factory.hpp:77] Creating layer Scale20
I0218 21:03:21.463758 31980 net.cpp:150] Setting up Scale20
I0218 21:03:21.463764 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.463768 31980 net.cpp:165] Memory required for data: 45879680
I0218 21:03:21.463771 31980 layer_factory.hpp:77] Creating layer Eltwise9
I0218 21:03:21.463778 31980 net.cpp:100] Creating Layer Eltwise9
I0218 21:03:21.463780 31980 net.cpp:444] Eltwise9 <- Convolution18
I0218 21:03:21.463784 31980 net.cpp:444] Eltwise9 <- Convolution20
I0218 21:03:21.463788 31980 net.cpp:418] Eltwise9 -> Eltwise9
I0218 21:03:21.463805 31980 net.cpp:150] Setting up Eltwise9
I0218 21:03:21.463810 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.463814 31980 net.cpp:165] Memory required for data: 46248320
I0218 21:03:21.463815 31980 layer_factory.hpp:77] Creating layer ReLU19
I0218 21:03:21.463819 31980 net.cpp:100] Creating Layer ReLU19
I0218 21:03:21.463822 31980 net.cpp:444] ReLU19 <- Eltwise9
I0218 21:03:21.463826 31980 net.cpp:405] ReLU19 -> Eltwise9 (in-place)
I0218 21:03:21.463990 31980 net.cpp:150] Setting up ReLU19
I0218 21:03:21.463999 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.464001 31980 net.cpp:165] Memory required for data: 46616960
I0218 21:03:21.464005 31980 layer_factory.hpp:77] Creating layer Eltwise9_ReLU19_0_split
I0218 21:03:21.464011 31980 net.cpp:100] Creating Layer Eltwise9_ReLU19_0_split
I0218 21:03:21.464015 31980 net.cpp:444] Eltwise9_ReLU19_0_split <- Eltwise9
I0218 21:03:21.464018 31980 net.cpp:418] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_0
I0218 21:03:21.464025 31980 net.cpp:418] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_1
I0218 21:03:21.464054 31980 net.cpp:150] Setting up Eltwise9_ReLU19_0_split
I0218 21:03:21.464059 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.464062 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.464066 31980 net.cpp:165] Memory required for data: 47354240
I0218 21:03:21.464068 31980 layer_factory.hpp:77] Creating layer Convolution21
I0218 21:03:21.464076 31980 net.cpp:100] Creating Layer Convolution21
I0218 21:03:21.464079 31980 net.cpp:444] Convolution21 <- Eltwise9_ReLU19_0_split_0
I0218 21:03:21.464085 31980 net.cpp:418] Convolution21 -> Convolution21
I0218 21:03:21.465559 31980 net.cpp:150] Setting up Convolution21
I0218 21:03:21.465571 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.465574 31980 net.cpp:165] Memory required for data: 47722880
I0218 21:03:21.465580 31980 layer_factory.hpp:77] Creating layer BatchNorm21
I0218 21:03:21.465587 31980 net.cpp:100] Creating Layer BatchNorm21
I0218 21:03:21.465590 31980 net.cpp:444] BatchNorm21 <- Convolution21
I0218 21:03:21.465595 31980 net.cpp:405] BatchNorm21 -> Convolution21 (in-place)
I0218 21:03:21.465736 31980 net.cpp:150] Setting up BatchNorm21
I0218 21:03:21.465744 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.465745 31980 net.cpp:165] Memory required for data: 48091520
I0218 21:03:21.465751 31980 layer_factory.hpp:77] Creating layer Scale21
I0218 21:03:21.465756 31980 net.cpp:100] Creating Layer Scale21
I0218 21:03:21.465759 31980 net.cpp:444] Scale21 <- Convolution21
I0218 21:03:21.465764 31980 net.cpp:405] Scale21 -> Convolution21 (in-place)
I0218 21:03:21.465797 31980 layer_factory.hpp:77] Creating layer Scale21
I0218 21:03:21.465888 31980 net.cpp:150] Setting up Scale21
I0218 21:03:21.465896 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.465899 31980 net.cpp:165] Memory required for data: 48460160
I0218 21:03:21.465904 31980 layer_factory.hpp:77] Creating layer ReLU20
I0218 21:03:21.465909 31980 net.cpp:100] Creating Layer ReLU20
I0218 21:03:21.465912 31980 net.cpp:444] ReLU20 <- Convolution21
I0218 21:03:21.465915 31980 net.cpp:405] ReLU20 -> Convolution21 (in-place)
I0218 21:03:21.466447 31980 net.cpp:150] Setting up ReLU20
I0218 21:03:21.466459 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.466461 31980 net.cpp:165] Memory required for data: 48828800
I0218 21:03:21.466464 31980 layer_factory.hpp:77] Creating layer Convolution22
I0218 21:03:21.466475 31980 net.cpp:100] Creating Layer Convolution22
I0218 21:03:21.466478 31980 net.cpp:444] Convolution22 <- Convolution21
I0218 21:03:21.466483 31980 net.cpp:418] Convolution22 -> Convolution22
I0218 21:03:21.467597 31980 net.cpp:150] Setting up Convolution22
I0218 21:03:21.467609 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.467612 31980 net.cpp:165] Memory required for data: 49197440
I0218 21:03:21.467618 31980 layer_factory.hpp:77] Creating layer BatchNorm22
I0218 21:03:21.467624 31980 net.cpp:100] Creating Layer BatchNorm22
I0218 21:03:21.467628 31980 net.cpp:444] BatchNorm22 <- Convolution22
I0218 21:03:21.467633 31980 net.cpp:405] BatchNorm22 -> Convolution22 (in-place)
I0218 21:03:21.467775 31980 net.cpp:150] Setting up BatchNorm22
I0218 21:03:21.467782 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.467784 31980 net.cpp:165] Memory required for data: 49566080
I0218 21:03:21.467790 31980 layer_factory.hpp:77] Creating layer Scale22
I0218 21:03:21.467797 31980 net.cpp:100] Creating Layer Scale22
I0218 21:03:21.467799 31980 net.cpp:444] Scale22 <- Convolution22
I0218 21:03:21.467803 31980 net.cpp:405] Scale22 -> Convolution22 (in-place)
I0218 21:03:21.467833 31980 layer_factory.hpp:77] Creating layer Scale22
I0218 21:03:21.467916 31980 net.cpp:150] Setting up Scale22
I0218 21:03:21.467921 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.467924 31980 net.cpp:165] Memory required for data: 49934720
I0218 21:03:21.467929 31980 layer_factory.hpp:77] Creating layer Eltwise10
I0218 21:03:21.467933 31980 net.cpp:100] Creating Layer Eltwise10
I0218 21:03:21.467938 31980 net.cpp:444] Eltwise10 <- Eltwise9_ReLU19_0_split_1
I0218 21:03:21.467941 31980 net.cpp:444] Eltwise10 <- Convolution22
I0218 21:03:21.467945 31980 net.cpp:418] Eltwise10 -> Eltwise10
I0218 21:03:21.467963 31980 net.cpp:150] Setting up Eltwise10
I0218 21:03:21.467968 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.467970 31980 net.cpp:165] Memory required for data: 50303360
I0218 21:03:21.467973 31980 layer_factory.hpp:77] Creating layer ReLU21
I0218 21:03:21.467978 31980 net.cpp:100] Creating Layer ReLU21
I0218 21:03:21.467981 31980 net.cpp:444] ReLU21 <- Eltwise10
I0218 21:03:21.467984 31980 net.cpp:405] ReLU21 -> Eltwise10 (in-place)
I0218 21:03:21.468519 31980 net.cpp:150] Setting up ReLU21
I0218 21:03:21.468530 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.468533 31980 net.cpp:165] Memory required for data: 50672000
I0218 21:03:21.468536 31980 layer_factory.hpp:77] Creating layer Eltwise10_ReLU21_0_split
I0218 21:03:21.468542 31980 net.cpp:100] Creating Layer Eltwise10_ReLU21_0_split
I0218 21:03:21.468545 31980 net.cpp:444] Eltwise10_ReLU21_0_split <- Eltwise10
I0218 21:03:21.468551 31980 net.cpp:418] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_0
I0218 21:03:21.468557 31980 net.cpp:418] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_1
I0218 21:03:21.468591 31980 net.cpp:150] Setting up Eltwise10_ReLU21_0_split
I0218 21:03:21.468596 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.468600 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.468602 31980 net.cpp:165] Memory required for data: 51409280
I0218 21:03:21.468608 31980 layer_factory.hpp:77] Creating layer Convolution23
I0218 21:03:21.468621 31980 net.cpp:100] Creating Layer Convolution23
I0218 21:03:21.468626 31980 net.cpp:444] Convolution23 <- Eltwise10_ReLU21_0_split_0
I0218 21:03:21.468631 31980 net.cpp:418] Convolution23 -> Convolution23
I0218 21:03:21.470103 31980 net.cpp:150] Setting up Convolution23
I0218 21:03:21.470115 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.470118 31980 net.cpp:165] Memory required for data: 51777920
I0218 21:03:21.470124 31980 layer_factory.hpp:77] Creating layer BatchNorm23
I0218 21:03:21.470130 31980 net.cpp:100] Creating Layer BatchNorm23
I0218 21:03:21.470134 31980 net.cpp:444] BatchNorm23 <- Convolution23
I0218 21:03:21.470139 31980 net.cpp:405] BatchNorm23 -> Convolution23 (in-place)
I0218 21:03:21.470284 31980 net.cpp:150] Setting up BatchNorm23
I0218 21:03:21.470291 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.470294 31980 net.cpp:165] Memory required for data: 52146560
I0218 21:03:21.470299 31980 layer_factory.hpp:77] Creating layer Scale23
I0218 21:03:21.470304 31980 net.cpp:100] Creating Layer Scale23
I0218 21:03:21.470307 31980 net.cpp:444] Scale23 <- Convolution23
I0218 21:03:21.470311 31980 net.cpp:405] Scale23 -> Convolution23 (in-place)
I0218 21:03:21.470341 31980 layer_factory.hpp:77] Creating layer Scale23
I0218 21:03:21.470424 31980 net.cpp:150] Setting up Scale23
I0218 21:03:21.470430 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.470433 31980 net.cpp:165] Memory required for data: 52515200
I0218 21:03:21.470438 31980 layer_factory.hpp:77] Creating layer ReLU22
I0218 21:03:21.470443 31980 net.cpp:100] Creating Layer ReLU22
I0218 21:03:21.470445 31980 net.cpp:444] ReLU22 <- Convolution23
I0218 21:03:21.470449 31980 net.cpp:405] ReLU22 -> Convolution23 (in-place)
I0218 21:03:21.470605 31980 net.cpp:150] Setting up ReLU22
I0218 21:03:21.470613 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.470616 31980 net.cpp:165] Memory required for data: 52883840
I0218 21:03:21.470619 31980 layer_factory.hpp:77] Creating layer Convolution24
I0218 21:03:21.470628 31980 net.cpp:100] Creating Layer Convolution24
I0218 21:03:21.470630 31980 net.cpp:444] Convolution24 <- Convolution23
I0218 21:03:21.470636 31980 net.cpp:418] Convolution24 -> Convolution24
I0218 21:03:21.472115 31980 net.cpp:150] Setting up Convolution24
I0218 21:03:21.472127 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.472131 31980 net.cpp:165] Memory required for data: 53252480
I0218 21:03:21.472136 31980 layer_factory.hpp:77] Creating layer BatchNorm24
I0218 21:03:21.472143 31980 net.cpp:100] Creating Layer BatchNorm24
I0218 21:03:21.472146 31980 net.cpp:444] BatchNorm24 <- Convolution24
I0218 21:03:21.472151 31980 net.cpp:405] BatchNorm24 -> Convolution24 (in-place)
I0218 21:03:21.472296 31980 net.cpp:150] Setting up BatchNorm24
I0218 21:03:21.472303 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.472306 31980 net.cpp:165] Memory required for data: 53621120
I0218 21:03:21.472311 31980 layer_factory.hpp:77] Creating layer Scale24
I0218 21:03:21.472316 31980 net.cpp:100] Creating Layer Scale24
I0218 21:03:21.472319 31980 net.cpp:444] Scale24 <- Convolution24
I0218 21:03:21.472322 31980 net.cpp:405] Scale24 -> Convolution24 (in-place)
I0218 21:03:21.472354 31980 layer_factory.hpp:77] Creating layer Scale24
I0218 21:03:21.472437 31980 net.cpp:150] Setting up Scale24
I0218 21:03:21.472445 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.472447 31980 net.cpp:165] Memory required for data: 53989760
I0218 21:03:21.472452 31980 layer_factory.hpp:77] Creating layer Eltwise11
I0218 21:03:21.472457 31980 net.cpp:100] Creating Layer Eltwise11
I0218 21:03:21.472460 31980 net.cpp:444] Eltwise11 <- Eltwise10_ReLU21_0_split_1
I0218 21:03:21.472463 31980 net.cpp:444] Eltwise11 <- Convolution24
I0218 21:03:21.472467 31980 net.cpp:418] Eltwise11 -> Eltwise11
I0218 21:03:21.472486 31980 net.cpp:150] Setting up Eltwise11
I0218 21:03:21.472496 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.472502 31980 net.cpp:165] Memory required for data: 54358400
I0218 21:03:21.472506 31980 layer_factory.hpp:77] Creating layer ReLU23
I0218 21:03:21.472512 31980 net.cpp:100] Creating Layer ReLU23
I0218 21:03:21.472514 31980 net.cpp:444] ReLU23 <- Eltwise11
I0218 21:03:21.472518 31980 net.cpp:405] ReLU23 -> Eltwise11 (in-place)
I0218 21:03:21.473050 31980 net.cpp:150] Setting up ReLU23
I0218 21:03:21.473062 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.473065 31980 net.cpp:165] Memory required for data: 54727040
I0218 21:03:21.473068 31980 layer_factory.hpp:77] Creating layer Eltwise11_ReLU23_0_split
I0218 21:03:21.473074 31980 net.cpp:100] Creating Layer Eltwise11_ReLU23_0_split
I0218 21:03:21.473078 31980 net.cpp:444] Eltwise11_ReLU23_0_split <- Eltwise11
I0218 21:03:21.473083 31980 net.cpp:418] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_0
I0218 21:03:21.473089 31980 net.cpp:418] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_1
I0218 21:03:21.473121 31980 net.cpp:150] Setting up Eltwise11_ReLU23_0_split
I0218 21:03:21.473127 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.473130 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.473134 31980 net.cpp:165] Memory required for data: 55464320
I0218 21:03:21.473135 31980 layer_factory.hpp:77] Creating layer Convolution25
I0218 21:03:21.473145 31980 net.cpp:100] Creating Layer Convolution25
I0218 21:03:21.473148 31980 net.cpp:444] Convolution25 <- Eltwise11_ReLU23_0_split_0
I0218 21:03:21.473155 31980 net.cpp:418] Convolution25 -> Convolution25
I0218 21:03:21.474617 31980 net.cpp:150] Setting up Convolution25
I0218 21:03:21.474628 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.474632 31980 net.cpp:165] Memory required for data: 55832960
I0218 21:03:21.474637 31980 layer_factory.hpp:77] Creating layer BatchNorm25
I0218 21:03:21.474643 31980 net.cpp:100] Creating Layer BatchNorm25
I0218 21:03:21.474647 31980 net.cpp:444] BatchNorm25 <- Convolution25
I0218 21:03:21.474653 31980 net.cpp:405] BatchNorm25 -> Convolution25 (in-place)
I0218 21:03:21.474802 31980 net.cpp:150] Setting up BatchNorm25
I0218 21:03:21.474809 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.474812 31980 net.cpp:165] Memory required for data: 56201600
I0218 21:03:21.474824 31980 layer_factory.hpp:77] Creating layer Scale25
I0218 21:03:21.474830 31980 net.cpp:100] Creating Layer Scale25
I0218 21:03:21.474833 31980 net.cpp:444] Scale25 <- Convolution25
I0218 21:03:21.474838 31980 net.cpp:405] Scale25 -> Convolution25 (in-place)
I0218 21:03:21.474869 31980 layer_factory.hpp:77] Creating layer Scale25
I0218 21:03:21.474957 31980 net.cpp:150] Setting up Scale25
I0218 21:03:21.474964 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.474967 31980 net.cpp:165] Memory required for data: 56570240
I0218 21:03:21.474972 31980 layer_factory.hpp:77] Creating layer ReLU24
I0218 21:03:21.474975 31980 net.cpp:100] Creating Layer ReLU24
I0218 21:03:21.474978 31980 net.cpp:444] ReLU24 <- Convolution25
I0218 21:03:21.474983 31980 net.cpp:405] ReLU24 -> Convolution25 (in-place)
I0218 21:03:21.475523 31980 net.cpp:150] Setting up ReLU24
I0218 21:03:21.475539 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.475543 31980 net.cpp:165] Memory required for data: 56938880
I0218 21:03:21.475545 31980 layer_factory.hpp:77] Creating layer Convolution26
I0218 21:03:21.475554 31980 net.cpp:100] Creating Layer Convolution26
I0218 21:03:21.475558 31980 net.cpp:444] Convolution26 <- Convolution25
I0218 21:03:21.475564 31980 net.cpp:418] Convolution26 -> Convolution26
I0218 21:03:21.477015 31980 net.cpp:150] Setting up Convolution26
I0218 21:03:21.477030 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.477032 31980 net.cpp:165] Memory required for data: 57307520
I0218 21:03:21.477037 31980 layer_factory.hpp:77] Creating layer BatchNorm26
I0218 21:03:21.477043 31980 net.cpp:100] Creating Layer BatchNorm26
I0218 21:03:21.477046 31980 net.cpp:444] BatchNorm26 <- Convolution26
I0218 21:03:21.477061 31980 net.cpp:405] BatchNorm26 -> Convolution26 (in-place)
I0218 21:03:21.477205 31980 net.cpp:150] Setting up BatchNorm26
I0218 21:03:21.477211 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.477214 31980 net.cpp:165] Memory required for data: 57676160
I0218 21:03:21.477219 31980 layer_factory.hpp:77] Creating layer Scale26
I0218 21:03:21.477224 31980 net.cpp:100] Creating Layer Scale26
I0218 21:03:21.477227 31980 net.cpp:444] Scale26 <- Convolution26
I0218 21:03:21.477232 31980 net.cpp:405] Scale26 -> Convolution26 (in-place)
I0218 21:03:21.477262 31980 layer_factory.hpp:77] Creating layer Scale26
I0218 21:03:21.477346 31980 net.cpp:150] Setting up Scale26
I0218 21:03:21.477352 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.477355 31980 net.cpp:165] Memory required for data: 58044800
I0218 21:03:21.477360 31980 layer_factory.hpp:77] Creating layer Eltwise12
I0218 21:03:21.477365 31980 net.cpp:100] Creating Layer Eltwise12
I0218 21:03:21.477367 31980 net.cpp:444] Eltwise12 <- Eltwise11_ReLU23_0_split_1
I0218 21:03:21.477371 31980 net.cpp:444] Eltwise12 <- Convolution26
I0218 21:03:21.477376 31980 net.cpp:418] Eltwise12 -> Eltwise12
I0218 21:03:21.477396 31980 net.cpp:150] Setting up Eltwise12
I0218 21:03:21.477401 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.477402 31980 net.cpp:165] Memory required for data: 58413440
I0218 21:03:21.477406 31980 layer_factory.hpp:77] Creating layer ReLU25
I0218 21:03:21.477409 31980 net.cpp:100] Creating Layer ReLU25
I0218 21:03:21.477411 31980 net.cpp:444] ReLU25 <- Eltwise12
I0218 21:03:21.477416 31980 net.cpp:405] ReLU25 -> Eltwise12 (in-place)
I0218 21:03:21.477569 31980 net.cpp:150] Setting up ReLU25
I0218 21:03:21.477578 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.477581 31980 net.cpp:165] Memory required for data: 58782080
I0218 21:03:21.477583 31980 layer_factory.hpp:77] Creating layer Eltwise12_ReLU25_0_split
I0218 21:03:21.477588 31980 net.cpp:100] Creating Layer Eltwise12_ReLU25_0_split
I0218 21:03:21.477591 31980 net.cpp:444] Eltwise12_ReLU25_0_split <- Eltwise12
I0218 21:03:21.477596 31980 net.cpp:418] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_0
I0218 21:03:21.477602 31980 net.cpp:418] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_1
I0218 21:03:21.477634 31980 net.cpp:150] Setting up Eltwise12_ReLU25_0_split
I0218 21:03:21.477639 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.477643 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.477645 31980 net.cpp:165] Memory required for data: 59519360
I0218 21:03:21.477648 31980 layer_factory.hpp:77] Creating layer Convolution27
I0218 21:03:21.477656 31980 net.cpp:100] Creating Layer Convolution27
I0218 21:03:21.477659 31980 net.cpp:444] Convolution27 <- Eltwise12_ReLU25_0_split_0
I0218 21:03:21.477665 31980 net.cpp:418] Convolution27 -> Convolution27
I0218 21:03:21.479110 31980 net.cpp:150] Setting up Convolution27
I0218 21:03:21.479121 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.479123 31980 net.cpp:165] Memory required for data: 59888000
I0218 21:03:21.479130 31980 layer_factory.hpp:77] Creating layer BatchNorm27
I0218 21:03:21.479135 31980 net.cpp:100] Creating Layer BatchNorm27
I0218 21:03:21.479138 31980 net.cpp:444] BatchNorm27 <- Convolution27
I0218 21:03:21.479143 31980 net.cpp:405] BatchNorm27 -> Convolution27 (in-place)
I0218 21:03:21.479292 31980 net.cpp:150] Setting up BatchNorm27
I0218 21:03:21.479300 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.479301 31980 net.cpp:165] Memory required for data: 60256640
I0218 21:03:21.479306 31980 layer_factory.hpp:77] Creating layer Scale27
I0218 21:03:21.479312 31980 net.cpp:100] Creating Layer Scale27
I0218 21:03:21.479315 31980 net.cpp:444] Scale27 <- Convolution27
I0218 21:03:21.479319 31980 net.cpp:405] Scale27 -> Convolution27 (in-place)
I0218 21:03:21.479349 31980 layer_factory.hpp:77] Creating layer Scale27
I0218 21:03:21.479434 31980 net.cpp:150] Setting up Scale27
I0218 21:03:21.479444 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.479450 31980 net.cpp:165] Memory required for data: 60625280
I0218 21:03:21.479455 31980 layer_factory.hpp:77] Creating layer ReLU26
I0218 21:03:21.479460 31980 net.cpp:100] Creating Layer ReLU26
I0218 21:03:21.479462 31980 net.cpp:444] ReLU26 <- Convolution27
I0218 21:03:21.479467 31980 net.cpp:405] ReLU26 -> Convolution27 (in-place)
I0218 21:03:21.479996 31980 net.cpp:150] Setting up ReLU26
I0218 21:03:21.480008 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.480011 31980 net.cpp:165] Memory required for data: 60993920
I0218 21:03:21.480013 31980 layer_factory.hpp:77] Creating layer Convolution28
I0218 21:03:21.480022 31980 net.cpp:100] Creating Layer Convolution28
I0218 21:03:21.480026 31980 net.cpp:444] Convolution28 <- Convolution27
I0218 21:03:21.480032 31980 net.cpp:418] Convolution28 -> Convolution28
I0218 21:03:21.481472 31980 net.cpp:150] Setting up Convolution28
I0218 21:03:21.481484 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.481487 31980 net.cpp:165] Memory required for data: 61362560
I0218 21:03:21.481493 31980 layer_factory.hpp:77] Creating layer BatchNorm28
I0218 21:03:21.481498 31980 net.cpp:100] Creating Layer BatchNorm28
I0218 21:03:21.481501 31980 net.cpp:444] BatchNorm28 <- Convolution28
I0218 21:03:21.481508 31980 net.cpp:405] BatchNorm28 -> Convolution28 (in-place)
I0218 21:03:21.481658 31980 net.cpp:150] Setting up BatchNorm28
I0218 21:03:21.481665 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.481667 31980 net.cpp:165] Memory required for data: 61731200
I0218 21:03:21.481673 31980 layer_factory.hpp:77] Creating layer Scale28
I0218 21:03:21.481678 31980 net.cpp:100] Creating Layer Scale28
I0218 21:03:21.481680 31980 net.cpp:444] Scale28 <- Convolution28
I0218 21:03:21.481685 31980 net.cpp:405] Scale28 -> Convolution28 (in-place)
I0218 21:03:21.481716 31980 layer_factory.hpp:77] Creating layer Scale28
I0218 21:03:21.481802 31980 net.cpp:150] Setting up Scale28
I0218 21:03:21.481808 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.481811 31980 net.cpp:165] Memory required for data: 62099840
I0218 21:03:21.481815 31980 layer_factory.hpp:77] Creating layer Eltwise13
I0218 21:03:21.481822 31980 net.cpp:100] Creating Layer Eltwise13
I0218 21:03:21.481825 31980 net.cpp:444] Eltwise13 <- Eltwise12_ReLU25_0_split_1
I0218 21:03:21.481828 31980 net.cpp:444] Eltwise13 <- Convolution28
I0218 21:03:21.481832 31980 net.cpp:418] Eltwise13 -> Eltwise13
I0218 21:03:21.481851 31980 net.cpp:150] Setting up Eltwise13
I0218 21:03:21.481856 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.481858 31980 net.cpp:165] Memory required for data: 62468480
I0218 21:03:21.481861 31980 layer_factory.hpp:77] Creating layer ReLU27
I0218 21:03:21.481866 31980 net.cpp:100] Creating Layer ReLU27
I0218 21:03:21.481868 31980 net.cpp:444] ReLU27 <- Eltwise13
I0218 21:03:21.481873 31980 net.cpp:405] ReLU27 -> Eltwise13 (in-place)
I0218 21:03:21.482398 31980 net.cpp:150] Setting up ReLU27
I0218 21:03:21.482409 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.482410 31980 net.cpp:165] Memory required for data: 62837120
I0218 21:03:21.482414 31980 layer_factory.hpp:77] Creating layer Eltwise13_ReLU27_0_split
I0218 21:03:21.482420 31980 net.cpp:100] Creating Layer Eltwise13_ReLU27_0_split
I0218 21:03:21.482424 31980 net.cpp:444] Eltwise13_ReLU27_0_split <- Eltwise13
I0218 21:03:21.482427 31980 net.cpp:418] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_0
I0218 21:03:21.482434 31980 net.cpp:418] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_1
I0218 21:03:21.482439 31980 net.cpp:418] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_2
I0218 21:03:21.482482 31980 net.cpp:150] Setting up Eltwise13_ReLU27_0_split
I0218 21:03:21.482487 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.482491 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.482494 31980 net.cpp:157] Top shape: 20 32 12 12 (92160)
I0218 21:03:21.482499 31980 net.cpp:165] Memory required for data: 63943040
I0218 21:03:21.482506 31980 layer_factory.hpp:77] Creating layer Convolution35
I0218 21:03:21.482515 31980 net.cpp:100] Creating Layer Convolution35
I0218 21:03:21.482519 31980 net.cpp:444] Convolution35 <- Eltwise13_ReLU27_0_split_0
I0218 21:03:21.482525 31980 net.cpp:418] Convolution35 -> Convolution35
I0218 21:03:21.483953 31980 net.cpp:150] Setting up Convolution35
I0218 21:03:21.483968 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.483970 31980 net.cpp:165] Memory required for data: 64127360
I0218 21:03:21.483976 31980 layer_factory.hpp:77] Creating layer BatchNorm35
I0218 21:03:21.483983 31980 net.cpp:100] Creating Layer BatchNorm35
I0218 21:03:21.483986 31980 net.cpp:444] BatchNorm35 <- Convolution35
I0218 21:03:21.483990 31980 net.cpp:405] BatchNorm35 -> Convolution35 (in-place)
I0218 21:03:21.484143 31980 net.cpp:150] Setting up BatchNorm35
I0218 21:03:21.484149 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.484151 31980 net.cpp:165] Memory required for data: 64311680
I0218 21:03:21.484158 31980 layer_factory.hpp:77] Creating layer Scale35
I0218 21:03:21.484163 31980 net.cpp:100] Creating Layer Scale35
I0218 21:03:21.484166 31980 net.cpp:444] Scale35 <- Convolution35
I0218 21:03:21.484169 31980 net.cpp:405] Scale35 -> Convolution35 (in-place)
I0218 21:03:21.484201 31980 layer_factory.hpp:77] Creating layer Scale35
I0218 21:03:21.484290 31980 net.cpp:150] Setting up Scale35
I0218 21:03:21.484297 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.484299 31980 net.cpp:165] Memory required for data: 64496000
I0218 21:03:21.484304 31980 layer_factory.hpp:77] Creating layer Convolution36
I0218 21:03:21.484313 31980 net.cpp:100] Creating Layer Convolution36
I0218 21:03:21.484316 31980 net.cpp:444] Convolution36 <- Eltwise13_ReLU27_0_split_1
I0218 21:03:21.484321 31980 net.cpp:418] Convolution36 -> Convolution36
I0218 21:03:21.485864 31980 net.cpp:150] Setting up Convolution36
I0218 21:03:21.485877 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.485879 31980 net.cpp:165] Memory required for data: 64680320
I0218 21:03:21.485885 31980 layer_factory.hpp:77] Creating layer BatchNorm36
I0218 21:03:21.485890 31980 net.cpp:100] Creating Layer BatchNorm36
I0218 21:03:21.485893 31980 net.cpp:444] BatchNorm36 <- Convolution36
I0218 21:03:21.485898 31980 net.cpp:405] BatchNorm36 -> Convolution36 (in-place)
I0218 21:03:21.486043 31980 net.cpp:150] Setting up BatchNorm36
I0218 21:03:21.486049 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.486052 31980 net.cpp:165] Memory required for data: 64864640
I0218 21:03:21.486057 31980 layer_factory.hpp:77] Creating layer Scale36
I0218 21:03:21.486061 31980 net.cpp:100] Creating Layer Scale36
I0218 21:03:21.486065 31980 net.cpp:444] Scale36 <- Convolution36
I0218 21:03:21.486069 31980 net.cpp:405] Scale36 -> Convolution36 (in-place)
I0218 21:03:21.486100 31980 layer_factory.hpp:77] Creating layer Scale36
I0218 21:03:21.486187 31980 net.cpp:150] Setting up Scale36
I0218 21:03:21.486194 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.486196 31980 net.cpp:165] Memory required for data: 65048960
I0218 21:03:21.486202 31980 layer_factory.hpp:77] Creating layer ReLU34
I0218 21:03:21.486207 31980 net.cpp:100] Creating Layer ReLU34
I0218 21:03:21.486210 31980 net.cpp:444] ReLU34 <- Convolution36
I0218 21:03:21.486213 31980 net.cpp:405] ReLU34 -> Convolution36 (in-place)
I0218 21:03:21.486366 31980 net.cpp:150] Setting up ReLU34
I0218 21:03:21.486373 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.486377 31980 net.cpp:165] Memory required for data: 65233280
I0218 21:03:21.486379 31980 layer_factory.hpp:77] Creating layer Convolution37
I0218 21:03:21.486387 31980 net.cpp:100] Creating Layer Convolution37
I0218 21:03:21.486392 31980 net.cpp:444] Convolution37 <- Convolution36
I0218 21:03:21.486397 31980 net.cpp:418] Convolution37 -> Convolution37
I0218 21:03:21.488456 31980 net.cpp:150] Setting up Convolution37
I0218 21:03:21.488472 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.488481 31980 net.cpp:165] Memory required for data: 65417600
I0218 21:03:21.488487 31980 layer_factory.hpp:77] Creating layer BatchNorm37
I0218 21:03:21.488493 31980 net.cpp:100] Creating Layer BatchNorm37
I0218 21:03:21.488497 31980 net.cpp:444] BatchNorm37 <- Convolution37
I0218 21:03:21.488502 31980 net.cpp:405] BatchNorm37 -> Convolution37 (in-place)
I0218 21:03:21.488652 31980 net.cpp:150] Setting up BatchNorm37
I0218 21:03:21.488658 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.488660 31980 net.cpp:165] Memory required for data: 65601920
I0218 21:03:21.488667 31980 layer_factory.hpp:77] Creating layer Scale37
I0218 21:03:21.488672 31980 net.cpp:100] Creating Layer Scale37
I0218 21:03:21.488675 31980 net.cpp:444] Scale37 <- Convolution37
I0218 21:03:21.488678 31980 net.cpp:405] Scale37 -> Convolution37 (in-place)
I0218 21:03:21.488710 31980 layer_factory.hpp:77] Creating layer Scale37
I0218 21:03:21.488795 31980 net.cpp:150] Setting up Scale37
I0218 21:03:21.488801 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.488803 31980 net.cpp:165] Memory required for data: 65786240
I0218 21:03:21.488808 31980 layer_factory.hpp:77] Creating layer Eltwise17
I0218 21:03:21.488814 31980 net.cpp:100] Creating Layer Eltwise17
I0218 21:03:21.488817 31980 net.cpp:444] Eltwise17 <- Convolution35
I0218 21:03:21.488821 31980 net.cpp:444] Eltwise17 <- Convolution37
I0218 21:03:21.488824 31980 net.cpp:418] Eltwise17 -> Eltwise17
I0218 21:03:21.488843 31980 net.cpp:150] Setting up Eltwise17
I0218 21:03:21.488847 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.488849 31980 net.cpp:165] Memory required for data: 65970560
I0218 21:03:21.488852 31980 layer_factory.hpp:77] Creating layer ReLU35
I0218 21:03:21.488858 31980 net.cpp:100] Creating Layer ReLU35
I0218 21:03:21.488860 31980 net.cpp:444] ReLU35 <- Eltwise17
I0218 21:03:21.488864 31980 net.cpp:405] ReLU35 -> Eltwise17 (in-place)
I0218 21:03:21.489024 31980 net.cpp:150] Setting up ReLU35
I0218 21:03:21.489033 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.489035 31980 net.cpp:165] Memory required for data: 66154880
I0218 21:03:21.489038 31980 layer_factory.hpp:77] Creating layer Eltwise17_ReLU35_0_split
I0218 21:03:21.489044 31980 net.cpp:100] Creating Layer Eltwise17_ReLU35_0_split
I0218 21:03:21.489048 31980 net.cpp:444] Eltwise17_ReLU35_0_split <- Eltwise17
I0218 21:03:21.489053 31980 net.cpp:418] Eltwise17_ReLU35_0_split -> Eltwise17_ReLU35_0_split_0
I0218 21:03:21.489063 31980 net.cpp:418] Eltwise17_ReLU35_0_split -> Eltwise17_ReLU35_0_split_1
I0218 21:03:21.489095 31980 net.cpp:150] Setting up Eltwise17_ReLU35_0_split
I0218 21:03:21.489101 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.489104 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.489106 31980 net.cpp:165] Memory required for data: 66523520
I0218 21:03:21.489109 31980 layer_factory.hpp:77] Creating layer Convolution38
I0218 21:03:21.489117 31980 net.cpp:100] Creating Layer Convolution38
I0218 21:03:21.489121 31980 net.cpp:444] Convolution38 <- Eltwise17_ReLU35_0_split_0
I0218 21:03:21.489126 31980 net.cpp:418] Convolution38 -> Convolution38
I0218 21:03:21.491137 31980 net.cpp:150] Setting up Convolution38
I0218 21:03:21.491149 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.491153 31980 net.cpp:165] Memory required for data: 66707840
I0218 21:03:21.491158 31980 layer_factory.hpp:77] Creating layer BatchNorm38
I0218 21:03:21.491164 31980 net.cpp:100] Creating Layer BatchNorm38
I0218 21:03:21.491168 31980 net.cpp:444] BatchNorm38 <- Convolution38
I0218 21:03:21.491173 31980 net.cpp:405] BatchNorm38 -> Convolution38 (in-place)
I0218 21:03:21.491323 31980 net.cpp:150] Setting up BatchNorm38
I0218 21:03:21.491329 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.491333 31980 net.cpp:165] Memory required for data: 66892160
I0218 21:03:21.491338 31980 layer_factory.hpp:77] Creating layer Scale38
I0218 21:03:21.491343 31980 net.cpp:100] Creating Layer Scale38
I0218 21:03:21.491348 31980 net.cpp:444] Scale38 <- Convolution38
I0218 21:03:21.491356 31980 net.cpp:405] Scale38 -> Convolution38 (in-place)
I0218 21:03:21.491391 31980 layer_factory.hpp:77] Creating layer Scale38
I0218 21:03:21.491477 31980 net.cpp:150] Setting up Scale38
I0218 21:03:21.491484 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.491487 31980 net.cpp:165] Memory required for data: 67076480
I0218 21:03:21.491492 31980 layer_factory.hpp:77] Creating layer ReLU36
I0218 21:03:21.491497 31980 net.cpp:100] Creating Layer ReLU36
I0218 21:03:21.491499 31980 net.cpp:444] ReLU36 <- Convolution38
I0218 21:03:21.491503 31980 net.cpp:405] ReLU36 -> Convolution38 (in-place)
I0218 21:03:21.492038 31980 net.cpp:150] Setting up ReLU36
I0218 21:03:21.492049 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.492051 31980 net.cpp:165] Memory required for data: 67260800
I0218 21:03:21.492055 31980 layer_factory.hpp:77] Creating layer Convolution39
I0218 21:03:21.492064 31980 net.cpp:100] Creating Layer Convolution39
I0218 21:03:21.492069 31980 net.cpp:444] Convolution39 <- Convolution38
I0218 21:03:21.492074 31980 net.cpp:418] Convolution39 -> Convolution39
I0218 21:03:21.494091 31980 net.cpp:150] Setting up Convolution39
I0218 21:03:21.494104 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.494107 31980 net.cpp:165] Memory required for data: 67445120
I0218 21:03:21.494113 31980 layer_factory.hpp:77] Creating layer BatchNorm39
I0218 21:03:21.494123 31980 net.cpp:100] Creating Layer BatchNorm39
I0218 21:03:21.494127 31980 net.cpp:444] BatchNorm39 <- Convolution39
I0218 21:03:21.494132 31980 net.cpp:405] BatchNorm39 -> Convolution39 (in-place)
I0218 21:03:21.494305 31980 net.cpp:150] Setting up BatchNorm39
I0218 21:03:21.494313 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.494314 31980 net.cpp:165] Memory required for data: 67629440
I0218 21:03:21.494320 31980 layer_factory.hpp:77] Creating layer Scale39
I0218 21:03:21.494324 31980 net.cpp:100] Creating Layer Scale39
I0218 21:03:21.494328 31980 net.cpp:444] Scale39 <- Convolution39
I0218 21:03:21.494333 31980 net.cpp:405] Scale39 -> Convolution39 (in-place)
I0218 21:03:21.494365 31980 layer_factory.hpp:77] Creating layer Scale39
I0218 21:03:21.494451 31980 net.cpp:150] Setting up Scale39
I0218 21:03:21.494457 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.494459 31980 net.cpp:165] Memory required for data: 67813760
I0218 21:03:21.494463 31980 layer_factory.hpp:77] Creating layer Eltwise18
I0218 21:03:21.494468 31980 net.cpp:100] Creating Layer Eltwise18
I0218 21:03:21.494472 31980 net.cpp:444] Eltwise18 <- Eltwise17_ReLU35_0_split_1
I0218 21:03:21.494474 31980 net.cpp:444] Eltwise18 <- Convolution39
I0218 21:03:21.494479 31980 net.cpp:418] Eltwise18 -> Eltwise18
I0218 21:03:21.494499 31980 net.cpp:150] Setting up Eltwise18
I0218 21:03:21.494503 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.494506 31980 net.cpp:165] Memory required for data: 67998080
I0218 21:03:21.494509 31980 layer_factory.hpp:77] Creating layer ReLU37
I0218 21:03:21.494513 31980 net.cpp:100] Creating Layer ReLU37
I0218 21:03:21.494515 31980 net.cpp:444] ReLU37 <- Eltwise18
I0218 21:03:21.494520 31980 net.cpp:405] ReLU37 -> Eltwise18 (in-place)
I0218 21:03:21.494678 31980 net.cpp:150] Setting up ReLU37
I0218 21:03:21.494685 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.494688 31980 net.cpp:165] Memory required for data: 68182400
I0218 21:03:21.494691 31980 layer_factory.hpp:77] Creating layer Eltwise18_ReLU37_0_split
I0218 21:03:21.494695 31980 net.cpp:100] Creating Layer Eltwise18_ReLU37_0_split
I0218 21:03:21.494699 31980 net.cpp:444] Eltwise18_ReLU37_0_split <- Eltwise18
I0218 21:03:21.494704 31980 net.cpp:418] Eltwise18_ReLU37_0_split -> Eltwise18_ReLU37_0_split_0
I0218 21:03:21.494709 31980 net.cpp:418] Eltwise18_ReLU37_0_split -> Eltwise18_ReLU37_0_split_1
I0218 21:03:21.494742 31980 net.cpp:150] Setting up Eltwise18_ReLU37_0_split
I0218 21:03:21.494747 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.494753 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.494760 31980 net.cpp:165] Memory required for data: 68551040
I0218 21:03:21.494763 31980 layer_factory.hpp:77] Creating layer Convolution40
I0218 21:03:21.494771 31980 net.cpp:100] Creating Layer Convolution40
I0218 21:03:21.494774 31980 net.cpp:444] Convolution40 <- Eltwise18_ReLU37_0_split_0
I0218 21:03:21.494781 31980 net.cpp:418] Convolution40 -> Convolution40
I0218 21:03:21.497097 31980 net.cpp:150] Setting up Convolution40
I0218 21:03:21.497109 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.497112 31980 net.cpp:165] Memory required for data: 68735360
I0218 21:03:21.497118 31980 layer_factory.hpp:77] Creating layer BatchNorm40
I0218 21:03:21.497123 31980 net.cpp:100] Creating Layer BatchNorm40
I0218 21:03:21.497128 31980 net.cpp:444] BatchNorm40 <- Convolution40
I0218 21:03:21.497134 31980 net.cpp:405] BatchNorm40 -> Convolution40 (in-place)
I0218 21:03:21.497309 31980 net.cpp:150] Setting up BatchNorm40
I0218 21:03:21.497316 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.497318 31980 net.cpp:165] Memory required for data: 68919680
I0218 21:03:21.497324 31980 layer_factory.hpp:77] Creating layer Scale40
I0218 21:03:21.497329 31980 net.cpp:100] Creating Layer Scale40
I0218 21:03:21.497331 31980 net.cpp:444] Scale40 <- Convolution40
I0218 21:03:21.497336 31980 net.cpp:405] Scale40 -> Convolution40 (in-place)
I0218 21:03:21.497368 31980 layer_factory.hpp:77] Creating layer Scale40
I0218 21:03:21.497474 31980 net.cpp:150] Setting up Scale40
I0218 21:03:21.497480 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.497483 31980 net.cpp:165] Memory required for data: 69104000
I0218 21:03:21.497488 31980 layer_factory.hpp:77] Creating layer ReLU38
I0218 21:03:21.497491 31980 net.cpp:100] Creating Layer ReLU38
I0218 21:03:21.497494 31980 net.cpp:444] ReLU38 <- Convolution40
I0218 21:03:21.497498 31980 net.cpp:405] ReLU38 -> Convolution40 (in-place)
I0218 21:03:21.497655 31980 net.cpp:150] Setting up ReLU38
I0218 21:03:21.497664 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.497666 31980 net.cpp:165] Memory required for data: 69288320
I0218 21:03:21.497669 31980 layer_factory.hpp:77] Creating layer Convolution41
I0218 21:03:21.497678 31980 net.cpp:100] Creating Layer Convolution41
I0218 21:03:21.497681 31980 net.cpp:444] Convolution41 <- Convolution40
I0218 21:03:21.497686 31980 net.cpp:418] Convolution41 -> Convolution41
I0218 21:03:21.499660 31980 net.cpp:150] Setting up Convolution41
I0218 21:03:21.499672 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.499676 31980 net.cpp:165] Memory required for data: 69472640
I0218 21:03:21.499681 31980 layer_factory.hpp:77] Creating layer BatchNorm41
I0218 21:03:21.499687 31980 net.cpp:100] Creating Layer BatchNorm41
I0218 21:03:21.499691 31980 net.cpp:444] BatchNorm41 <- Convolution41
I0218 21:03:21.499696 31980 net.cpp:405] BatchNorm41 -> Convolution41 (in-place)
I0218 21:03:21.499847 31980 net.cpp:150] Setting up BatchNorm41
I0218 21:03:21.499853 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.499856 31980 net.cpp:165] Memory required for data: 69656960
I0218 21:03:21.499861 31980 layer_factory.hpp:77] Creating layer Scale41
I0218 21:03:21.499869 31980 net.cpp:100] Creating Layer Scale41
I0218 21:03:21.499872 31980 net.cpp:444] Scale41 <- Convolution41
I0218 21:03:21.499876 31980 net.cpp:405] Scale41 -> Convolution41 (in-place)
I0218 21:03:21.499910 31980 layer_factory.hpp:77] Creating layer Scale41
I0218 21:03:21.499997 31980 net.cpp:150] Setting up Scale41
I0218 21:03:21.500003 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.500005 31980 net.cpp:165] Memory required for data: 69841280
I0218 21:03:21.500010 31980 layer_factory.hpp:77] Creating layer Eltwise19
I0218 21:03:21.500015 31980 net.cpp:100] Creating Layer Eltwise19
I0218 21:03:21.500017 31980 net.cpp:444] Eltwise19 <- Eltwise18_ReLU37_0_split_1
I0218 21:03:21.500021 31980 net.cpp:444] Eltwise19 <- Convolution41
I0218 21:03:21.500031 31980 net.cpp:418] Eltwise19 -> Eltwise19
I0218 21:03:21.500056 31980 net.cpp:150] Setting up Eltwise19
I0218 21:03:21.500061 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.500062 31980 net.cpp:165] Memory required for data: 70025600
I0218 21:03:21.500066 31980 layer_factory.hpp:77] Creating layer ReLU39
I0218 21:03:21.500072 31980 net.cpp:100] Creating Layer ReLU39
I0218 21:03:21.500073 31980 net.cpp:444] ReLU39 <- Eltwise19
I0218 21:03:21.500077 31980 net.cpp:405] ReLU39 -> Eltwise19 (in-place)
I0218 21:03:21.500591 31980 net.cpp:150] Setting up ReLU39
I0218 21:03:21.500620 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.500623 31980 net.cpp:165] Memory required for data: 70209920
I0218 21:03:21.500627 31980 layer_factory.hpp:77] Creating layer Eltwise19_ReLU39_0_split
I0218 21:03:21.500633 31980 net.cpp:100] Creating Layer Eltwise19_ReLU39_0_split
I0218 21:03:21.500635 31980 net.cpp:444] Eltwise19_ReLU39_0_split <- Eltwise19
I0218 21:03:21.500641 31980 net.cpp:418] Eltwise19_ReLU39_0_split -> Eltwise19_ReLU39_0_split_0
I0218 21:03:21.500648 31980 net.cpp:418] Eltwise19_ReLU39_0_split -> Eltwise19_ReLU39_0_split_1
I0218 21:03:21.500682 31980 net.cpp:150] Setting up Eltwise19_ReLU39_0_split
I0218 21:03:21.500687 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.500690 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.500692 31980 net.cpp:165] Memory required for data: 70578560
I0218 21:03:21.500695 31980 layer_factory.hpp:77] Creating layer Convolution42
I0218 21:03:21.500705 31980 net.cpp:100] Creating Layer Convolution42
I0218 21:03:21.500707 31980 net.cpp:444] Convolution42 <- Eltwise19_ReLU39_0_split_0
I0218 21:03:21.500712 31980 net.cpp:418] Convolution42 -> Convolution42
I0218 21:03:21.502697 31980 net.cpp:150] Setting up Convolution42
I0218 21:03:21.502710 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.502712 31980 net.cpp:165] Memory required for data: 70762880
I0218 21:03:21.502718 31980 layer_factory.hpp:77] Creating layer BatchNorm42
I0218 21:03:21.502724 31980 net.cpp:100] Creating Layer BatchNorm42
I0218 21:03:21.502728 31980 net.cpp:444] BatchNorm42 <- Convolution42
I0218 21:03:21.502732 31980 net.cpp:405] BatchNorm42 -> Convolution42 (in-place)
I0218 21:03:21.502885 31980 net.cpp:150] Setting up BatchNorm42
I0218 21:03:21.502892 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.502894 31980 net.cpp:165] Memory required for data: 70947200
I0218 21:03:21.502899 31980 layer_factory.hpp:77] Creating layer Scale42
I0218 21:03:21.502903 31980 net.cpp:100] Creating Layer Scale42
I0218 21:03:21.502907 31980 net.cpp:444] Scale42 <- Convolution42
I0218 21:03:21.502912 31980 net.cpp:405] Scale42 -> Convolution42 (in-place)
I0218 21:03:21.502944 31980 layer_factory.hpp:77] Creating layer Scale42
I0218 21:03:21.503036 31980 net.cpp:150] Setting up Scale42
I0218 21:03:21.503042 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.503044 31980 net.cpp:165] Memory required for data: 71131520
I0218 21:03:21.503049 31980 layer_factory.hpp:77] Creating layer ReLU40
I0218 21:03:21.503054 31980 net.cpp:100] Creating Layer ReLU40
I0218 21:03:21.503057 31980 net.cpp:444] ReLU40 <- Convolution42
I0218 21:03:21.503062 31980 net.cpp:405] ReLU40 -> Convolution42 (in-place)
I0218 21:03:21.503568 31980 net.cpp:150] Setting up ReLU40
I0218 21:03:21.503581 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.503583 31980 net.cpp:165] Memory required for data: 71315840
I0218 21:03:21.503587 31980 layer_factory.hpp:77] Creating layer Convolution43
I0218 21:03:21.503595 31980 net.cpp:100] Creating Layer Convolution43
I0218 21:03:21.503599 31980 net.cpp:444] Convolution43 <- Convolution42
I0218 21:03:21.503605 31980 net.cpp:418] Convolution43 -> Convolution43
I0218 21:03:21.505628 31980 net.cpp:150] Setting up Convolution43
I0218 21:03:21.505640 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.505643 31980 net.cpp:165] Memory required for data: 71500160
I0218 21:03:21.505650 31980 layer_factory.hpp:77] Creating layer BatchNorm43
I0218 21:03:21.505658 31980 net.cpp:100] Creating Layer BatchNorm43
I0218 21:03:21.505666 31980 net.cpp:444] BatchNorm43 <- Convolution43
I0218 21:03:21.505671 31980 net.cpp:405] BatchNorm43 -> Convolution43 (in-place)
I0218 21:03:21.505826 31980 net.cpp:150] Setting up BatchNorm43
I0218 21:03:21.505831 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.505834 31980 net.cpp:165] Memory required for data: 71684480
I0218 21:03:21.505839 31980 layer_factory.hpp:77] Creating layer Scale43
I0218 21:03:21.505844 31980 net.cpp:100] Creating Layer Scale43
I0218 21:03:21.505847 31980 net.cpp:444] Scale43 <- Convolution43
I0218 21:03:21.505851 31980 net.cpp:405] Scale43 -> Convolution43 (in-place)
I0218 21:03:21.505882 31980 layer_factory.hpp:77] Creating layer Scale43
I0218 21:03:21.505973 31980 net.cpp:150] Setting up Scale43
I0218 21:03:21.505980 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.505981 31980 net.cpp:165] Memory required for data: 71868800
I0218 21:03:21.505986 31980 layer_factory.hpp:77] Creating layer Eltwise20
I0218 21:03:21.505991 31980 net.cpp:100] Creating Layer Eltwise20
I0218 21:03:21.505995 31980 net.cpp:444] Eltwise20 <- Eltwise19_ReLU39_0_split_1
I0218 21:03:21.505997 31980 net.cpp:444] Eltwise20 <- Convolution43
I0218 21:03:21.506002 31980 net.cpp:418] Eltwise20 -> Eltwise20
I0218 21:03:21.506023 31980 net.cpp:150] Setting up Eltwise20
I0218 21:03:21.506027 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.506031 31980 net.cpp:165] Memory required for data: 72053120
I0218 21:03:21.506032 31980 layer_factory.hpp:77] Creating layer ReLU41
I0218 21:03:21.506037 31980 net.cpp:100] Creating Layer ReLU41
I0218 21:03:21.506039 31980 net.cpp:444] ReLU41 <- Eltwise20
I0218 21:03:21.506044 31980 net.cpp:405] ReLU41 -> Eltwise20 (in-place)
I0218 21:03:21.506201 31980 net.cpp:150] Setting up ReLU41
I0218 21:03:21.506208 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.506211 31980 net.cpp:165] Memory required for data: 72237440
I0218 21:03:21.506213 31980 layer_factory.hpp:77] Creating layer Eltwise20_ReLU41_0_split
I0218 21:03:21.506218 31980 net.cpp:100] Creating Layer Eltwise20_ReLU41_0_split
I0218 21:03:21.506222 31980 net.cpp:444] Eltwise20_ReLU41_0_split <- Eltwise20
I0218 21:03:21.506227 31980 net.cpp:418] Eltwise20_ReLU41_0_split -> Eltwise20_ReLU41_0_split_0
I0218 21:03:21.506232 31980 net.cpp:418] Eltwise20_ReLU41_0_split -> Eltwise20_ReLU41_0_split_1
I0218 21:03:21.506265 31980 net.cpp:150] Setting up Eltwise20_ReLU41_0_split
I0218 21:03:21.506270 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.506273 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.506275 31980 net.cpp:165] Memory required for data: 72606080
I0218 21:03:21.506278 31980 layer_factory.hpp:77] Creating layer Convolution44
I0218 21:03:21.506285 31980 net.cpp:100] Creating Layer Convolution44
I0218 21:03:21.506289 31980 net.cpp:444] Convolution44 <- Eltwise20_ReLU41_0_split_0
I0218 21:03:21.506294 31980 net.cpp:418] Convolution44 -> Convolution44
I0218 21:03:21.508261 31980 net.cpp:150] Setting up Convolution44
I0218 21:03:21.508275 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.508277 31980 net.cpp:165] Memory required for data: 72790400
I0218 21:03:21.508282 31980 layer_factory.hpp:77] Creating layer BatchNorm44
I0218 21:03:21.508288 31980 net.cpp:100] Creating Layer BatchNorm44
I0218 21:03:21.508292 31980 net.cpp:444] BatchNorm44 <- Convolution44
I0218 21:03:21.508296 31980 net.cpp:405] BatchNorm44 -> Convolution44 (in-place)
I0218 21:03:21.508451 31980 net.cpp:150] Setting up BatchNorm44
I0218 21:03:21.508457 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.508460 31980 net.cpp:165] Memory required for data: 72974720
I0218 21:03:21.508466 31980 layer_factory.hpp:77] Creating layer Scale44
I0218 21:03:21.508471 31980 net.cpp:100] Creating Layer Scale44
I0218 21:03:21.508473 31980 net.cpp:444] Scale44 <- Convolution44
I0218 21:03:21.508476 31980 net.cpp:405] Scale44 -> Convolution44 (in-place)
I0218 21:03:21.508514 31980 layer_factory.hpp:77] Creating layer Scale44
I0218 21:03:21.508610 31980 net.cpp:150] Setting up Scale44
I0218 21:03:21.508616 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.508620 31980 net.cpp:165] Memory required for data: 73159040
I0218 21:03:21.508625 31980 layer_factory.hpp:77] Creating layer ReLU42
I0218 21:03:21.508630 31980 net.cpp:100] Creating Layer ReLU42
I0218 21:03:21.508632 31980 net.cpp:444] ReLU42 <- Convolution44
I0218 21:03:21.508636 31980 net.cpp:405] ReLU42 -> Convolution44 (in-place)
I0218 21:03:21.509151 31980 net.cpp:150] Setting up ReLU42
I0218 21:03:21.509162 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.509165 31980 net.cpp:165] Memory required for data: 73343360
I0218 21:03:21.509168 31980 layer_factory.hpp:77] Creating layer Convolution45
I0218 21:03:21.509177 31980 net.cpp:100] Creating Layer Convolution45
I0218 21:03:21.509181 31980 net.cpp:444] Convolution45 <- Convolution44
I0218 21:03:21.509186 31980 net.cpp:418] Convolution45 -> Convolution45
I0218 21:03:21.511149 31980 net.cpp:150] Setting up Convolution45
I0218 21:03:21.511162 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.511164 31980 net.cpp:165] Memory required for data: 73527680
I0218 21:03:21.511170 31980 layer_factory.hpp:77] Creating layer BatchNorm45
I0218 21:03:21.511176 31980 net.cpp:100] Creating Layer BatchNorm45
I0218 21:03:21.511180 31980 net.cpp:444] BatchNorm45 <- Convolution45
I0218 21:03:21.511184 31980 net.cpp:405] BatchNorm45 -> Convolution45 (in-place)
I0218 21:03:21.511343 31980 net.cpp:150] Setting up BatchNorm45
I0218 21:03:21.511349 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.511353 31980 net.cpp:165] Memory required for data: 73712000
I0218 21:03:21.511358 31980 layer_factory.hpp:77] Creating layer Scale45
I0218 21:03:21.511379 31980 net.cpp:100] Creating Layer Scale45
I0218 21:03:21.511381 31980 net.cpp:444] Scale45 <- Convolution45
I0218 21:03:21.511385 31980 net.cpp:405] Scale45 -> Convolution45 (in-place)
I0218 21:03:21.511418 31980 layer_factory.hpp:77] Creating layer Scale45
I0218 21:03:21.511509 31980 net.cpp:150] Setting up Scale45
I0218 21:03:21.511515 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.511518 31980 net.cpp:165] Memory required for data: 73896320
I0218 21:03:21.511523 31980 layer_factory.hpp:77] Creating layer Eltwise21
I0218 21:03:21.511533 31980 net.cpp:100] Creating Layer Eltwise21
I0218 21:03:21.511538 31980 net.cpp:444] Eltwise21 <- Eltwise20_ReLU41_0_split_1
I0218 21:03:21.511541 31980 net.cpp:444] Eltwise21 <- Convolution45
I0218 21:03:21.511545 31980 net.cpp:418] Eltwise21 -> Eltwise21
I0218 21:03:21.511566 31980 net.cpp:150] Setting up Eltwise21
I0218 21:03:21.511571 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.511574 31980 net.cpp:165] Memory required for data: 74080640
I0218 21:03:21.511576 31980 layer_factory.hpp:77] Creating layer Convolution_eltwise5
I0218 21:03:21.511584 31980 net.cpp:100] Creating Layer Convolution_eltwise5
I0218 21:03:21.511587 31980 net.cpp:444] Convolution_eltwise5 <- Eltwise5_ReLU11_0_split_2
I0218 21:03:21.511592 31980 net.cpp:418] Convolution_eltwise5 -> Convolution_eltwise5
I0218 21:03:21.512713 31980 net.cpp:150] Setting up Convolution_eltwise5
I0218 21:03:21.512725 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.512728 31980 net.cpp:165] Memory required for data: 74264960
I0218 21:03:21.512733 31980 layer_factory.hpp:77] Creating layer BatchNorm_Convolution_eltwise5
I0218 21:03:21.512739 31980 net.cpp:100] Creating Layer BatchNorm_Convolution_eltwise5
I0218 21:03:21.512742 31980 net.cpp:444] BatchNorm_Convolution_eltwise5 <- Convolution_eltwise5
I0218 21:03:21.512748 31980 net.cpp:405] BatchNorm_Convolution_eltwise5 -> Convolution_eltwise5 (in-place)
I0218 21:03:21.512898 31980 net.cpp:150] Setting up BatchNorm_Convolution_eltwise5
I0218 21:03:21.512904 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.512907 31980 net.cpp:165] Memory required for data: 74449280
I0218 21:03:21.512912 31980 layer_factory.hpp:77] Creating layer Scale_Convolution_eltwise5
I0218 21:03:21.512925 31980 net.cpp:100] Creating Layer Scale_Convolution_eltwise5
I0218 21:03:21.512928 31980 net.cpp:444] Scale_Convolution_eltwise5 <- Convolution_eltwise5
I0218 21:03:21.512933 31980 net.cpp:405] Scale_Convolution_eltwise5 -> Convolution_eltwise5 (in-place)
I0218 21:03:21.512967 31980 layer_factory.hpp:77] Creating layer Scale_Convolution_eltwise5
I0218 21:03:21.513058 31980 net.cpp:150] Setting up Scale_Convolution_eltwise5
I0218 21:03:21.513063 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.513067 31980 net.cpp:165] Memory required for data: 74633600
I0218 21:03:21.513070 31980 layer_factory.hpp:77] Creating layer Convolution_eltwise13
I0218 21:03:21.513078 31980 net.cpp:100] Creating Layer Convolution_eltwise13
I0218 21:03:21.513082 31980 net.cpp:444] Convolution_eltwise13 <- Eltwise13_ReLU27_0_split_2
I0218 21:03:21.513087 31980 net.cpp:418] Convolution_eltwise13 -> Convolution_eltwise13
I0218 21:03:21.514583 31980 net.cpp:150] Setting up Convolution_eltwise13
I0218 21:03:21.514595 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.514598 31980 net.cpp:165] Memory required for data: 74817920
I0218 21:03:21.514603 31980 layer_factory.hpp:77] Creating layer BatchNorm_Convolution_eltwise13
I0218 21:03:21.514611 31980 net.cpp:100] Creating Layer BatchNorm_Convolution_eltwise13
I0218 21:03:21.514614 31980 net.cpp:444] BatchNorm_Convolution_eltwise13 <- Convolution_eltwise13
I0218 21:03:21.514619 31980 net.cpp:405] BatchNorm_Convolution_eltwise13 -> Convolution_eltwise13 (in-place)
I0218 21:03:21.514820 31980 net.cpp:150] Setting up BatchNorm_Convolution_eltwise13
I0218 21:03:21.514827 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.514829 31980 net.cpp:165] Memory required for data: 75002240
I0218 21:03:21.514835 31980 layer_factory.hpp:77] Creating layer Scale_Convolution_eltwise13
I0218 21:03:21.514840 31980 net.cpp:100] Creating Layer Scale_Convolution_eltwise13
I0218 21:03:21.514843 31980 net.cpp:444] Scale_Convolution_eltwise13 <- Convolution_eltwise13
I0218 21:03:21.514847 31980 net.cpp:405] Scale_Convolution_eltwise13 -> Convolution_eltwise13 (in-place)
I0218 21:03:21.514881 31980 layer_factory.hpp:77] Creating layer Scale_Convolution_eltwise13
I0218 21:03:21.514971 31980 net.cpp:150] Setting up Scale_Convolution_eltwise13
I0218 21:03:21.514976 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.514979 31980 net.cpp:165] Memory required for data: 75186560
I0218 21:03:21.514983 31980 layer_factory.hpp:77] Creating layer fuse1
I0218 21:03:21.514989 31980 net.cpp:100] Creating Layer fuse1
I0218 21:03:21.514992 31980 net.cpp:444] fuse1 <- Convolution_eltwise5
I0218 21:03:21.514997 31980 net.cpp:444] fuse1 <- Convolution_eltwise13
I0218 21:03:21.515000 31980 net.cpp:418] fuse1 -> fuse1
I0218 21:03:21.515020 31980 net.cpp:150] Setting up fuse1
I0218 21:03:21.515024 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.515027 31980 net.cpp:165] Memory required for data: 75370880
I0218 21:03:21.515029 31980 layer_factory.hpp:77] Creating layer fuse2
I0218 21:03:21.515033 31980 net.cpp:100] Creating Layer fuse2
I0218 21:03:21.515035 31980 net.cpp:444] fuse2 <- fuse1
I0218 21:03:21.515039 31980 net.cpp:444] fuse2 <- Eltwise21
I0218 21:03:21.515043 31980 net.cpp:418] fuse2 -> fuse2
I0218 21:03:21.515059 31980 net.cpp:150] Setting up fuse2
I0218 21:03:21.515064 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.515066 31980 net.cpp:165] Memory required for data: 75555200
I0218 21:03:21.515069 31980 layer_factory.hpp:77] Creating layer ReLU49
I0218 21:03:21.515074 31980 net.cpp:100] Creating Layer ReLU49
I0218 21:03:21.515075 31980 net.cpp:444] ReLU49 <- fuse2
I0218 21:03:21.515079 31980 net.cpp:405] ReLU49 -> fuse2 (in-place)
I0218 21:03:21.515591 31980 net.cpp:150] Setting up ReLU49
I0218 21:03:21.515602 31980 net.cpp:157] Top shape: 20 64 6 6 (46080)
I0218 21:03:21.515605 31980 net.cpp:165] Memory required for data: 75739520
I0218 21:03:21.515609 31980 layer_factory.hpp:77] Creating layer Pooling1
I0218 21:03:21.515619 31980 net.cpp:100] Creating Layer Pooling1
I0218 21:03:21.515625 31980 net.cpp:444] Pooling1 <- fuse2
I0218 21:03:21.515631 31980 net.cpp:418] Pooling1 -> Pooling1
I0218 21:03:21.515797 31980 net.cpp:150] Setting up Pooling1
I0218 21:03:21.515805 31980 net.cpp:157] Top shape: 20 64 1 1 (1280)
I0218 21:03:21.515807 31980 net.cpp:165] Memory required for data: 75744640
I0218 21:03:21.515810 31980 layer_factory.hpp:77] Creating layer InnerProduct1
I0218 21:03:21.515818 31980 net.cpp:100] Creating Layer InnerProduct1
I0218 21:03:21.515821 31980 net.cpp:444] InnerProduct1 <- Pooling1
I0218 21:03:21.515826 31980 net.cpp:418] InnerProduct1 -> InnerProduct1
I0218 21:03:21.515931 31980 net.cpp:150] Setting up InnerProduct1
I0218 21:03:21.515938 31980 net.cpp:157] Top shape: 20 9 (180)
I0218 21:03:21.515940 31980 net.cpp:165] Memory required for data: 75745360
I0218 21:03:21.515945 31980 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I0218 21:03:21.515949 31980 net.cpp:100] Creating Layer InnerProduct1_InnerProduct1_0_split
I0218 21:03:21.515952 31980 net.cpp:444] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I0218 21:03:21.515957 31980 net.cpp:418] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I0218 21:03:21.515962 31980 net.cpp:418] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I0218 21:03:21.515993 31980 net.cpp:150] Setting up InnerProduct1_InnerProduct1_0_split
I0218 21:03:21.515998 31980 net.cpp:157] Top shape: 20 9 (180)
I0218 21:03:21.516001 31980 net.cpp:157] Top shape: 20 9 (180)
I0218 21:03:21.516003 31980 net.cpp:165] Memory required for data: 75746800
I0218 21:03:21.516005 31980 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0218 21:03:21.516010 31980 net.cpp:100] Creating Layer SoftmaxWithLoss1
I0218 21:03:21.516013 31980 net.cpp:444] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I0218 21:03:21.516016 31980 net.cpp:444] SoftmaxWithLoss1 <- label_paviau_1_split_0
I0218 21:03:21.516021 31980 net.cpp:418] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0218 21:03:21.516027 31980 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0218 21:03:21.516608 31980 net.cpp:150] Setting up SoftmaxWithLoss1
I0218 21:03:21.516618 31980 net.cpp:157] Top shape: (1)
I0218 21:03:21.516621 31980 net.cpp:160]     with loss weight 1
I0218 21:03:21.516630 31980 net.cpp:165] Memory required for data: 75746804
I0218 21:03:21.516633 31980 layer_factory.hpp:77] Creating layer Accuracy1
I0218 21:03:21.516639 31980 net.cpp:100] Creating Layer Accuracy1
I0218 21:03:21.516644 31980 net.cpp:444] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I0218 21:03:21.516647 31980 net.cpp:444] Accuracy1 <- label_paviau_1_split_1
I0218 21:03:21.516651 31980 net.cpp:418] Accuracy1 -> Accuracy1
I0218 21:03:21.516659 31980 net.cpp:150] Setting up Accuracy1
I0218 21:03:21.516661 31980 net.cpp:157] Top shape: (1)
I0218 21:03:21.516664 31980 net.cpp:165] Memory required for data: 75746808
I0218 21:03:21.516666 31980 net.cpp:228] Accuracy1 does not need backward computation.
I0218 21:03:21.516669 31980 net.cpp:226] SoftmaxWithLoss1 needs backward computation.
I0218 21:03:21.516672 31980 net.cpp:226] InnerProduct1_InnerProduct1_0_split needs backward computation.
I0218 21:03:21.516675 31980 net.cpp:226] InnerProduct1 needs backward computation.
I0218 21:03:21.516677 31980 net.cpp:226] Pooling1 needs backward computation.
I0218 21:03:21.516680 31980 net.cpp:226] ReLU49 needs backward computation.
I0218 21:03:21.516682 31980 net.cpp:226] fuse2 needs backward computation.
I0218 21:03:21.516686 31980 net.cpp:226] fuse1 needs backward computation.
I0218 21:03:21.516690 31980 net.cpp:226] Scale_Convolution_eltwise13 needs backward computation.
I0218 21:03:21.516692 31980 net.cpp:226] BatchNorm_Convolution_eltwise13 needs backward computation.
I0218 21:03:21.516695 31980 net.cpp:226] Convolution_eltwise13 needs backward computation.
I0218 21:03:21.516697 31980 net.cpp:226] Scale_Convolution_eltwise5 needs backward computation.
I0218 21:03:21.516703 31980 net.cpp:226] BatchNorm_Convolution_eltwise5 needs backward computation.
I0218 21:03:21.516710 31980 net.cpp:226] Convolution_eltwise5 needs backward computation.
I0218 21:03:21.516713 31980 net.cpp:226] Eltwise21 needs backward computation.
I0218 21:03:21.516716 31980 net.cpp:226] Scale45 needs backward computation.
I0218 21:03:21.516719 31980 net.cpp:226] BatchNorm45 needs backward computation.
I0218 21:03:21.516721 31980 net.cpp:226] Convolution45 needs backward computation.
I0218 21:03:21.516723 31980 net.cpp:226] ReLU42 needs backward computation.
I0218 21:03:21.516726 31980 net.cpp:226] Scale44 needs backward computation.
I0218 21:03:21.516729 31980 net.cpp:226] BatchNorm44 needs backward computation.
I0218 21:03:21.516731 31980 net.cpp:226] Convolution44 needs backward computation.
I0218 21:03:21.516734 31980 net.cpp:226] Eltwise20_ReLU41_0_split needs backward computation.
I0218 21:03:21.516737 31980 net.cpp:226] ReLU41 needs backward computation.
I0218 21:03:21.516739 31980 net.cpp:226] Eltwise20 needs backward computation.
I0218 21:03:21.516742 31980 net.cpp:226] Scale43 needs backward computation.
I0218 21:03:21.516744 31980 net.cpp:226] BatchNorm43 needs backward computation.
I0218 21:03:21.516747 31980 net.cpp:226] Convolution43 needs backward computation.
I0218 21:03:21.516750 31980 net.cpp:226] ReLU40 needs backward computation.
I0218 21:03:21.516752 31980 net.cpp:226] Scale42 needs backward computation.
I0218 21:03:21.516754 31980 net.cpp:226] BatchNorm42 needs backward computation.
I0218 21:03:21.516757 31980 net.cpp:226] Convolution42 needs backward computation.
I0218 21:03:21.516759 31980 net.cpp:226] Eltwise19_ReLU39_0_split needs backward computation.
I0218 21:03:21.516762 31980 net.cpp:226] ReLU39 needs backward computation.
I0218 21:03:21.516765 31980 net.cpp:226] Eltwise19 needs backward computation.
I0218 21:03:21.516768 31980 net.cpp:226] Scale41 needs backward computation.
I0218 21:03:21.516772 31980 net.cpp:226] BatchNorm41 needs backward computation.
I0218 21:03:21.516773 31980 net.cpp:226] Convolution41 needs backward computation.
I0218 21:03:21.516775 31980 net.cpp:226] ReLU38 needs backward computation.
I0218 21:03:21.516778 31980 net.cpp:226] Scale40 needs backward computation.
I0218 21:03:21.516780 31980 net.cpp:226] BatchNorm40 needs backward computation.
I0218 21:03:21.516782 31980 net.cpp:226] Convolution40 needs backward computation.
I0218 21:03:21.516785 31980 net.cpp:226] Eltwise18_ReLU37_0_split needs backward computation.
I0218 21:03:21.516788 31980 net.cpp:226] ReLU37 needs backward computation.
I0218 21:03:21.516790 31980 net.cpp:226] Eltwise18 needs backward computation.
I0218 21:03:21.516793 31980 net.cpp:226] Scale39 needs backward computation.
I0218 21:03:21.516795 31980 net.cpp:226] BatchNorm39 needs backward computation.
I0218 21:03:21.516798 31980 net.cpp:226] Convolution39 needs backward computation.
I0218 21:03:21.516800 31980 net.cpp:226] ReLU36 needs backward computation.
I0218 21:03:21.516803 31980 net.cpp:226] Scale38 needs backward computation.
I0218 21:03:21.516805 31980 net.cpp:226] BatchNorm38 needs backward computation.
I0218 21:03:21.516808 31980 net.cpp:226] Convolution38 needs backward computation.
I0218 21:03:21.516811 31980 net.cpp:226] Eltwise17_ReLU35_0_split needs backward computation.
I0218 21:03:21.516814 31980 net.cpp:226] ReLU35 needs backward computation.
I0218 21:03:21.516816 31980 net.cpp:226] Eltwise17 needs backward computation.
I0218 21:03:21.516819 31980 net.cpp:226] Scale37 needs backward computation.
I0218 21:03:21.516821 31980 net.cpp:226] BatchNorm37 needs backward computation.
I0218 21:03:21.516824 31980 net.cpp:226] Convolution37 needs backward computation.
I0218 21:03:21.516826 31980 net.cpp:226] ReLU34 needs backward computation.
I0218 21:03:21.516829 31980 net.cpp:226] Scale36 needs backward computation.
I0218 21:03:21.516831 31980 net.cpp:226] BatchNorm36 needs backward computation.
I0218 21:03:21.516834 31980 net.cpp:226] Convolution36 needs backward computation.
I0218 21:03:21.516836 31980 net.cpp:226] Scale35 needs backward computation.
I0218 21:03:21.516844 31980 net.cpp:226] BatchNorm35 needs backward computation.
I0218 21:03:21.516845 31980 net.cpp:226] Convolution35 needs backward computation.
I0218 21:03:21.516849 31980 net.cpp:226] Eltwise13_ReLU27_0_split needs backward computation.
I0218 21:03:21.516850 31980 net.cpp:226] ReLU27 needs backward computation.
I0218 21:03:21.516854 31980 net.cpp:226] Eltwise13 needs backward computation.
I0218 21:03:21.516856 31980 net.cpp:226] Scale28 needs backward computation.
I0218 21:03:21.516858 31980 net.cpp:226] BatchNorm28 needs backward computation.
I0218 21:03:21.516860 31980 net.cpp:226] Convolution28 needs backward computation.
I0218 21:03:21.516863 31980 net.cpp:226] ReLU26 needs backward computation.
I0218 21:03:21.516866 31980 net.cpp:226] Scale27 needs backward computation.
I0218 21:03:21.516868 31980 net.cpp:226] BatchNorm27 needs backward computation.
I0218 21:03:21.516870 31980 net.cpp:226] Convolution27 needs backward computation.
I0218 21:03:21.516873 31980 net.cpp:226] Eltwise12_ReLU25_0_split needs backward computation.
I0218 21:03:21.516876 31980 net.cpp:226] ReLU25 needs backward computation.
I0218 21:03:21.516878 31980 net.cpp:226] Eltwise12 needs backward computation.
I0218 21:03:21.516880 31980 net.cpp:226] Scale26 needs backward computation.
I0218 21:03:21.516883 31980 net.cpp:226] BatchNorm26 needs backward computation.
I0218 21:03:21.516885 31980 net.cpp:226] Convolution26 needs backward computation.
I0218 21:03:21.516888 31980 net.cpp:226] ReLU24 needs backward computation.
I0218 21:03:21.516891 31980 net.cpp:226] Scale25 needs backward computation.
I0218 21:03:21.516893 31980 net.cpp:226] BatchNorm25 needs backward computation.
I0218 21:03:21.516896 31980 net.cpp:226] Convolution25 needs backward computation.
I0218 21:03:21.516897 31980 net.cpp:226] Eltwise11_ReLU23_0_split needs backward computation.
I0218 21:03:21.516901 31980 net.cpp:226] ReLU23 needs backward computation.
I0218 21:03:21.516903 31980 net.cpp:226] Eltwise11 needs backward computation.
I0218 21:03:21.516906 31980 net.cpp:226] Scale24 needs backward computation.
I0218 21:03:21.516909 31980 net.cpp:226] BatchNorm24 needs backward computation.
I0218 21:03:21.516911 31980 net.cpp:226] Convolution24 needs backward computation.
I0218 21:03:21.516914 31980 net.cpp:226] ReLU22 needs backward computation.
I0218 21:03:21.516916 31980 net.cpp:226] Scale23 needs backward computation.
I0218 21:03:21.516918 31980 net.cpp:226] BatchNorm23 needs backward computation.
I0218 21:03:21.516921 31980 net.cpp:226] Convolution23 needs backward computation.
I0218 21:03:21.516924 31980 net.cpp:226] Eltwise10_ReLU21_0_split needs backward computation.
I0218 21:03:21.516927 31980 net.cpp:226] ReLU21 needs backward computation.
I0218 21:03:21.516929 31980 net.cpp:226] Eltwise10 needs backward computation.
I0218 21:03:21.516932 31980 net.cpp:226] Scale22 needs backward computation.
I0218 21:03:21.516934 31980 net.cpp:226] BatchNorm22 needs backward computation.
I0218 21:03:21.516937 31980 net.cpp:226] Convolution22 needs backward computation.
I0218 21:03:21.516939 31980 net.cpp:226] ReLU20 needs backward computation.
I0218 21:03:21.516942 31980 net.cpp:226] Scale21 needs backward computation.
I0218 21:03:21.516944 31980 net.cpp:226] BatchNorm21 needs backward computation.
I0218 21:03:21.516947 31980 net.cpp:226] Convolution21 needs backward computation.
I0218 21:03:21.516949 31980 net.cpp:226] Eltwise9_ReLU19_0_split needs backward computation.
I0218 21:03:21.516952 31980 net.cpp:226] ReLU19 needs backward computation.
I0218 21:03:21.516955 31980 net.cpp:226] Eltwise9 needs backward computation.
I0218 21:03:21.516957 31980 net.cpp:226] Scale20 needs backward computation.
I0218 21:03:21.516960 31980 net.cpp:226] BatchNorm20 needs backward computation.
I0218 21:03:21.516963 31980 net.cpp:226] Convolution20 needs backward computation.
I0218 21:03:21.516965 31980 net.cpp:226] ReLU18 needs backward computation.
I0218 21:03:21.516968 31980 net.cpp:226] Scale19 needs backward computation.
I0218 21:03:21.516970 31980 net.cpp:226] BatchNorm19 needs backward computation.
I0218 21:03:21.516976 31980 net.cpp:226] Convolution19 needs backward computation.
I0218 21:03:21.516980 31980 net.cpp:226] Scale18 needs backward computation.
I0218 21:03:21.516983 31980 net.cpp:226] BatchNorm18 needs backward computation.
I0218 21:03:21.516985 31980 net.cpp:226] Convolution18 needs backward computation.
I0218 21:03:21.516988 31980 net.cpp:226] Eltwise5_ReLU11_0_split needs backward computation.
I0218 21:03:21.516990 31980 net.cpp:226] ReLU11 needs backward computation.
I0218 21:03:21.516993 31980 net.cpp:226] Eltwise5 needs backward computation.
I0218 21:03:21.516995 31980 net.cpp:226] Scale11 needs backward computation.
I0218 21:03:21.516999 31980 net.cpp:226] BatchNorm11 needs backward computation.
I0218 21:03:21.517001 31980 net.cpp:226] Convolution11 needs backward computation.
I0218 21:03:21.517004 31980 net.cpp:226] ReLU10 needs backward computation.
I0218 21:03:21.517005 31980 net.cpp:226] Scale10 needs backward computation.
I0218 21:03:21.517009 31980 net.cpp:226] BatchNorm10 needs backward computation.
I0218 21:03:21.517010 31980 net.cpp:226] Convolution10 needs backward computation.
I0218 21:03:21.517014 31980 net.cpp:226] Eltwise4_ReLU9_0_split needs backward computation.
I0218 21:03:21.517016 31980 net.cpp:226] ReLU9 needs backward computation.
I0218 21:03:21.517019 31980 net.cpp:226] Eltwise4 needs backward computation.
I0218 21:03:21.517022 31980 net.cpp:226] Scale9 needs backward computation.
I0218 21:03:21.517024 31980 net.cpp:226] BatchNorm9 needs backward computation.
I0218 21:03:21.517026 31980 net.cpp:226] Convolution9 needs backward computation.
I0218 21:03:21.517030 31980 net.cpp:226] ReLU8 needs backward computation.
I0218 21:03:21.517032 31980 net.cpp:226] Scale8 needs backward computation.
I0218 21:03:21.517035 31980 net.cpp:226] BatchNorm8 needs backward computation.
I0218 21:03:21.517036 31980 net.cpp:226] Convolution8 needs backward computation.
I0218 21:03:21.517040 31980 net.cpp:226] Eltwise3_ReLU7_0_split needs backward computation.
I0218 21:03:21.517045 31980 net.cpp:226] ReLU7 needs backward computation.
I0218 21:03:21.517046 31980 net.cpp:226] Eltwise3 needs backward computation.
I0218 21:03:21.517050 31980 net.cpp:226] Scale7 needs backward computation.
I0218 21:03:21.517052 31980 net.cpp:226] BatchNorm7 needs backward computation.
I0218 21:03:21.517055 31980 net.cpp:226] Convolution7 needs backward computation.
I0218 21:03:21.517057 31980 net.cpp:226] ReLU6 needs backward computation.
I0218 21:03:21.517060 31980 net.cpp:226] Scale6 needs backward computation.
I0218 21:03:21.517062 31980 net.cpp:226] BatchNorm6 needs backward computation.
I0218 21:03:21.517065 31980 net.cpp:226] Convolution6 needs backward computation.
I0218 21:03:21.517067 31980 net.cpp:226] Eltwise2_ReLU5_0_split needs backward computation.
I0218 21:03:21.517071 31980 net.cpp:226] ReLU5 needs backward computation.
I0218 21:03:21.517072 31980 net.cpp:226] Eltwise2 needs backward computation.
I0218 21:03:21.517076 31980 net.cpp:226] Scale5 needs backward computation.
I0218 21:03:21.517078 31980 net.cpp:226] BatchNorm5 needs backward computation.
I0218 21:03:21.517081 31980 net.cpp:226] Convolution5 needs backward computation.
I0218 21:03:21.517083 31980 net.cpp:226] ReLU4 needs backward computation.
I0218 21:03:21.517086 31980 net.cpp:226] Scale4 needs backward computation.
I0218 21:03:21.517088 31980 net.cpp:226] BatchNorm4 needs backward computation.
I0218 21:03:21.517091 31980 net.cpp:226] Convolution4 needs backward computation.
I0218 21:03:21.517093 31980 net.cpp:226] Eltwise1_ReLU3_0_split needs backward computation.
I0218 21:03:21.517096 31980 net.cpp:226] ReLU3 needs backward computation.
I0218 21:03:21.517099 31980 net.cpp:226] Eltwise1 needs backward computation.
I0218 21:03:21.517102 31980 net.cpp:226] Scale3 needs backward computation.
I0218 21:03:21.517104 31980 net.cpp:226] BatchNorm3 needs backward computation.
I0218 21:03:21.517107 31980 net.cpp:226] Convolution3 needs backward computation.
I0218 21:03:21.517110 31980 net.cpp:226] ReLU2 needs backward computation.
I0218 21:03:21.517114 31980 net.cpp:226] Scale2 needs backward computation.
I0218 21:03:21.517119 31980 net.cpp:226] BatchNorm2 needs backward computation.
I0218 21:03:21.517122 31980 net.cpp:226] Convolution2 needs backward computation.
I0218 21:03:21.517125 31980 net.cpp:226] Convolution1_ReLU1_0_split needs backward computation.
I0218 21:03:21.517128 31980 net.cpp:226] ReLU1 needs backward computation.
I0218 21:03:21.517130 31980 net.cpp:226] Scale1 needs backward computation.
I0218 21:03:21.517133 31980 net.cpp:226] BatchNorm1 needs backward computation.
I0218 21:03:21.517135 31980 net.cpp:226] Convolution1 needs backward computation.
I0218 21:03:21.517138 31980 net.cpp:228] label_paviau_1_split does not need backward computation.
I0218 21:03:21.517143 31980 net.cpp:228] paviau does not need backward computation.
I0218 21:03:21.517145 31980 net.cpp:270] This network produces output Accuracy1
I0218 21:03:21.517148 31980 net.cpp:270] This network produces output SoftmaxWithLoss1
I0218 21:03:21.517207 31980 net.cpp:283] Network initialization done.
I0218 21:03:21.517494 31980 solver.cpp:60] Solver scaffolding done.
I0218 21:03:21.523844 31980 caffe.cpp:252] Starting Optimization
I0218 21:03:21.523851 31980 solver.cpp:279] Solving DFFN_paviau
I0218 21:03:21.523854 31980 solver.cpp:280] Learning Rate Policy: multistep
I0218 21:03:21.529422 31980 solver.cpp:337] Iteration 0, Testing net (#0)
I0218 21:03:38.037385 31980 solver.cpp:404]     Test net output #0: Accuracy1 = 0.0221373
I0218 21:03:38.037427 31980 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 87.3382 (* 1 = 87.3382 loss)
I0218 21:03:38.188681 31980 solver.cpp:228] Iteration 0, loss = 2.22859
I0218 21:03:38.188706 31980 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 2.22859 (* 1 = 2.22859 loss)
I0218 21:03:38.188719 31980 sgd_solver.cpp:106] Iteration 0, lr = 0.1
I0218 21:05:03.661970 31980 solver.cpp:228] Iteration 1000, loss = 0.000164512
I0218 21:05:03.662067 31980 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00016452 (* 1 = 0.00016452 loss)
I0218 21:05:03.662075 31980 sgd_solver.cpp:106] Iteration 1000, lr = 0.1
I0218 21:06:30.057350 31980 solver.cpp:228] Iteration 2000, loss = 6.24902e-05
I0218 21:06:30.057464 31980 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 6.24975e-05 (* 1 = 6.24975e-05 loss)
I0218 21:06:30.057472 31980 sgd_solver.cpp:106] Iteration 2000, lr = 0.1
I0218 21:07:55.068323 31980 solver.cpp:228] Iteration 3000, loss = 5.60821e-05
I0218 21:07:55.068449 31980 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 5.60895e-05 (* 1 = 5.60895e-05 loss)
I0218 21:07:55.068457 31980 sgd_solver.cpp:106] Iteration 3000, lr = 0.1
I0218 21:09:19.386245 31980 solver.cpp:228] Iteration 4000, loss = 6.91693e-05
I0218 21:09:19.386411 31980 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 6.91766e-05 (* 1 = 6.91766e-05 loss)
I0218 21:09:19.386448 31980 sgd_solver.cpp:106] Iteration 4000, lr = 0.1
I0218 21:10:43.629676 31980 solver.cpp:228] Iteration 5000, loss = 7.25289e-05
I0218 21:10:43.629798 31980 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 7.25361e-05 (* 1 = 7.25361e-05 loss)
I0218 21:10:43.629804 31980 sgd_solver.cpp:46] MultiStep Status: Iteration 5000, step = 1
I0218 21:10:43.629808 31980 sgd_solver.cpp:106] Iteration 5000, lr = 0.01
I0218 21:12:08.914331 31980 solver.cpp:228] Iteration 6000, loss = 0.000117083
I0218 21:12:08.914459 31980 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00011709 (* 1 = 0.00011709 loss)
I0218 21:12:08.914467 31980 sgd_solver.cpp:106] Iteration 6000, lr = 0.01
I0218 21:13:36.232605 31980 solver.cpp:228] Iteration 7000, loss = 5.58087e-05
I0218 21:13:36.232726 31980 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 5.5816e-05 (* 1 = 5.5816e-05 loss)
I0218 21:13:36.232734 31980 sgd_solver.cpp:106] Iteration 7000, lr = 0.01
I0218 21:15:01.932515 31980 solver.cpp:228] Iteration 8000, loss = 8.97174e-05
I0218 21:15:01.932655 31980 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 8.97247e-05 (* 1 = 8.97247e-05 loss)
I0218 21:15:01.932664 31980 sgd_solver.cpp:106] Iteration 8000, lr = 0.01
I0218 21:16:27.824134 31980 solver.cpp:228] Iteration 9000, loss = 5.8617e-05
I0218 21:16:27.824254 31980 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 5.86243e-05 (* 1 = 5.86243e-05 loss)
I0218 21:16:27.824260 31980 sgd_solver.cpp:106] Iteration 9000, lr = 0.01
I0218 21:17:52.751780 31980 solver.cpp:228] Iteration 10000, loss = 5.05772e-05
I0218 21:17:52.751912 31980 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 5.05846e-05 (* 1 = 5.05846e-05 loss)
I0218 21:17:52.751919 31980 sgd_solver.cpp:46] MultiStep Status: Iteration 10000, step = 2
I0218 21:17:52.751924 31980 sgd_solver.cpp:106] Iteration 10000, lr = 0.001
I0218 21:19:17.879793 31980 solver.cpp:228] Iteration 11000, loss = 6.62491e-05
I0218 21:19:17.879912 31980 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 6.62564e-05 (* 1 = 6.62564e-05 loss)
I0218 21:19:17.879920 31980 sgd_solver.cpp:106] Iteration 11000, lr = 0.001
I0218 21:20:43.222931 31980 solver.cpp:228] Iteration 12000, loss = 0.000101564
I0218 21:20:43.223052 31980 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000101571 (* 1 = 0.000101571 loss)
I0218 21:20:43.223060 31980 sgd_solver.cpp:106] Iteration 12000, lr = 0.001
I0218 21:22:08.990537 31980 solver.cpp:228] Iteration 13000, loss = 8.94649e-05
I0218 21:22:08.990654 31980 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 8.94722e-05 (* 1 = 8.94722e-05 loss)
I0218 21:22:08.990661 31980 sgd_solver.cpp:106] Iteration 13000, lr = 0.001
I0218 21:23:36.400384 31980 solver.cpp:228] Iteration 14000, loss = 4.452e-05
I0218 21:23:36.400497 31980 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 4.45273e-05 (* 1 = 4.45273e-05 loss)
I0218 21:23:36.400506 31980 sgd_solver.cpp:106] Iteration 14000, lr = 0.001
I0218 21:25:04.476464 31980 solver.cpp:228] Iteration 15000, loss = 4.51048e-05
I0218 21:25:04.476562 31980 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 4.51121e-05 (* 1 = 4.51121e-05 loss)
I0218 21:25:04.476569 31980 sgd_solver.cpp:46] MultiStep Status: Iteration 15000, step = 3
I0218 21:25:04.476574 31980 sgd_solver.cpp:106] Iteration 15000, lr = 0.0001
I0218 21:26:30.707860 31980 solver.cpp:228] Iteration 16000, loss = 6.3253e-05
I0218 21:26:30.707975 31980 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 6.32604e-05 (* 1 = 6.32604e-05 loss)
I0218 21:26:30.707984 31980 sgd_solver.cpp:106] Iteration 16000, lr = 0.0001
I0218 21:27:57.942674 31980 solver.cpp:228] Iteration 17000, loss = 9.7403e-05
I0218 21:27:57.942801 31980 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 9.74104e-05 (* 1 = 9.74104e-05 loss)
I0218 21:27:57.942811 31980 sgd_solver.cpp:106] Iteration 17000, lr = 0.0001
I0218 21:29:23.953508 31980 solver.cpp:228] Iteration 18000, loss = 9.89231e-05
I0218 21:29:23.953609 31980 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 9.89304e-05 (* 1 = 9.89304e-05 loss)
I0218 21:29:23.953619 31980 sgd_solver.cpp:106] Iteration 18000, lr = 0.0001
I0218 21:30:48.853422 31980 solver.cpp:228] Iteration 19000, loss = 4.84943e-05
I0218 21:30:48.853539 31980 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 4.85016e-05 (* 1 = 4.85016e-05 loss)
I0218 21:30:48.853547 31980 sgd_solver.cpp:106] Iteration 19000, lr = 0.0001
I0218 21:32:13.582834 31980 solver.cpp:454] Snapshotting to binary proto file ./snapshot/paviau/_iter_20000.caffemodel
I0218 21:32:13.597954 31980 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshot/paviau/_iter_20000.solverstate
I0218 21:32:13.619544 31980 solver.cpp:317] Iteration 20000, loss = 4.69953e-05
I0218 21:32:13.619573 31980 solver.cpp:337] Iteration 20000, Testing net (#0)
I0218 21:32:30.130129 31980 solver.cpp:404]     Test net output #0: Accuracy1 = 0.986351
I0218 21:32:30.130163 31980 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.0618354 (* 1 = 0.0618354 loss)
I0218 21:32:30.130168 31980 solver.cpp:322] Optimization Done.
I0218 21:32:30.130172 31980 caffe.cpp:255] Optimization Done.
