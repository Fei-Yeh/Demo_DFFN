I0218 21:49:20.788635  9736 caffe.cpp:218] Using GPUs 0
I0218 21:49:20.834633  9736 caffe.cpp:223] GPU 0: GeForce GTX TITAN X
I0218 21:49:21.196820  9736 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1077
test_interval: 20000
base_lr: 0.1
display: 1000
max_iter: 20000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 20000
snapshot_prefix: "./snapshot/salinas/"
solver_mode: GPU
device_id: 0
net: "./prototxt_files/train_salinas.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 5000
stepvalue: 10000
stepvalue: 15000
stepvalue: 20000
I0218 21:49:21.196928  9736 solver.cpp:91] Creating training net from net file: ./prototxt_files/train_salinas.prototxt
I0218 21:49:21.197661  9736 net.cpp:332] The NetState phase (0) differed from the phase (1) specified by a rule in layer salinas
I0218 21:49:21.197710  9736 net.cpp:332] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I0218 21:49:21.198194  9736 net.cpp:58] Initializing net from parameters: 
name: "DFFN_salinas"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "salinas"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "samples/salinas/train.txt"
    batch_size: 100
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "data"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution11"
  top: "Convolution11"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Convolution11"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Convolution10"
  bottom: "Convolution12"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "Convolution13"
  top: "Convolution13"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Convolution15"
  top: "Convolution15"
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Convolution15"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution16"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution17"
  top: "Convolution17"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Convolution17"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution18"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution20"
  top: "Convolution20"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Convolution19"
  bottom: "Convolution21"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU20"
  type: "ReLU"
  bottom: "Convolution22"
  top: "Convolution22"
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Convolution22"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Eltwise9"
  bottom: "Convolution23"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "Convolution24"
  top: "Convolution24"
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Convolution24"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution25"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "Eltwise11"
  top: "Eltwise11"
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU24"
  type: "ReLU"
  bottom: "Convolution26"
  top: "Convolution26"
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Convolution26"
  top: "Convolution27"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Eltwise11"
  bottom: "Convolution27"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution_eltwise4"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution_eltwise4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm_Convolution_eltwise4"
  type: "BatchNorm"
  bottom: "Convolution_eltwise4"
  top: "Convolution_eltwise4"
}
layer {
  name: "Scale_Convolution_eltwise4"
  type: "Scale"
  bottom: "Convolution_eltwise4"
  top: "Convolution_eltwise4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution_eltwise8"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution_eltwise8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm_Convolution_eltwise8"
  type: "BatchNorm"
  bottom: "Convolution_eltwise8"
  top: "Convolution_eltwise8"
}
layer {
  name: "Scale_Convolution_eltwise8"
  type: "Scale"
  bottom: "Convolution_eltwise8"
  top: "Convolution_eltwise8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "fuse1"
  type: "Eltwise"
  bottom: "Convolution_eltwise4"
  bottom: "Convolution_eltwise8"
  top: "fuse1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "fuse2"
  type: "Eltwise"
  bottom: "fuse1"
  bottom: "Eltwise12"
  top: "fuse2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "fuse2"
  top: "fuse2"
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "fuse2"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "InnerProduct1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 16
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "label"
  top: "SoftmaxWithLoss1"
}
I0218 21:49:21.198549  9736 layer_factory.hpp:77] Creating layer salinas
I0218 21:49:21.198563  9736 net.cpp:100] Creating Layer salinas
I0218 21:49:21.198570  9736 net.cpp:418] salinas -> data
I0218 21:49:21.198588  9736 net.cpp:418] salinas -> label
I0218 21:49:21.198598  9736 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: samples/salinas/train.txt
I0218 21:49:21.198622  9736 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I0218 21:49:21.199378  9736 hdf5.cpp:36] Datatype class: H5T_FLOAT
I0218 21:49:21.211901  9736 net.cpp:150] Setting up salinas
I0218 21:49:21.211935  9736 net.cpp:157] Top shape: 100 10 27 27 (729000)
I0218 21:49:21.211939  9736 net.cpp:157] Top shape: 100 1 (100)
I0218 21:49:21.211942  9736 net.cpp:165] Memory required for data: 2916400
I0218 21:49:21.211949  9736 layer_factory.hpp:77] Creating layer Convolution1
I0218 21:49:21.211968  9736 net.cpp:100] Creating Layer Convolution1
I0218 21:49:21.211974  9736 net.cpp:444] Convolution1 <- data
I0218 21:49:21.211985  9736 net.cpp:418] Convolution1 -> Convolution1
I0218 21:49:21.393465  9736 net.cpp:150] Setting up Convolution1
I0218 21:49:21.393496  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.393499  9736 net.cpp:165] Memory required for data: 7582000
I0218 21:49:21.393523  9736 layer_factory.hpp:77] Creating layer BatchNorm1
I0218 21:49:21.393534  9736 net.cpp:100] Creating Layer BatchNorm1
I0218 21:49:21.393539  9736 net.cpp:444] BatchNorm1 <- Convolution1
I0218 21:49:21.393544  9736 net.cpp:405] BatchNorm1 -> Convolution1 (in-place)
I0218 21:49:21.393692  9736 net.cpp:150] Setting up BatchNorm1
I0218 21:49:21.393699  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.393702  9736 net.cpp:165] Memory required for data: 12247600
I0218 21:49:21.393710  9736 layer_factory.hpp:77] Creating layer Scale1
I0218 21:49:21.393716  9736 net.cpp:100] Creating Layer Scale1
I0218 21:49:21.393719  9736 net.cpp:444] Scale1 <- Convolution1
I0218 21:49:21.393723  9736 net.cpp:405] Scale1 -> Convolution1 (in-place)
I0218 21:49:21.393759  9736 layer_factory.hpp:77] Creating layer Scale1
I0218 21:49:21.393846  9736 net.cpp:150] Setting up Scale1
I0218 21:49:21.393852  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.393854  9736 net.cpp:165] Memory required for data: 16913200
I0218 21:49:21.393859  9736 layer_factory.hpp:77] Creating layer ReLU1
I0218 21:49:21.393865  9736 net.cpp:100] Creating Layer ReLU1
I0218 21:49:21.393868  9736 net.cpp:444] ReLU1 <- Convolution1
I0218 21:49:21.393872  9736 net.cpp:405] ReLU1 -> Convolution1 (in-place)
I0218 21:49:21.394373  9736 net.cpp:150] Setting up ReLU1
I0218 21:49:21.394384  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.394387  9736 net.cpp:165] Memory required for data: 21578800
I0218 21:49:21.394390  9736 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I0218 21:49:21.394397  9736 net.cpp:100] Creating Layer Convolution1_ReLU1_0_split
I0218 21:49:21.394399  9736 net.cpp:444] Convolution1_ReLU1_0_split <- Convolution1
I0218 21:49:21.394404  9736 net.cpp:418] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I0218 21:49:21.394410  9736 net.cpp:418] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I0218 21:49:21.394443  9736 net.cpp:150] Setting up Convolution1_ReLU1_0_split
I0218 21:49:21.394448  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.394453  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.394454  9736 net.cpp:165] Memory required for data: 30910000
I0218 21:49:21.394457  9736 layer_factory.hpp:77] Creating layer Convolution2
I0218 21:49:21.394466  9736 net.cpp:100] Creating Layer Convolution2
I0218 21:49:21.394469  9736 net.cpp:444] Convolution2 <- Convolution1_ReLU1_0_split_0
I0218 21:49:21.394474  9736 net.cpp:418] Convolution2 -> Convolution2
I0218 21:49:21.395773  9736 net.cpp:150] Setting up Convolution2
I0218 21:49:21.395794  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.395797  9736 net.cpp:165] Memory required for data: 35575600
I0218 21:49:21.395804  9736 layer_factory.hpp:77] Creating layer BatchNorm2
I0218 21:49:21.395810  9736 net.cpp:100] Creating Layer BatchNorm2
I0218 21:49:21.395814  9736 net.cpp:444] BatchNorm2 <- Convolution2
I0218 21:49:21.395819  9736 net.cpp:405] BatchNorm2 -> Convolution2 (in-place)
I0218 21:49:21.395952  9736 net.cpp:150] Setting up BatchNorm2
I0218 21:49:21.395958  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.395961  9736 net.cpp:165] Memory required for data: 40241200
I0218 21:49:21.395967  9736 layer_factory.hpp:77] Creating layer Scale2
I0218 21:49:21.395972  9736 net.cpp:100] Creating Layer Scale2
I0218 21:49:21.395975  9736 net.cpp:444] Scale2 <- Convolution2
I0218 21:49:21.395979  9736 net.cpp:405] Scale2 -> Convolution2 (in-place)
I0218 21:49:21.396008  9736 layer_factory.hpp:77] Creating layer Scale2
I0218 21:49:21.396086  9736 net.cpp:150] Setting up Scale2
I0218 21:49:21.396092  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.396095  9736 net.cpp:165] Memory required for data: 44906800
I0218 21:49:21.396100  9736 layer_factory.hpp:77] Creating layer ReLU2
I0218 21:49:21.396103  9736 net.cpp:100] Creating Layer ReLU2
I0218 21:49:21.396106  9736 net.cpp:444] ReLU2 <- Convolution2
I0218 21:49:21.396111  9736 net.cpp:405] ReLU2 -> Convolution2 (in-place)
I0218 21:49:21.396235  9736 net.cpp:150] Setting up ReLU2
I0218 21:49:21.396243  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.396245  9736 net.cpp:165] Memory required for data: 49572400
I0218 21:49:21.396248  9736 layer_factory.hpp:77] Creating layer Convolution3
I0218 21:49:21.396255  9736 net.cpp:100] Creating Layer Convolution3
I0218 21:49:21.396258  9736 net.cpp:444] Convolution3 <- Convolution2
I0218 21:49:21.396263  9736 net.cpp:418] Convolution3 -> Convolution3
I0218 21:49:21.397542  9736 net.cpp:150] Setting up Convolution3
I0218 21:49:21.397554  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.397557  9736 net.cpp:165] Memory required for data: 54238000
I0218 21:49:21.397562  9736 layer_factory.hpp:77] Creating layer BatchNorm3
I0218 21:49:21.397568  9736 net.cpp:100] Creating Layer BatchNorm3
I0218 21:49:21.397572  9736 net.cpp:444] BatchNorm3 <- Convolution3
I0218 21:49:21.397577  9736 net.cpp:405] BatchNorm3 -> Convolution3 (in-place)
I0218 21:49:21.397706  9736 net.cpp:150] Setting up BatchNorm3
I0218 21:49:21.397712  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.397716  9736 net.cpp:165] Memory required for data: 58903600
I0218 21:49:21.397723  9736 layer_factory.hpp:77] Creating layer Scale3
I0218 21:49:21.397727  9736 net.cpp:100] Creating Layer Scale3
I0218 21:49:21.397732  9736 net.cpp:444] Scale3 <- Convolution3
I0218 21:49:21.397735  9736 net.cpp:405] Scale3 -> Convolution3 (in-place)
I0218 21:49:21.397763  9736 layer_factory.hpp:77] Creating layer Scale3
I0218 21:49:21.397842  9736 net.cpp:150] Setting up Scale3
I0218 21:49:21.397848  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.397851  9736 net.cpp:165] Memory required for data: 63569200
I0218 21:49:21.397856  9736 layer_factory.hpp:77] Creating layer Eltwise1
I0218 21:49:21.397862  9736 net.cpp:100] Creating Layer Eltwise1
I0218 21:49:21.397866  9736 net.cpp:444] Eltwise1 <- Convolution1_ReLU1_0_split_1
I0218 21:49:21.397868  9736 net.cpp:444] Eltwise1 <- Convolution3
I0218 21:49:21.397872  9736 net.cpp:418] Eltwise1 -> Eltwise1
I0218 21:49:21.397892  9736 net.cpp:150] Setting up Eltwise1
I0218 21:49:21.397898  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.397902  9736 net.cpp:165] Memory required for data: 68234800
I0218 21:49:21.397903  9736 layer_factory.hpp:77] Creating layer ReLU3
I0218 21:49:21.397907  9736 net.cpp:100] Creating Layer ReLU3
I0218 21:49:21.397912  9736 net.cpp:444] ReLU3 <- Eltwise1
I0218 21:49:21.397919  9736 net.cpp:405] ReLU3 -> Eltwise1 (in-place)
I0218 21:49:21.398416  9736 net.cpp:150] Setting up ReLU3
I0218 21:49:21.398427  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.398430  9736 net.cpp:165] Memory required for data: 72900400
I0218 21:49:21.398433  9736 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I0218 21:49:21.398439  9736 net.cpp:100] Creating Layer Eltwise1_ReLU3_0_split
I0218 21:49:21.398442  9736 net.cpp:444] Eltwise1_ReLU3_0_split <- Eltwise1
I0218 21:49:21.398447  9736 net.cpp:418] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I0218 21:49:21.398454  9736 net.cpp:418] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I0218 21:49:21.398484  9736 net.cpp:150] Setting up Eltwise1_ReLU3_0_split
I0218 21:49:21.398489  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.398494  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.398495  9736 net.cpp:165] Memory required for data: 82231600
I0218 21:49:21.398499  9736 layer_factory.hpp:77] Creating layer Convolution4
I0218 21:49:21.398506  9736 net.cpp:100] Creating Layer Convolution4
I0218 21:49:21.398509  9736 net.cpp:444] Convolution4 <- Eltwise1_ReLU3_0_split_0
I0218 21:49:21.398514  9736 net.cpp:418] Convolution4 -> Convolution4
I0218 21:49:21.399454  9736 net.cpp:150] Setting up Convolution4
I0218 21:49:21.399467  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.399471  9736 net.cpp:165] Memory required for data: 86897200
I0218 21:49:21.399475  9736 layer_factory.hpp:77] Creating layer BatchNorm4
I0218 21:49:21.399482  9736 net.cpp:100] Creating Layer BatchNorm4
I0218 21:49:21.399484  9736 net.cpp:444] BatchNorm4 <- Convolution4
I0218 21:49:21.399490  9736 net.cpp:405] BatchNorm4 -> Convolution4 (in-place)
I0218 21:49:21.399641  9736 net.cpp:150] Setting up BatchNorm4
I0218 21:49:21.399648  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.399652  9736 net.cpp:165] Memory required for data: 91562800
I0218 21:49:21.399657  9736 layer_factory.hpp:77] Creating layer Scale4
I0218 21:49:21.399662  9736 net.cpp:100] Creating Layer Scale4
I0218 21:49:21.399665  9736 net.cpp:444] Scale4 <- Convolution4
I0218 21:49:21.399670  9736 net.cpp:405] Scale4 -> Convolution4 (in-place)
I0218 21:49:21.399700  9736 layer_factory.hpp:77] Creating layer Scale4
I0218 21:49:21.399785  9736 net.cpp:150] Setting up Scale4
I0218 21:49:21.399791  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.399793  9736 net.cpp:165] Memory required for data: 96228400
I0218 21:49:21.399798  9736 layer_factory.hpp:77] Creating layer ReLU4
I0218 21:49:21.399803  9736 net.cpp:100] Creating Layer ReLU4
I0218 21:49:21.399806  9736 net.cpp:444] ReLU4 <- Convolution4
I0218 21:49:21.399811  9736 net.cpp:405] ReLU4 -> Convolution4 (in-place)
I0218 21:49:21.400311  9736 net.cpp:150] Setting up ReLU4
I0218 21:49:21.400321  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.400324  9736 net.cpp:165] Memory required for data: 100894000
I0218 21:49:21.400327  9736 layer_factory.hpp:77] Creating layer Convolution5
I0218 21:49:21.400336  9736 net.cpp:100] Creating Layer Convolution5
I0218 21:49:21.400339  9736 net.cpp:444] Convolution5 <- Convolution4
I0218 21:49:21.400346  9736 net.cpp:418] Convolution5 -> Convolution5
I0218 21:49:21.401671  9736 net.cpp:150] Setting up Convolution5
I0218 21:49:21.401684  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.401686  9736 net.cpp:165] Memory required for data: 105559600
I0218 21:49:21.401691  9736 layer_factory.hpp:77] Creating layer BatchNorm5
I0218 21:49:21.401698  9736 net.cpp:100] Creating Layer BatchNorm5
I0218 21:49:21.401702  9736 net.cpp:444] BatchNorm5 <- Convolution5
I0218 21:49:21.401706  9736 net.cpp:405] BatchNorm5 -> Convolution5 (in-place)
I0218 21:49:21.401854  9736 net.cpp:150] Setting up BatchNorm5
I0218 21:49:21.401860  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.401863  9736 net.cpp:165] Memory required for data: 110225200
I0218 21:49:21.401871  9736 layer_factory.hpp:77] Creating layer Scale5
I0218 21:49:21.401880  9736 net.cpp:100] Creating Layer Scale5
I0218 21:49:21.401888  9736 net.cpp:444] Scale5 <- Convolution5
I0218 21:49:21.401892  9736 net.cpp:405] Scale5 -> Convolution5 (in-place)
I0218 21:49:21.401926  9736 layer_factory.hpp:77] Creating layer Scale5
I0218 21:49:21.402014  9736 net.cpp:150] Setting up Scale5
I0218 21:49:21.402019  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.402022  9736 net.cpp:165] Memory required for data: 114890800
I0218 21:49:21.402027  9736 layer_factory.hpp:77] Creating layer Eltwise2
I0218 21:49:21.402032  9736 net.cpp:100] Creating Layer Eltwise2
I0218 21:49:21.402035  9736 net.cpp:444] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I0218 21:49:21.402040  9736 net.cpp:444] Eltwise2 <- Convolution5
I0218 21:49:21.402043  9736 net.cpp:418] Eltwise2 -> Eltwise2
I0218 21:49:21.402062  9736 net.cpp:150] Setting up Eltwise2
I0218 21:49:21.402067  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.402070  9736 net.cpp:165] Memory required for data: 119556400
I0218 21:49:21.402072  9736 layer_factory.hpp:77] Creating layer ReLU5
I0218 21:49:21.402076  9736 net.cpp:100] Creating Layer ReLU5
I0218 21:49:21.402079  9736 net.cpp:444] ReLU5 <- Eltwise2
I0218 21:49:21.402083  9736 net.cpp:405] ReLU5 -> Eltwise2 (in-place)
I0218 21:49:21.402216  9736 net.cpp:150] Setting up ReLU5
I0218 21:49:21.402223  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.402226  9736 net.cpp:165] Memory required for data: 124222000
I0218 21:49:21.402230  9736 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I0218 21:49:21.402235  9736 net.cpp:100] Creating Layer Eltwise2_ReLU5_0_split
I0218 21:49:21.402236  9736 net.cpp:444] Eltwise2_ReLU5_0_split <- Eltwise2
I0218 21:49:21.402242  9736 net.cpp:418] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I0218 21:49:21.402248  9736 net.cpp:418] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I0218 21:49:21.402279  9736 net.cpp:150] Setting up Eltwise2_ReLU5_0_split
I0218 21:49:21.402284  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.402287  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.402290  9736 net.cpp:165] Memory required for data: 133553200
I0218 21:49:21.402292  9736 layer_factory.hpp:77] Creating layer Convolution6
I0218 21:49:21.402302  9736 net.cpp:100] Creating Layer Convolution6
I0218 21:49:21.402304  9736 net.cpp:444] Convolution6 <- Eltwise2_ReLU5_0_split_0
I0218 21:49:21.402310  9736 net.cpp:418] Convolution6 -> Convolution6
I0218 21:49:21.403642  9736 net.cpp:150] Setting up Convolution6
I0218 21:49:21.403656  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.403659  9736 net.cpp:165] Memory required for data: 138218800
I0218 21:49:21.403664  9736 layer_factory.hpp:77] Creating layer BatchNorm6
I0218 21:49:21.403671  9736 net.cpp:100] Creating Layer BatchNorm6
I0218 21:49:21.403673  9736 net.cpp:444] BatchNorm6 <- Convolution6
I0218 21:49:21.403678  9736 net.cpp:405] BatchNorm6 -> Convolution6 (in-place)
I0218 21:49:21.403825  9736 net.cpp:150] Setting up BatchNorm6
I0218 21:49:21.403831  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.403832  9736 net.cpp:165] Memory required for data: 142884400
I0218 21:49:21.403838  9736 layer_factory.hpp:77] Creating layer Scale6
I0218 21:49:21.403843  9736 net.cpp:100] Creating Layer Scale6
I0218 21:49:21.403846  9736 net.cpp:444] Scale6 <- Convolution6
I0218 21:49:21.403851  9736 net.cpp:405] Scale6 -> Convolution6 (in-place)
I0218 21:49:21.403879  9736 layer_factory.hpp:77] Creating layer Scale6
I0218 21:49:21.403970  9736 net.cpp:150] Setting up Scale6
I0218 21:49:21.403976  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.403980  9736 net.cpp:165] Memory required for data: 147550000
I0218 21:49:21.403983  9736 layer_factory.hpp:77] Creating layer ReLU6
I0218 21:49:21.403988  9736 net.cpp:100] Creating Layer ReLU6
I0218 21:49:21.403991  9736 net.cpp:444] ReLU6 <- Convolution6
I0218 21:49:21.403995  9736 net.cpp:405] ReLU6 -> Convolution6 (in-place)
I0218 21:49:21.404498  9736 net.cpp:150] Setting up ReLU6
I0218 21:49:21.404515  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.404518  9736 net.cpp:165] Memory required for data: 152215600
I0218 21:49:21.404521  9736 layer_factory.hpp:77] Creating layer Convolution7
I0218 21:49:21.404530  9736 net.cpp:100] Creating Layer Convolution7
I0218 21:49:21.404533  9736 net.cpp:444] Convolution7 <- Convolution6
I0218 21:49:21.404541  9736 net.cpp:418] Convolution7 -> Convolution7
I0218 21:49:21.405517  9736 net.cpp:150] Setting up Convolution7
I0218 21:49:21.405529  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.405532  9736 net.cpp:165] Memory required for data: 156881200
I0218 21:49:21.405539  9736 layer_factory.hpp:77] Creating layer BatchNorm7
I0218 21:49:21.405545  9736 net.cpp:100] Creating Layer BatchNorm7
I0218 21:49:21.405548  9736 net.cpp:444] BatchNorm7 <- Convolution7
I0218 21:49:21.405555  9736 net.cpp:405] BatchNorm7 -> Convolution7 (in-place)
I0218 21:49:21.405704  9736 net.cpp:150] Setting up BatchNorm7
I0218 21:49:21.405709  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.405711  9736 net.cpp:165] Memory required for data: 161546800
I0218 21:49:21.405717  9736 layer_factory.hpp:77] Creating layer Scale7
I0218 21:49:21.405725  9736 net.cpp:100] Creating Layer Scale7
I0218 21:49:21.405727  9736 net.cpp:444] Scale7 <- Convolution7
I0218 21:49:21.405731  9736 net.cpp:405] Scale7 -> Convolution7 (in-place)
I0218 21:49:21.405762  9736 layer_factory.hpp:77] Creating layer Scale7
I0218 21:49:21.405849  9736 net.cpp:150] Setting up Scale7
I0218 21:49:21.405855  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.405858  9736 net.cpp:165] Memory required for data: 166212400
I0218 21:49:21.405863  9736 layer_factory.hpp:77] Creating layer Eltwise3
I0218 21:49:21.405869  9736 net.cpp:100] Creating Layer Eltwise3
I0218 21:49:21.405871  9736 net.cpp:444] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I0218 21:49:21.405875  9736 net.cpp:444] Eltwise3 <- Convolution7
I0218 21:49:21.405879  9736 net.cpp:418] Eltwise3 -> Eltwise3
I0218 21:49:21.405900  9736 net.cpp:150] Setting up Eltwise3
I0218 21:49:21.405905  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.405906  9736 net.cpp:165] Memory required for data: 170878000
I0218 21:49:21.405910  9736 layer_factory.hpp:77] Creating layer ReLU7
I0218 21:49:21.405913  9736 net.cpp:100] Creating Layer ReLU7
I0218 21:49:21.405916  9736 net.cpp:444] ReLU7 <- Eltwise3
I0218 21:49:21.405921  9736 net.cpp:405] ReLU7 -> Eltwise3 (in-place)
I0218 21:49:21.406424  9736 net.cpp:150] Setting up ReLU7
I0218 21:49:21.406433  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.406436  9736 net.cpp:165] Memory required for data: 175543600
I0218 21:49:21.406440  9736 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I0218 21:49:21.406445  9736 net.cpp:100] Creating Layer Eltwise3_ReLU7_0_split
I0218 21:49:21.406450  9736 net.cpp:444] Eltwise3_ReLU7_0_split <- Eltwise3
I0218 21:49:21.406453  9736 net.cpp:418] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I0218 21:49:21.406460  9736 net.cpp:418] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I0218 21:49:21.406494  9736 net.cpp:150] Setting up Eltwise3_ReLU7_0_split
I0218 21:49:21.406499  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.406502  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.406505  9736 net.cpp:165] Memory required for data: 184874800
I0218 21:49:21.406508  9736 layer_factory.hpp:77] Creating layer Convolution8
I0218 21:49:21.406517  9736 net.cpp:100] Creating Layer Convolution8
I0218 21:49:21.406519  9736 net.cpp:444] Convolution8 <- Eltwise3_ReLU7_0_split_0
I0218 21:49:21.406524  9736 net.cpp:418] Convolution8 -> Convolution8
I0218 21:49:21.407881  9736 net.cpp:150] Setting up Convolution8
I0218 21:49:21.407893  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.407896  9736 net.cpp:165] Memory required for data: 189540400
I0218 21:49:21.407905  9736 layer_factory.hpp:77] Creating layer BatchNorm8
I0218 21:49:21.407917  9736 net.cpp:100] Creating Layer BatchNorm8
I0218 21:49:21.407922  9736 net.cpp:444] BatchNorm8 <- Convolution8
I0218 21:49:21.407925  9736 net.cpp:405] BatchNorm8 -> Convolution8 (in-place)
I0218 21:49:21.408074  9736 net.cpp:150] Setting up BatchNorm8
I0218 21:49:21.408082  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.408083  9736 net.cpp:165] Memory required for data: 194206000
I0218 21:49:21.408089  9736 layer_factory.hpp:77] Creating layer Scale8
I0218 21:49:21.408093  9736 net.cpp:100] Creating Layer Scale8
I0218 21:49:21.408097  9736 net.cpp:444] Scale8 <- Convolution8
I0218 21:49:21.408100  9736 net.cpp:405] Scale8 -> Convolution8 (in-place)
I0218 21:49:21.408133  9736 layer_factory.hpp:77] Creating layer Scale8
I0218 21:49:21.408221  9736 net.cpp:150] Setting up Scale8
I0218 21:49:21.408227  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.408231  9736 net.cpp:165] Memory required for data: 198871600
I0218 21:49:21.408234  9736 layer_factory.hpp:77] Creating layer ReLU8
I0218 21:49:21.408239  9736 net.cpp:100] Creating Layer ReLU8
I0218 21:49:21.408243  9736 net.cpp:444] ReLU8 <- Convolution8
I0218 21:49:21.408246  9736 net.cpp:405] ReLU8 -> Convolution8 (in-place)
I0218 21:49:21.408744  9736 net.cpp:150] Setting up ReLU8
I0218 21:49:21.408754  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.408758  9736 net.cpp:165] Memory required for data: 203537200
I0218 21:49:21.408761  9736 layer_factory.hpp:77] Creating layer Convolution9
I0218 21:49:21.408771  9736 net.cpp:100] Creating Layer Convolution9
I0218 21:49:21.408773  9736 net.cpp:444] Convolution9 <- Convolution8
I0218 21:49:21.408779  9736 net.cpp:418] Convolution9 -> Convolution9
I0218 21:49:21.410140  9736 net.cpp:150] Setting up Convolution9
I0218 21:49:21.410152  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.410156  9736 net.cpp:165] Memory required for data: 208202800
I0218 21:49:21.410161  9736 layer_factory.hpp:77] Creating layer BatchNorm9
I0218 21:49:21.410167  9736 net.cpp:100] Creating Layer BatchNorm9
I0218 21:49:21.410171  9736 net.cpp:444] BatchNorm9 <- Convolution9
I0218 21:49:21.410176  9736 net.cpp:405] BatchNorm9 -> Convolution9 (in-place)
I0218 21:49:21.410327  9736 net.cpp:150] Setting up BatchNorm9
I0218 21:49:21.410333  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.410336  9736 net.cpp:165] Memory required for data: 212868400
I0218 21:49:21.410341  9736 layer_factory.hpp:77] Creating layer Scale9
I0218 21:49:21.410346  9736 net.cpp:100] Creating Layer Scale9
I0218 21:49:21.410349  9736 net.cpp:444] Scale9 <- Convolution9
I0218 21:49:21.410352  9736 net.cpp:405] Scale9 -> Convolution9 (in-place)
I0218 21:49:21.410384  9736 layer_factory.hpp:77] Creating layer Scale9
I0218 21:49:21.410476  9736 net.cpp:150] Setting up Scale9
I0218 21:49:21.410482  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.410485  9736 net.cpp:165] Memory required for data: 217534000
I0218 21:49:21.410490  9736 layer_factory.hpp:77] Creating layer Eltwise4
I0218 21:49:21.410495  9736 net.cpp:100] Creating Layer Eltwise4
I0218 21:49:21.410497  9736 net.cpp:444] Eltwise4 <- Eltwise3_ReLU7_0_split_1
I0218 21:49:21.410501  9736 net.cpp:444] Eltwise4 <- Convolution9
I0218 21:49:21.410506  9736 net.cpp:418] Eltwise4 -> Eltwise4
I0218 21:49:21.410526  9736 net.cpp:150] Setting up Eltwise4
I0218 21:49:21.410531  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.410534  9736 net.cpp:165] Memory required for data: 222199600
I0218 21:49:21.410537  9736 layer_factory.hpp:77] Creating layer ReLU9
I0218 21:49:21.410542  9736 net.cpp:100] Creating Layer ReLU9
I0218 21:49:21.410544  9736 net.cpp:444] ReLU9 <- Eltwise4
I0218 21:49:21.410547  9736 net.cpp:405] ReLU9 -> Eltwise4 (in-place)
I0218 21:49:21.411048  9736 net.cpp:150] Setting up ReLU9
I0218 21:49:21.411058  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.411062  9736 net.cpp:165] Memory required for data: 226865200
I0218 21:49:21.411069  9736 layer_factory.hpp:77] Creating layer Eltwise4_ReLU9_0_split
I0218 21:49:21.411080  9736 net.cpp:100] Creating Layer Eltwise4_ReLU9_0_split
I0218 21:49:21.411084  9736 net.cpp:444] Eltwise4_ReLU9_0_split <- Eltwise4
I0218 21:49:21.411089  9736 net.cpp:418] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_0
I0218 21:49:21.411095  9736 net.cpp:418] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_1
I0218 21:49:21.411100  9736 net.cpp:418] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_2
I0218 21:49:21.411144  9736 net.cpp:150] Setting up Eltwise4_ReLU9_0_split
I0218 21:49:21.411149  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.411152  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.411154  9736 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0218 21:49:21.411157  9736 net.cpp:165] Memory required for data: 240862000
I0218 21:49:21.411160  9736 layer_factory.hpp:77] Creating layer Convolution10
I0218 21:49:21.411168  9736 net.cpp:100] Creating Layer Convolution10
I0218 21:49:21.411172  9736 net.cpp:444] Convolution10 <- Eltwise4_ReLU9_0_split_0
I0218 21:49:21.411177  9736 net.cpp:418] Convolution10 -> Convolution10
I0218 21:49:21.412514  9736 net.cpp:150] Setting up Convolution10
I0218 21:49:21.412526  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.412529  9736 net.cpp:165] Memory required for data: 243370800
I0218 21:49:21.412541  9736 layer_factory.hpp:77] Creating layer BatchNorm10
I0218 21:49:21.412549  9736 net.cpp:100] Creating Layer BatchNorm10
I0218 21:49:21.412551  9736 net.cpp:444] BatchNorm10 <- Convolution10
I0218 21:49:21.412556  9736 net.cpp:405] BatchNorm10 -> Convolution10 (in-place)
I0218 21:49:21.412714  9736 net.cpp:150] Setting up BatchNorm10
I0218 21:49:21.412720  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.412722  9736 net.cpp:165] Memory required for data: 245879600
I0218 21:49:21.412729  9736 layer_factory.hpp:77] Creating layer Scale10
I0218 21:49:21.412734  9736 net.cpp:100] Creating Layer Scale10
I0218 21:49:21.412737  9736 net.cpp:444] Scale10 <- Convolution10
I0218 21:49:21.412741  9736 net.cpp:405] Scale10 -> Convolution10 (in-place)
I0218 21:49:21.412773  9736 layer_factory.hpp:77] Creating layer Scale10
I0218 21:49:21.412863  9736 net.cpp:150] Setting up Scale10
I0218 21:49:21.412868  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.412871  9736 net.cpp:165] Memory required for data: 248388400
I0218 21:49:21.412875  9736 layer_factory.hpp:77] Creating layer Convolution11
I0218 21:49:21.412883  9736 net.cpp:100] Creating Layer Convolution11
I0218 21:49:21.412887  9736 net.cpp:444] Convolution11 <- Eltwise4_ReLU9_0_split_1
I0218 21:49:21.412892  9736 net.cpp:418] Convolution11 -> Convolution11
I0218 21:49:21.414938  9736 net.cpp:150] Setting up Convolution11
I0218 21:49:21.414952  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.414954  9736 net.cpp:165] Memory required for data: 250897200
I0218 21:49:21.414960  9736 layer_factory.hpp:77] Creating layer BatchNorm11
I0218 21:49:21.414968  9736 net.cpp:100] Creating Layer BatchNorm11
I0218 21:49:21.414971  9736 net.cpp:444] BatchNorm11 <- Convolution11
I0218 21:49:21.414975  9736 net.cpp:405] BatchNorm11 -> Convolution11 (in-place)
I0218 21:49:21.415132  9736 net.cpp:150] Setting up BatchNorm11
I0218 21:49:21.415138  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.415140  9736 net.cpp:165] Memory required for data: 253406000
I0218 21:49:21.415145  9736 layer_factory.hpp:77] Creating layer Scale11
I0218 21:49:21.415151  9736 net.cpp:100] Creating Layer Scale11
I0218 21:49:21.415154  9736 net.cpp:444] Scale11 <- Convolution11
I0218 21:49:21.415159  9736 net.cpp:405] Scale11 -> Convolution11 (in-place)
I0218 21:49:21.415191  9736 layer_factory.hpp:77] Creating layer Scale11
I0218 21:49:21.415279  9736 net.cpp:150] Setting up Scale11
I0218 21:49:21.415285  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.415288  9736 net.cpp:165] Memory required for data: 255914800
I0218 21:49:21.415297  9736 layer_factory.hpp:77] Creating layer ReLU10
I0218 21:49:21.415307  9736 net.cpp:100] Creating Layer ReLU10
I0218 21:49:21.415309  9736 net.cpp:444] ReLU10 <- Convolution11
I0218 21:49:21.415314  9736 net.cpp:405] ReLU10 -> Convolution11 (in-place)
I0218 21:49:21.415833  9736 net.cpp:150] Setting up ReLU10
I0218 21:49:21.415846  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.415849  9736 net.cpp:165] Memory required for data: 258423600
I0218 21:49:21.415853  9736 layer_factory.hpp:77] Creating layer Convolution12
I0218 21:49:21.415861  9736 net.cpp:100] Creating Layer Convolution12
I0218 21:49:21.415864  9736 net.cpp:444] Convolution12 <- Convolution11
I0218 21:49:21.415869  9736 net.cpp:418] Convolution12 -> Convolution12
I0218 21:49:21.417374  9736 net.cpp:150] Setting up Convolution12
I0218 21:49:21.417387  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.417390  9736 net.cpp:165] Memory required for data: 260932400
I0218 21:49:21.417395  9736 layer_factory.hpp:77] Creating layer BatchNorm12
I0218 21:49:21.417404  9736 net.cpp:100] Creating Layer BatchNorm12
I0218 21:49:21.417407  9736 net.cpp:444] BatchNorm12 <- Convolution12
I0218 21:49:21.417412  9736 net.cpp:405] BatchNorm12 -> Convolution12 (in-place)
I0218 21:49:21.417567  9736 net.cpp:150] Setting up BatchNorm12
I0218 21:49:21.417574  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.417577  9736 net.cpp:165] Memory required for data: 263441200
I0218 21:49:21.417582  9736 layer_factory.hpp:77] Creating layer Scale12
I0218 21:49:21.417588  9736 net.cpp:100] Creating Layer Scale12
I0218 21:49:21.417592  9736 net.cpp:444] Scale12 <- Convolution12
I0218 21:49:21.417595  9736 net.cpp:405] Scale12 -> Convolution12 (in-place)
I0218 21:49:21.417626  9736 layer_factory.hpp:77] Creating layer Scale12
I0218 21:49:21.417714  9736 net.cpp:150] Setting up Scale12
I0218 21:49:21.417721  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.417722  9736 net.cpp:165] Memory required for data: 265950000
I0218 21:49:21.417727  9736 layer_factory.hpp:77] Creating layer Eltwise5
I0218 21:49:21.417732  9736 net.cpp:100] Creating Layer Eltwise5
I0218 21:49:21.417737  9736 net.cpp:444] Eltwise5 <- Convolution10
I0218 21:49:21.417739  9736 net.cpp:444] Eltwise5 <- Convolution12
I0218 21:49:21.417744  9736 net.cpp:418] Eltwise5 -> Eltwise5
I0218 21:49:21.417763  9736 net.cpp:150] Setting up Eltwise5
I0218 21:49:21.417769  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.417771  9736 net.cpp:165] Memory required for data: 268458800
I0218 21:49:21.417774  9736 layer_factory.hpp:77] Creating layer ReLU11
I0218 21:49:21.417779  9736 net.cpp:100] Creating Layer ReLU11
I0218 21:49:21.417783  9736 net.cpp:444] ReLU11 <- Eltwise5
I0218 21:49:21.417786  9736 net.cpp:405] ReLU11 -> Eltwise5 (in-place)
I0218 21:49:21.418284  9736 net.cpp:150] Setting up ReLU11
I0218 21:49:21.418296  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.418300  9736 net.cpp:165] Memory required for data: 270967600
I0218 21:49:21.418303  9736 layer_factory.hpp:77] Creating layer Eltwise5_ReLU11_0_split
I0218 21:49:21.418308  9736 net.cpp:100] Creating Layer Eltwise5_ReLU11_0_split
I0218 21:49:21.418311  9736 net.cpp:444] Eltwise5_ReLU11_0_split <- Eltwise5
I0218 21:49:21.418316  9736 net.cpp:418] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_0
I0218 21:49:21.418323  9736 net.cpp:418] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_1
I0218 21:49:21.418359  9736 net.cpp:150] Setting up Eltwise5_ReLU11_0_split
I0218 21:49:21.418365  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.418367  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.418370  9736 net.cpp:165] Memory required for data: 275985200
I0218 21:49:21.418372  9736 layer_factory.hpp:77] Creating layer Convolution13
I0218 21:49:21.418381  9736 net.cpp:100] Creating Layer Convolution13
I0218 21:49:21.418385  9736 net.cpp:444] Convolution13 <- Eltwise5_ReLU11_0_split_0
I0218 21:49:21.418395  9736 net.cpp:418] Convolution13 -> Convolution13
I0218 21:49:21.419826  9736 net.cpp:150] Setting up Convolution13
I0218 21:49:21.419839  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.419842  9736 net.cpp:165] Memory required for data: 278494000
I0218 21:49:21.419848  9736 layer_factory.hpp:77] Creating layer BatchNorm13
I0218 21:49:21.419855  9736 net.cpp:100] Creating Layer BatchNorm13
I0218 21:49:21.419858  9736 net.cpp:444] BatchNorm13 <- Convolution13
I0218 21:49:21.419864  9736 net.cpp:405] BatchNorm13 -> Convolution13 (in-place)
I0218 21:49:21.420020  9736 net.cpp:150] Setting up BatchNorm13
I0218 21:49:21.420027  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.420029  9736 net.cpp:165] Memory required for data: 281002800
I0218 21:49:21.420035  9736 layer_factory.hpp:77] Creating layer Scale13
I0218 21:49:21.420042  9736 net.cpp:100] Creating Layer Scale13
I0218 21:49:21.420044  9736 net.cpp:444] Scale13 <- Convolution13
I0218 21:49:21.420048  9736 net.cpp:405] Scale13 -> Convolution13 (in-place)
I0218 21:49:21.420081  9736 layer_factory.hpp:77] Creating layer Scale13
I0218 21:49:21.420169  9736 net.cpp:150] Setting up Scale13
I0218 21:49:21.420176  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.420177  9736 net.cpp:165] Memory required for data: 283511600
I0218 21:49:21.420182  9736 layer_factory.hpp:77] Creating layer ReLU12
I0218 21:49:21.420188  9736 net.cpp:100] Creating Layer ReLU12
I0218 21:49:21.420192  9736 net.cpp:444] ReLU12 <- Convolution13
I0218 21:49:21.420195  9736 net.cpp:405] ReLU12 -> Convolution13 (in-place)
I0218 21:49:21.420334  9736 net.cpp:150] Setting up ReLU12
I0218 21:49:21.420342  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.420344  9736 net.cpp:165] Memory required for data: 286020400
I0218 21:49:21.420347  9736 layer_factory.hpp:77] Creating layer Convolution14
I0218 21:49:21.420356  9736 net.cpp:100] Creating Layer Convolution14
I0218 21:49:21.420359  9736 net.cpp:444] Convolution14 <- Convolution13
I0218 21:49:21.420364  9736 net.cpp:418] Convolution14 -> Convolution14
I0218 21:49:21.421775  9736 net.cpp:150] Setting up Convolution14
I0218 21:49:21.421787  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.421790  9736 net.cpp:165] Memory required for data: 288529200
I0218 21:49:21.421797  9736 layer_factory.hpp:77] Creating layer BatchNorm14
I0218 21:49:21.421805  9736 net.cpp:100] Creating Layer BatchNorm14
I0218 21:49:21.421809  9736 net.cpp:444] BatchNorm14 <- Convolution14
I0218 21:49:21.421814  9736 net.cpp:405] BatchNorm14 -> Convolution14 (in-place)
I0218 21:49:21.421969  9736 net.cpp:150] Setting up BatchNorm14
I0218 21:49:21.421977  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.421980  9736 net.cpp:165] Memory required for data: 291038000
I0218 21:49:21.421985  9736 layer_factory.hpp:77] Creating layer Scale14
I0218 21:49:21.421990  9736 net.cpp:100] Creating Layer Scale14
I0218 21:49:21.421993  9736 net.cpp:444] Scale14 <- Convolution14
I0218 21:49:21.421998  9736 net.cpp:405] Scale14 -> Convolution14 (in-place)
I0218 21:49:21.422029  9736 layer_factory.hpp:77] Creating layer Scale14
I0218 21:49:21.422119  9736 net.cpp:150] Setting up Scale14
I0218 21:49:21.422125  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.422128  9736 net.cpp:165] Memory required for data: 293546800
I0218 21:49:21.422133  9736 layer_factory.hpp:77] Creating layer Eltwise6
I0218 21:49:21.422137  9736 net.cpp:100] Creating Layer Eltwise6
I0218 21:49:21.422140  9736 net.cpp:444] Eltwise6 <- Eltwise5_ReLU11_0_split_1
I0218 21:49:21.422144  9736 net.cpp:444] Eltwise6 <- Convolution14
I0218 21:49:21.422152  9736 net.cpp:418] Eltwise6 -> Eltwise6
I0218 21:49:21.422173  9736 net.cpp:150] Setting up Eltwise6
I0218 21:49:21.422179  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.422183  9736 net.cpp:165] Memory required for data: 296055600
I0218 21:49:21.422185  9736 layer_factory.hpp:77] Creating layer ReLU13
I0218 21:49:21.422189  9736 net.cpp:100] Creating Layer ReLU13
I0218 21:49:21.422196  9736 net.cpp:444] ReLU13 <- Eltwise6
I0218 21:49:21.422205  9736 net.cpp:405] ReLU13 -> Eltwise6 (in-place)
I0218 21:49:21.422714  9736 net.cpp:150] Setting up ReLU13
I0218 21:49:21.422724  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.422727  9736 net.cpp:165] Memory required for data: 298564400
I0218 21:49:21.422731  9736 layer_factory.hpp:77] Creating layer Eltwise6_ReLU13_0_split
I0218 21:49:21.422737  9736 net.cpp:100] Creating Layer Eltwise6_ReLU13_0_split
I0218 21:49:21.422740  9736 net.cpp:444] Eltwise6_ReLU13_0_split <- Eltwise6
I0218 21:49:21.422745  9736 net.cpp:418] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_0
I0218 21:49:21.422752  9736 net.cpp:418] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_1
I0218 21:49:21.422786  9736 net.cpp:150] Setting up Eltwise6_ReLU13_0_split
I0218 21:49:21.422792  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.422796  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.422798  9736 net.cpp:165] Memory required for data: 303582000
I0218 21:49:21.422801  9736 layer_factory.hpp:77] Creating layer Convolution15
I0218 21:49:21.422809  9736 net.cpp:100] Creating Layer Convolution15
I0218 21:49:21.422812  9736 net.cpp:444] Convolution15 <- Eltwise6_ReLU13_0_split_0
I0218 21:49:21.422817  9736 net.cpp:418] Convolution15 -> Convolution15
I0218 21:49:21.423877  9736 net.cpp:150] Setting up Convolution15
I0218 21:49:21.423890  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.423893  9736 net.cpp:165] Memory required for data: 306090800
I0218 21:49:21.423899  9736 layer_factory.hpp:77] Creating layer BatchNorm15
I0218 21:49:21.423905  9736 net.cpp:100] Creating Layer BatchNorm15
I0218 21:49:21.423909  9736 net.cpp:444] BatchNorm15 <- Convolution15
I0218 21:49:21.423914  9736 net.cpp:405] BatchNorm15 -> Convolution15 (in-place)
I0218 21:49:21.424070  9736 net.cpp:150] Setting up BatchNorm15
I0218 21:49:21.424077  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.424078  9736 net.cpp:165] Memory required for data: 308599600
I0218 21:49:21.424084  9736 layer_factory.hpp:77] Creating layer Scale15
I0218 21:49:21.424089  9736 net.cpp:100] Creating Layer Scale15
I0218 21:49:21.424093  9736 net.cpp:444] Scale15 <- Convolution15
I0218 21:49:21.424096  9736 net.cpp:405] Scale15 -> Convolution15 (in-place)
I0218 21:49:21.424129  9736 layer_factory.hpp:77] Creating layer Scale15
I0218 21:49:21.424219  9736 net.cpp:150] Setting up Scale15
I0218 21:49:21.424226  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.424228  9736 net.cpp:165] Memory required for data: 311108400
I0218 21:49:21.424232  9736 layer_factory.hpp:77] Creating layer ReLU14
I0218 21:49:21.424237  9736 net.cpp:100] Creating Layer ReLU14
I0218 21:49:21.424240  9736 net.cpp:444] ReLU14 <- Convolution15
I0218 21:49:21.424247  9736 net.cpp:405] ReLU14 -> Convolution15 (in-place)
I0218 21:49:21.424751  9736 net.cpp:150] Setting up ReLU14
I0218 21:49:21.424762  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.424764  9736 net.cpp:165] Memory required for data: 313617200
I0218 21:49:21.424767  9736 layer_factory.hpp:77] Creating layer Convolution16
I0218 21:49:21.424777  9736 net.cpp:100] Creating Layer Convolution16
I0218 21:49:21.424780  9736 net.cpp:444] Convolution16 <- Convolution15
I0218 21:49:21.424787  9736 net.cpp:418] Convolution16 -> Convolution16
I0218 21:49:21.426260  9736 net.cpp:150] Setting up Convolution16
I0218 21:49:21.426275  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.426277  9736 net.cpp:165] Memory required for data: 316126000
I0218 21:49:21.426283  9736 layer_factory.hpp:77] Creating layer BatchNorm16
I0218 21:49:21.426290  9736 net.cpp:100] Creating Layer BatchNorm16
I0218 21:49:21.426292  9736 net.cpp:444] BatchNorm16 <- Convolution16
I0218 21:49:21.426298  9736 net.cpp:405] BatchNorm16 -> Convolution16 (in-place)
I0218 21:49:21.426458  9736 net.cpp:150] Setting up BatchNorm16
I0218 21:49:21.426465  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.426471  9736 net.cpp:165] Memory required for data: 318634800
I0218 21:49:21.426482  9736 layer_factory.hpp:77] Creating layer Scale16
I0218 21:49:21.426487  9736 net.cpp:100] Creating Layer Scale16
I0218 21:49:21.426491  9736 net.cpp:444] Scale16 <- Convolution16
I0218 21:49:21.426496  9736 net.cpp:405] Scale16 -> Convolution16 (in-place)
I0218 21:49:21.426529  9736 layer_factory.hpp:77] Creating layer Scale16
I0218 21:49:21.426622  9736 net.cpp:150] Setting up Scale16
I0218 21:49:21.426628  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.426631  9736 net.cpp:165] Memory required for data: 321143600
I0218 21:49:21.426636  9736 layer_factory.hpp:77] Creating layer Eltwise7
I0218 21:49:21.426642  9736 net.cpp:100] Creating Layer Eltwise7
I0218 21:49:21.426645  9736 net.cpp:444] Eltwise7 <- Eltwise6_ReLU13_0_split_1
I0218 21:49:21.426650  9736 net.cpp:444] Eltwise7 <- Convolution16
I0218 21:49:21.426653  9736 net.cpp:418] Eltwise7 -> Eltwise7
I0218 21:49:21.426676  9736 net.cpp:150] Setting up Eltwise7
I0218 21:49:21.426681  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.426683  9736 net.cpp:165] Memory required for data: 323652400
I0218 21:49:21.426687  9736 layer_factory.hpp:77] Creating layer ReLU15
I0218 21:49:21.426690  9736 net.cpp:100] Creating Layer ReLU15
I0218 21:49:21.426693  9736 net.cpp:444] ReLU15 <- Eltwise7
I0218 21:49:21.426698  9736 net.cpp:405] ReLU15 -> Eltwise7 (in-place)
I0218 21:49:21.426838  9736 net.cpp:150] Setting up ReLU15
I0218 21:49:21.426846  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.426848  9736 net.cpp:165] Memory required for data: 326161200
I0218 21:49:21.426851  9736 layer_factory.hpp:77] Creating layer Eltwise7_ReLU15_0_split
I0218 21:49:21.426856  9736 net.cpp:100] Creating Layer Eltwise7_ReLU15_0_split
I0218 21:49:21.426859  9736 net.cpp:444] Eltwise7_ReLU15_0_split <- Eltwise7
I0218 21:49:21.426864  9736 net.cpp:418] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_0
I0218 21:49:21.426870  9736 net.cpp:418] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_1
I0218 21:49:21.426905  9736 net.cpp:150] Setting up Eltwise7_ReLU15_0_split
I0218 21:49:21.426910  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.426914  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.426916  9736 net.cpp:165] Memory required for data: 331178800
I0218 21:49:21.426919  9736 layer_factory.hpp:77] Creating layer Convolution17
I0218 21:49:21.426926  9736 net.cpp:100] Creating Layer Convolution17
I0218 21:49:21.426930  9736 net.cpp:444] Convolution17 <- Eltwise7_ReLU15_0_split_0
I0218 21:49:21.426935  9736 net.cpp:418] Convolution17 -> Convolution17
I0218 21:49:21.429059  9736 net.cpp:150] Setting up Convolution17
I0218 21:49:21.429074  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.429076  9736 net.cpp:165] Memory required for data: 333687600
I0218 21:49:21.429082  9736 layer_factory.hpp:77] Creating layer BatchNorm17
I0218 21:49:21.429088  9736 net.cpp:100] Creating Layer BatchNorm17
I0218 21:49:21.429091  9736 net.cpp:444] BatchNorm17 <- Convolution17
I0218 21:49:21.429097  9736 net.cpp:405] BatchNorm17 -> Convolution17 (in-place)
I0218 21:49:21.429260  9736 net.cpp:150] Setting up BatchNorm17
I0218 21:49:21.429265  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.429268  9736 net.cpp:165] Memory required for data: 336196400
I0218 21:49:21.429273  9736 layer_factory.hpp:77] Creating layer Scale17
I0218 21:49:21.429278  9736 net.cpp:100] Creating Layer Scale17
I0218 21:49:21.429281  9736 net.cpp:444] Scale17 <- Convolution17
I0218 21:49:21.429286  9736 net.cpp:405] Scale17 -> Convolution17 (in-place)
I0218 21:49:21.429318  9736 layer_factory.hpp:77] Creating layer Scale17
I0218 21:49:21.429410  9736 net.cpp:150] Setting up Scale17
I0218 21:49:21.429417  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.429419  9736 net.cpp:165] Memory required for data: 338705200
I0218 21:49:21.429424  9736 layer_factory.hpp:77] Creating layer ReLU16
I0218 21:49:21.429431  9736 net.cpp:100] Creating Layer ReLU16
I0218 21:49:21.429440  9736 net.cpp:444] ReLU16 <- Convolution17
I0218 21:49:21.429446  9736 net.cpp:405] ReLU16 -> Convolution17 (in-place)
I0218 21:49:21.429960  9736 net.cpp:150] Setting up ReLU16
I0218 21:49:21.429971  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.429975  9736 net.cpp:165] Memory required for data: 341214000
I0218 21:49:21.429977  9736 layer_factory.hpp:77] Creating layer Convolution18
I0218 21:49:21.429986  9736 net.cpp:100] Creating Layer Convolution18
I0218 21:49:21.429989  9736 net.cpp:444] Convolution18 <- Convolution17
I0218 21:49:21.429996  9736 net.cpp:418] Convolution18 -> Convolution18
I0218 21:49:21.431058  9736 net.cpp:150] Setting up Convolution18
I0218 21:49:21.431071  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.431073  9736 net.cpp:165] Memory required for data: 343722800
I0218 21:49:21.431079  9736 layer_factory.hpp:77] Creating layer BatchNorm18
I0218 21:49:21.431085  9736 net.cpp:100] Creating Layer BatchNorm18
I0218 21:49:21.431089  9736 net.cpp:444] BatchNorm18 <- Convolution18
I0218 21:49:21.431093  9736 net.cpp:405] BatchNorm18 -> Convolution18 (in-place)
I0218 21:49:21.431257  9736 net.cpp:150] Setting up BatchNorm18
I0218 21:49:21.431262  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.431265  9736 net.cpp:165] Memory required for data: 346231600
I0218 21:49:21.431270  9736 layer_factory.hpp:77] Creating layer Scale18
I0218 21:49:21.431275  9736 net.cpp:100] Creating Layer Scale18
I0218 21:49:21.431278  9736 net.cpp:444] Scale18 <- Convolution18
I0218 21:49:21.431282  9736 net.cpp:405] Scale18 -> Convolution18 (in-place)
I0218 21:49:21.431318  9736 layer_factory.hpp:77] Creating layer Scale18
I0218 21:49:21.431411  9736 net.cpp:150] Setting up Scale18
I0218 21:49:21.431417  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.431421  9736 net.cpp:165] Memory required for data: 348740400
I0218 21:49:21.431426  9736 layer_factory.hpp:77] Creating layer Eltwise8
I0218 21:49:21.431430  9736 net.cpp:100] Creating Layer Eltwise8
I0218 21:49:21.431433  9736 net.cpp:444] Eltwise8 <- Eltwise7_ReLU15_0_split_1
I0218 21:49:21.431437  9736 net.cpp:444] Eltwise8 <- Convolution18
I0218 21:49:21.431440  9736 net.cpp:418] Eltwise8 -> Eltwise8
I0218 21:49:21.431463  9736 net.cpp:150] Setting up Eltwise8
I0218 21:49:21.431468  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.431470  9736 net.cpp:165] Memory required for data: 351249200
I0218 21:49:21.431473  9736 layer_factory.hpp:77] Creating layer ReLU17
I0218 21:49:21.431479  9736 net.cpp:100] Creating Layer ReLU17
I0218 21:49:21.431483  9736 net.cpp:444] ReLU17 <- Eltwise8
I0218 21:49:21.431486  9736 net.cpp:405] ReLU17 -> Eltwise8 (in-place)
I0218 21:49:21.432003  9736 net.cpp:150] Setting up ReLU17
I0218 21:49:21.432015  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.432018  9736 net.cpp:165] Memory required for data: 353758000
I0218 21:49:21.432021  9736 layer_factory.hpp:77] Creating layer Eltwise8_ReLU17_0_split
I0218 21:49:21.432027  9736 net.cpp:100] Creating Layer Eltwise8_ReLU17_0_split
I0218 21:49:21.432031  9736 net.cpp:444] Eltwise8_ReLU17_0_split <- Eltwise8
I0218 21:49:21.432036  9736 net.cpp:418] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_0
I0218 21:49:21.432044  9736 net.cpp:418] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_1
I0218 21:49:21.432047  9736 net.cpp:418] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_2
I0218 21:49:21.432093  9736 net.cpp:150] Setting up Eltwise8_ReLU17_0_split
I0218 21:49:21.432098  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.432101  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.432104  9736 net.cpp:157] Top shape: 100 32 14 14 (627200)
I0218 21:49:21.432107  9736 net.cpp:165] Memory required for data: 361284400
I0218 21:49:21.432111  9736 layer_factory.hpp:77] Creating layer Convolution19
I0218 21:49:21.432118  9736 net.cpp:100] Creating Layer Convolution19
I0218 21:49:21.432126  9736 net.cpp:444] Convolution19 <- Eltwise8_ReLU17_0_split_0
I0218 21:49:21.432137  9736 net.cpp:418] Convolution19 -> Convolution19
I0218 21:49:21.433527  9736 net.cpp:150] Setting up Convolution19
I0218 21:49:21.433540  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.433543  9736 net.cpp:165] Memory required for data: 362538800
I0218 21:49:21.433549  9736 layer_factory.hpp:77] Creating layer BatchNorm19
I0218 21:49:21.433557  9736 net.cpp:100] Creating Layer BatchNorm19
I0218 21:49:21.433560  9736 net.cpp:444] BatchNorm19 <- Convolution19
I0218 21:49:21.433565  9736 net.cpp:405] BatchNorm19 -> Convolution19 (in-place)
I0218 21:49:21.433727  9736 net.cpp:150] Setting up BatchNorm19
I0218 21:49:21.433733  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.433735  9736 net.cpp:165] Memory required for data: 363793200
I0218 21:49:21.433748  9736 layer_factory.hpp:77] Creating layer Scale19
I0218 21:49:21.433754  9736 net.cpp:100] Creating Layer Scale19
I0218 21:49:21.433758  9736 net.cpp:444] Scale19 <- Convolution19
I0218 21:49:21.433761  9736 net.cpp:405] Scale19 -> Convolution19 (in-place)
I0218 21:49:21.433797  9736 layer_factory.hpp:77] Creating layer Scale19
I0218 21:49:21.433892  9736 net.cpp:150] Setting up Scale19
I0218 21:49:21.433897  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.433900  9736 net.cpp:165] Memory required for data: 365047600
I0218 21:49:21.433905  9736 layer_factory.hpp:77] Creating layer Convolution20
I0218 21:49:21.433913  9736 net.cpp:100] Creating Layer Convolution20
I0218 21:49:21.433917  9736 net.cpp:444] Convolution20 <- Eltwise8_ReLU17_0_split_1
I0218 21:49:21.433923  9736 net.cpp:418] Convolution20 -> Convolution20
I0218 21:49:21.435731  9736 net.cpp:150] Setting up Convolution20
I0218 21:49:21.435745  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.435748  9736 net.cpp:165] Memory required for data: 366302000
I0218 21:49:21.435755  9736 layer_factory.hpp:77] Creating layer BatchNorm20
I0218 21:49:21.435761  9736 net.cpp:100] Creating Layer BatchNorm20
I0218 21:49:21.435765  9736 net.cpp:444] BatchNorm20 <- Convolution20
I0218 21:49:21.435770  9736 net.cpp:405] BatchNorm20 -> Convolution20 (in-place)
I0218 21:49:21.435931  9736 net.cpp:150] Setting up BatchNorm20
I0218 21:49:21.435937  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.435940  9736 net.cpp:165] Memory required for data: 367556400
I0218 21:49:21.435946  9736 layer_factory.hpp:77] Creating layer Scale20
I0218 21:49:21.435951  9736 net.cpp:100] Creating Layer Scale20
I0218 21:49:21.435955  9736 net.cpp:444] Scale20 <- Convolution20
I0218 21:49:21.435958  9736 net.cpp:405] Scale20 -> Convolution20 (in-place)
I0218 21:49:21.435994  9736 layer_factory.hpp:77] Creating layer Scale20
I0218 21:49:21.436089  9736 net.cpp:150] Setting up Scale20
I0218 21:49:21.436095  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.436098  9736 net.cpp:165] Memory required for data: 368810800
I0218 21:49:21.436103  9736 layer_factory.hpp:77] Creating layer ReLU18
I0218 21:49:21.436108  9736 net.cpp:100] Creating Layer ReLU18
I0218 21:49:21.436110  9736 net.cpp:444] ReLU18 <- Convolution20
I0218 21:49:21.436115  9736 net.cpp:405] ReLU18 -> Convolution20 (in-place)
I0218 21:49:21.436259  9736 net.cpp:150] Setting up ReLU18
I0218 21:49:21.436267  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.436270  9736 net.cpp:165] Memory required for data: 370065200
I0218 21:49:21.436273  9736 layer_factory.hpp:77] Creating layer Convolution21
I0218 21:49:21.436281  9736 net.cpp:100] Creating Layer Convolution21
I0218 21:49:21.436285  9736 net.cpp:444] Convolution21 <- Convolution20
I0218 21:49:21.436290  9736 net.cpp:418] Convolution21 -> Convolution21
I0218 21:49:21.438285  9736 net.cpp:150] Setting up Convolution21
I0218 21:49:21.438298  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.438302  9736 net.cpp:165] Memory required for data: 371319600
I0218 21:49:21.438308  9736 layer_factory.hpp:77] Creating layer BatchNorm21
I0218 21:49:21.438316  9736 net.cpp:100] Creating Layer BatchNorm21
I0218 21:49:21.438325  9736 net.cpp:444] BatchNorm21 <- Convolution21
I0218 21:49:21.438331  9736 net.cpp:405] BatchNorm21 -> Convolution21 (in-place)
I0218 21:49:21.438498  9736 net.cpp:150] Setting up BatchNorm21
I0218 21:49:21.438504  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.438508  9736 net.cpp:165] Memory required for data: 372574000
I0218 21:49:21.438513  9736 layer_factory.hpp:77] Creating layer Scale21
I0218 21:49:21.438519  9736 net.cpp:100] Creating Layer Scale21
I0218 21:49:21.438521  9736 net.cpp:444] Scale21 <- Convolution21
I0218 21:49:21.438526  9736 net.cpp:405] Scale21 -> Convolution21 (in-place)
I0218 21:49:21.438560  9736 layer_factory.hpp:77] Creating layer Scale21
I0218 21:49:21.438653  9736 net.cpp:150] Setting up Scale21
I0218 21:49:21.438659  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.438663  9736 net.cpp:165] Memory required for data: 373828400
I0218 21:49:21.438666  9736 layer_factory.hpp:77] Creating layer Eltwise9
I0218 21:49:21.438671  9736 net.cpp:100] Creating Layer Eltwise9
I0218 21:49:21.438674  9736 net.cpp:444] Eltwise9 <- Convolution19
I0218 21:49:21.438678  9736 net.cpp:444] Eltwise9 <- Convolution21
I0218 21:49:21.438683  9736 net.cpp:418] Eltwise9 -> Eltwise9
I0218 21:49:21.438706  9736 net.cpp:150] Setting up Eltwise9
I0218 21:49:21.438712  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.438714  9736 net.cpp:165] Memory required for data: 375082800
I0218 21:49:21.438717  9736 layer_factory.hpp:77] Creating layer ReLU19
I0218 21:49:21.438721  9736 net.cpp:100] Creating Layer ReLU19
I0218 21:49:21.438724  9736 net.cpp:444] ReLU19 <- Eltwise9
I0218 21:49:21.438730  9736 net.cpp:405] ReLU19 -> Eltwise9 (in-place)
I0218 21:49:21.438876  9736 net.cpp:150] Setting up ReLU19
I0218 21:49:21.438884  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.438887  9736 net.cpp:165] Memory required for data: 376337200
I0218 21:49:21.438890  9736 layer_factory.hpp:77] Creating layer Eltwise9_ReLU19_0_split
I0218 21:49:21.438894  9736 net.cpp:100] Creating Layer Eltwise9_ReLU19_0_split
I0218 21:49:21.438897  9736 net.cpp:444] Eltwise9_ReLU19_0_split <- Eltwise9
I0218 21:49:21.438904  9736 net.cpp:418] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_0
I0218 21:49:21.438910  9736 net.cpp:418] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_1
I0218 21:49:21.438946  9736 net.cpp:150] Setting up Eltwise9_ReLU19_0_split
I0218 21:49:21.438951  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.438954  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.438957  9736 net.cpp:165] Memory required for data: 378846000
I0218 21:49:21.438959  9736 layer_factory.hpp:77] Creating layer Convolution22
I0218 21:49:21.438967  9736 net.cpp:100] Creating Layer Convolution22
I0218 21:49:21.438971  9736 net.cpp:444] Convolution22 <- Eltwise9_ReLU19_0_split_0
I0218 21:49:21.438977  9736 net.cpp:418] Convolution22 -> Convolution22
I0218 21:49:21.440933  9736 net.cpp:150] Setting up Convolution22
I0218 21:49:21.440946  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.440949  9736 net.cpp:165] Memory required for data: 380100400
I0218 21:49:21.440955  9736 layer_factory.hpp:77] Creating layer BatchNorm22
I0218 21:49:21.440963  9736 net.cpp:100] Creating Layer BatchNorm22
I0218 21:49:21.440965  9736 net.cpp:444] BatchNorm22 <- Convolution22
I0218 21:49:21.440970  9736 net.cpp:405] BatchNorm22 -> Convolution22 (in-place)
I0218 21:49:21.441164  9736 net.cpp:150] Setting up BatchNorm22
I0218 21:49:21.441172  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.441174  9736 net.cpp:165] Memory required for data: 381354800
I0218 21:49:21.441181  9736 layer_factory.hpp:77] Creating layer Scale22
I0218 21:49:21.441186  9736 net.cpp:100] Creating Layer Scale22
I0218 21:49:21.441190  9736 net.cpp:444] Scale22 <- Convolution22
I0218 21:49:21.441193  9736 net.cpp:405] Scale22 -> Convolution22 (in-place)
I0218 21:49:21.441234  9736 layer_factory.hpp:77] Creating layer Scale22
I0218 21:49:21.441336  9736 net.cpp:150] Setting up Scale22
I0218 21:49:21.441347  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.441349  9736 net.cpp:165] Memory required for data: 382609200
I0218 21:49:21.441355  9736 layer_factory.hpp:77] Creating layer ReLU20
I0218 21:49:21.441360  9736 net.cpp:100] Creating Layer ReLU20
I0218 21:49:21.441363  9736 net.cpp:444] ReLU20 <- Convolution22
I0218 21:49:21.441367  9736 net.cpp:405] ReLU20 -> Convolution22 (in-place)
I0218 21:49:21.441891  9736 net.cpp:150] Setting up ReLU20
I0218 21:49:21.441901  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.441905  9736 net.cpp:165] Memory required for data: 383863600
I0218 21:49:21.441907  9736 layer_factory.hpp:77] Creating layer Convolution23
I0218 21:49:21.441917  9736 net.cpp:100] Creating Layer Convolution23
I0218 21:49:21.441921  9736 net.cpp:444] Convolution23 <- Convolution22
I0218 21:49:21.441926  9736 net.cpp:418] Convolution23 -> Convolution23
I0218 21:49:21.443943  9736 net.cpp:150] Setting up Convolution23
I0218 21:49:21.443955  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.443958  9736 net.cpp:165] Memory required for data: 385118000
I0218 21:49:21.443964  9736 layer_factory.hpp:77] Creating layer BatchNorm23
I0218 21:49:21.443971  9736 net.cpp:100] Creating Layer BatchNorm23
I0218 21:49:21.443975  9736 net.cpp:444] BatchNorm23 <- Convolution23
I0218 21:49:21.443979  9736 net.cpp:405] BatchNorm23 -> Convolution23 (in-place)
I0218 21:49:21.444149  9736 net.cpp:150] Setting up BatchNorm23
I0218 21:49:21.444154  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.444157  9736 net.cpp:165] Memory required for data: 386372400
I0218 21:49:21.444164  9736 layer_factory.hpp:77] Creating layer Scale23
I0218 21:49:21.444169  9736 net.cpp:100] Creating Layer Scale23
I0218 21:49:21.444171  9736 net.cpp:444] Scale23 <- Convolution23
I0218 21:49:21.444176  9736 net.cpp:405] Scale23 -> Convolution23 (in-place)
I0218 21:49:21.444212  9736 layer_factory.hpp:77] Creating layer Scale23
I0218 21:49:21.444310  9736 net.cpp:150] Setting up Scale23
I0218 21:49:21.444316  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.444319  9736 net.cpp:165] Memory required for data: 387626800
I0218 21:49:21.444324  9736 layer_factory.hpp:77] Creating layer Eltwise10
I0218 21:49:21.444331  9736 net.cpp:100] Creating Layer Eltwise10
I0218 21:49:21.444335  9736 net.cpp:444] Eltwise10 <- Eltwise9_ReLU19_0_split_1
I0218 21:49:21.444339  9736 net.cpp:444] Eltwise10 <- Convolution23
I0218 21:49:21.444344  9736 net.cpp:418] Eltwise10 -> Eltwise10
I0218 21:49:21.444368  9736 net.cpp:150] Setting up Eltwise10
I0218 21:49:21.444373  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.444376  9736 net.cpp:165] Memory required for data: 388881200
I0218 21:49:21.444378  9736 layer_factory.hpp:77] Creating layer ReLU21
I0218 21:49:21.444382  9736 net.cpp:100] Creating Layer ReLU21
I0218 21:49:21.444386  9736 net.cpp:444] ReLU21 <- Eltwise10
I0218 21:49:21.444391  9736 net.cpp:405] ReLU21 -> Eltwise10 (in-place)
I0218 21:49:21.444536  9736 net.cpp:150] Setting up ReLU21
I0218 21:49:21.444545  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.444546  9736 net.cpp:165] Memory required for data: 390135600
I0218 21:49:21.444550  9736 layer_factory.hpp:77] Creating layer Eltwise10_ReLU21_0_split
I0218 21:49:21.444555  9736 net.cpp:100] Creating Layer Eltwise10_ReLU21_0_split
I0218 21:49:21.444558  9736 net.cpp:444] Eltwise10_ReLU21_0_split <- Eltwise10
I0218 21:49:21.444563  9736 net.cpp:418] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_0
I0218 21:49:21.444569  9736 net.cpp:418] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_1
I0218 21:49:21.444605  9736 net.cpp:150] Setting up Eltwise10_ReLU21_0_split
I0218 21:49:21.444612  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.444614  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.444617  9736 net.cpp:165] Memory required for data: 392644400
I0218 21:49:21.444625  9736 layer_factory.hpp:77] Creating layer Convolution24
I0218 21:49:21.444638  9736 net.cpp:100] Creating Layer Convolution24
I0218 21:49:21.444643  9736 net.cpp:444] Convolution24 <- Eltwise10_ReLU21_0_split_0
I0218 21:49:21.444648  9736 net.cpp:418] Convolution24 -> Convolution24
I0218 21:49:21.446616  9736 net.cpp:150] Setting up Convolution24
I0218 21:49:21.446629  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.446631  9736 net.cpp:165] Memory required for data: 393898800
I0218 21:49:21.446637  9736 layer_factory.hpp:77] Creating layer BatchNorm24
I0218 21:49:21.446645  9736 net.cpp:100] Creating Layer BatchNorm24
I0218 21:49:21.446648  9736 net.cpp:444] BatchNorm24 <- Convolution24
I0218 21:49:21.446653  9736 net.cpp:405] BatchNorm24 -> Convolution24 (in-place)
I0218 21:49:21.446827  9736 net.cpp:150] Setting up BatchNorm24
I0218 21:49:21.446833  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.446836  9736 net.cpp:165] Memory required for data: 395153200
I0218 21:49:21.446841  9736 layer_factory.hpp:77] Creating layer Scale24
I0218 21:49:21.446847  9736 net.cpp:100] Creating Layer Scale24
I0218 21:49:21.446851  9736 net.cpp:444] Scale24 <- Convolution24
I0218 21:49:21.446853  9736 net.cpp:405] Scale24 -> Convolution24 (in-place)
I0218 21:49:21.446890  9736 layer_factory.hpp:77] Creating layer Scale24
I0218 21:49:21.446990  9736 net.cpp:150] Setting up Scale24
I0218 21:49:21.446995  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.446998  9736 net.cpp:165] Memory required for data: 396407600
I0218 21:49:21.447002  9736 layer_factory.hpp:77] Creating layer ReLU22
I0218 21:49:21.447007  9736 net.cpp:100] Creating Layer ReLU22
I0218 21:49:21.447010  9736 net.cpp:444] ReLU22 <- Convolution24
I0218 21:49:21.447016  9736 net.cpp:405] ReLU22 -> Convolution24 (in-place)
I0218 21:49:21.447163  9736 net.cpp:150] Setting up ReLU22
I0218 21:49:21.447172  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.447175  9736 net.cpp:165] Memory required for data: 397662000
I0218 21:49:21.447177  9736 layer_factory.hpp:77] Creating layer Convolution25
I0218 21:49:21.447185  9736 net.cpp:100] Creating Layer Convolution25
I0218 21:49:21.447190  9736 net.cpp:444] Convolution25 <- Convolution24
I0218 21:49:21.447196  9736 net.cpp:418] Convolution25 -> Convolution25
I0218 21:49:21.449569  9736 net.cpp:150] Setting up Convolution25
I0218 21:49:21.449582  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.449585  9736 net.cpp:165] Memory required for data: 398916400
I0218 21:49:21.449591  9736 layer_factory.hpp:77] Creating layer BatchNorm25
I0218 21:49:21.449597  9736 net.cpp:100] Creating Layer BatchNorm25
I0218 21:49:21.449601  9736 net.cpp:444] BatchNorm25 <- Convolution25
I0218 21:49:21.449607  9736 net.cpp:405] BatchNorm25 -> Convolution25 (in-place)
I0218 21:49:21.449777  9736 net.cpp:150] Setting up BatchNorm25
I0218 21:49:21.449784  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.449785  9736 net.cpp:165] Memory required for data: 400170800
I0218 21:49:21.449791  9736 layer_factory.hpp:77] Creating layer Scale25
I0218 21:49:21.449797  9736 net.cpp:100] Creating Layer Scale25
I0218 21:49:21.449800  9736 net.cpp:444] Scale25 <- Convolution25
I0218 21:49:21.449805  9736 net.cpp:405] Scale25 -> Convolution25 (in-place)
I0218 21:49:21.449841  9736 layer_factory.hpp:77] Creating layer Scale25
I0218 21:49:21.449941  9736 net.cpp:150] Setting up Scale25
I0218 21:49:21.449947  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.449949  9736 net.cpp:165] Memory required for data: 401425200
I0218 21:49:21.449954  9736 layer_factory.hpp:77] Creating layer Eltwise11
I0218 21:49:21.449959  9736 net.cpp:100] Creating Layer Eltwise11
I0218 21:49:21.449962  9736 net.cpp:444] Eltwise11 <- Eltwise10_ReLU21_0_split_1
I0218 21:49:21.449966  9736 net.cpp:444] Eltwise11 <- Convolution25
I0218 21:49:21.449971  9736 net.cpp:418] Eltwise11 -> Eltwise11
I0218 21:49:21.449993  9736 net.cpp:150] Setting up Eltwise11
I0218 21:49:21.449998  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.450006  9736 net.cpp:165] Memory required for data: 402679600
I0218 21:49:21.450013  9736 layer_factory.hpp:77] Creating layer ReLU23
I0218 21:49:21.450019  9736 net.cpp:100] Creating Layer ReLU23
I0218 21:49:21.450022  9736 net.cpp:444] ReLU23 <- Eltwise11
I0218 21:49:21.450026  9736 net.cpp:405] ReLU23 -> Eltwise11 (in-place)
I0218 21:49:21.450543  9736 net.cpp:150] Setting up ReLU23
I0218 21:49:21.450553  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.450556  9736 net.cpp:165] Memory required for data: 403934000
I0218 21:49:21.450559  9736 layer_factory.hpp:77] Creating layer Eltwise11_ReLU23_0_split
I0218 21:49:21.450565  9736 net.cpp:100] Creating Layer Eltwise11_ReLU23_0_split
I0218 21:49:21.450568  9736 net.cpp:444] Eltwise11_ReLU23_0_split <- Eltwise11
I0218 21:49:21.450574  9736 net.cpp:418] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_0
I0218 21:49:21.450580  9736 net.cpp:418] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_1
I0218 21:49:21.450620  9736 net.cpp:150] Setting up Eltwise11_ReLU23_0_split
I0218 21:49:21.450625  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.450628  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.450630  9736 net.cpp:165] Memory required for data: 406442800
I0218 21:49:21.450634  9736 layer_factory.hpp:77] Creating layer Convolution26
I0218 21:49:21.450644  9736 net.cpp:100] Creating Layer Convolution26
I0218 21:49:21.450647  9736 net.cpp:444] Convolution26 <- Eltwise11_ReLU23_0_split_0
I0218 21:49:21.450652  9736 net.cpp:418] Convolution26 -> Convolution26
I0218 21:49:21.452667  9736 net.cpp:150] Setting up Convolution26
I0218 21:49:21.452680  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.452683  9736 net.cpp:165] Memory required for data: 407697200
I0218 21:49:21.452689  9736 layer_factory.hpp:77] Creating layer BatchNorm26
I0218 21:49:21.452697  9736 net.cpp:100] Creating Layer BatchNorm26
I0218 21:49:21.452700  9736 net.cpp:444] BatchNorm26 <- Convolution26
I0218 21:49:21.452706  9736 net.cpp:405] BatchNorm26 -> Convolution26 (in-place)
I0218 21:49:21.452880  9736 net.cpp:150] Setting up BatchNorm26
I0218 21:49:21.452888  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.452890  9736 net.cpp:165] Memory required for data: 408951600
I0218 21:49:21.452896  9736 layer_factory.hpp:77] Creating layer Scale26
I0218 21:49:21.452901  9736 net.cpp:100] Creating Layer Scale26
I0218 21:49:21.452905  9736 net.cpp:444] Scale26 <- Convolution26
I0218 21:49:21.452909  9736 net.cpp:405] Scale26 -> Convolution26 (in-place)
I0218 21:49:21.452946  9736 layer_factory.hpp:77] Creating layer Scale26
I0218 21:49:21.453048  9736 net.cpp:150] Setting up Scale26
I0218 21:49:21.453055  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.453058  9736 net.cpp:165] Memory required for data: 410206000
I0218 21:49:21.453063  9736 layer_factory.hpp:77] Creating layer ReLU24
I0218 21:49:21.453068  9736 net.cpp:100] Creating Layer ReLU24
I0218 21:49:21.453070  9736 net.cpp:444] ReLU24 <- Convolution26
I0218 21:49:21.453075  9736 net.cpp:405] ReLU24 -> Convolution26 (in-place)
I0218 21:49:21.453222  9736 net.cpp:150] Setting up ReLU24
I0218 21:49:21.453229  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.453233  9736 net.cpp:165] Memory required for data: 411460400
I0218 21:49:21.453235  9736 layer_factory.hpp:77] Creating layer Convolution27
I0218 21:49:21.453243  9736 net.cpp:100] Creating Layer Convolution27
I0218 21:49:21.453246  9736 net.cpp:444] Convolution27 <- Convolution26
I0218 21:49:21.453253  9736 net.cpp:418] Convolution27 -> Convolution27
I0218 21:49:21.455598  9736 net.cpp:150] Setting up Convolution27
I0218 21:49:21.455611  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.455615  9736 net.cpp:165] Memory required for data: 412714800
I0218 21:49:21.455621  9736 layer_factory.hpp:77] Creating layer BatchNorm27
I0218 21:49:21.455627  9736 net.cpp:100] Creating Layer BatchNorm27
I0218 21:49:21.455631  9736 net.cpp:444] BatchNorm27 <- Convolution27
I0218 21:49:21.455639  9736 net.cpp:405] BatchNorm27 -> Convolution27 (in-place)
I0218 21:49:21.455826  9736 net.cpp:150] Setting up BatchNorm27
I0218 21:49:21.455832  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.455834  9736 net.cpp:165] Memory required for data: 413969200
I0218 21:49:21.455839  9736 layer_factory.hpp:77] Creating layer Scale27
I0218 21:49:21.455850  9736 net.cpp:100] Creating Layer Scale27
I0218 21:49:21.455853  9736 net.cpp:444] Scale27 <- Convolution27
I0218 21:49:21.455857  9736 net.cpp:405] Scale27 -> Convolution27 (in-place)
I0218 21:49:21.455894  9736 layer_factory.hpp:77] Creating layer Scale27
I0218 21:49:21.455998  9736 net.cpp:150] Setting up Scale27
I0218 21:49:21.456004  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.456007  9736 net.cpp:165] Memory required for data: 415223600
I0218 21:49:21.456012  9736 layer_factory.hpp:77] Creating layer Eltwise12
I0218 21:49:21.456017  9736 net.cpp:100] Creating Layer Eltwise12
I0218 21:49:21.456022  9736 net.cpp:444] Eltwise12 <- Eltwise11_ReLU23_0_split_1
I0218 21:49:21.456024  9736 net.cpp:444] Eltwise12 <- Convolution27
I0218 21:49:21.456028  9736 net.cpp:418] Eltwise12 -> Eltwise12
I0218 21:49:21.456053  9736 net.cpp:150] Setting up Eltwise12
I0218 21:49:21.456058  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.456060  9736 net.cpp:165] Memory required for data: 416478000
I0218 21:49:21.456063  9736 layer_factory.hpp:77] Creating layer Convolution_eltwise4
I0218 21:49:21.456075  9736 net.cpp:100] Creating Layer Convolution_eltwise4
I0218 21:49:21.456079  9736 net.cpp:444] Convolution_eltwise4 <- Eltwise4_ReLU9_0_split_2
I0218 21:49:21.456085  9736 net.cpp:418] Convolution_eltwise4 -> Convolution_eltwise4
I0218 21:49:21.457551  9736 net.cpp:150] Setting up Convolution_eltwise4
I0218 21:49:21.457564  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.457567  9736 net.cpp:165] Memory required for data: 417732400
I0218 21:49:21.457573  9736 layer_factory.hpp:77] Creating layer BatchNorm_Convolution_eltwise4
I0218 21:49:21.457579  9736 net.cpp:100] Creating Layer BatchNorm_Convolution_eltwise4
I0218 21:49:21.457583  9736 net.cpp:444] BatchNorm_Convolution_eltwise4 <- Convolution_eltwise4
I0218 21:49:21.457588  9736 net.cpp:405] BatchNorm_Convolution_eltwise4 -> Convolution_eltwise4 (in-place)
I0218 21:49:21.457762  9736 net.cpp:150] Setting up BatchNorm_Convolution_eltwise4
I0218 21:49:21.457767  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.457770  9736 net.cpp:165] Memory required for data: 418986800
I0218 21:49:21.457777  9736 layer_factory.hpp:77] Creating layer Scale_Convolution_eltwise4
I0218 21:49:21.457782  9736 net.cpp:100] Creating Layer Scale_Convolution_eltwise4
I0218 21:49:21.457785  9736 net.cpp:444] Scale_Convolution_eltwise4 <- Convolution_eltwise4
I0218 21:49:21.457789  9736 net.cpp:405] Scale_Convolution_eltwise4 -> Convolution_eltwise4 (in-place)
I0218 21:49:21.457828  9736 layer_factory.hpp:77] Creating layer Scale_Convolution_eltwise4
I0218 21:49:21.457931  9736 net.cpp:150] Setting up Scale_Convolution_eltwise4
I0218 21:49:21.457937  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.457939  9736 net.cpp:165] Memory required for data: 420241200
I0218 21:49:21.457943  9736 layer_factory.hpp:77] Creating layer Convolution_eltwise8
I0218 21:49:21.457952  9736 net.cpp:100] Creating Layer Convolution_eltwise8
I0218 21:49:21.457957  9736 net.cpp:444] Convolution_eltwise8 <- Eltwise8_ReLU17_0_split_2
I0218 21:49:21.457962  9736 net.cpp:418] Convolution_eltwise8 -> Convolution_eltwise8
I0218 21:49:21.459492  9736 net.cpp:150] Setting up Convolution_eltwise8
I0218 21:49:21.459503  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.459506  9736 net.cpp:165] Memory required for data: 421495600
I0218 21:49:21.459512  9736 layer_factory.hpp:77] Creating layer BatchNorm_Convolution_eltwise8
I0218 21:49:21.459518  9736 net.cpp:100] Creating Layer BatchNorm_Convolution_eltwise8
I0218 21:49:21.459522  9736 net.cpp:444] BatchNorm_Convolution_eltwise8 <- Convolution_eltwise8
I0218 21:49:21.459540  9736 net.cpp:405] BatchNorm_Convolution_eltwise8 -> Convolution_eltwise8 (in-place)
I0218 21:49:21.459715  9736 net.cpp:150] Setting up BatchNorm_Convolution_eltwise8
I0218 21:49:21.459722  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.459723  9736 net.cpp:165] Memory required for data: 422750000
I0218 21:49:21.459729  9736 layer_factory.hpp:77] Creating layer Scale_Convolution_eltwise8
I0218 21:49:21.459736  9736 net.cpp:100] Creating Layer Scale_Convolution_eltwise8
I0218 21:49:21.459739  9736 net.cpp:444] Scale_Convolution_eltwise8 <- Convolution_eltwise8
I0218 21:49:21.459743  9736 net.cpp:405] Scale_Convolution_eltwise8 -> Convolution_eltwise8 (in-place)
I0218 21:49:21.459780  9736 layer_factory.hpp:77] Creating layer Scale_Convolution_eltwise8
I0218 21:49:21.459884  9736 net.cpp:150] Setting up Scale_Convolution_eltwise8
I0218 21:49:21.459890  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.459893  9736 net.cpp:165] Memory required for data: 424004400
I0218 21:49:21.459897  9736 layer_factory.hpp:77] Creating layer fuse1
I0218 21:49:21.459904  9736 net.cpp:100] Creating Layer fuse1
I0218 21:49:21.459908  9736 net.cpp:444] fuse1 <- Convolution_eltwise4
I0218 21:49:21.459910  9736 net.cpp:444] fuse1 <- Convolution_eltwise8
I0218 21:49:21.459915  9736 net.cpp:418] fuse1 -> fuse1
I0218 21:49:21.459939  9736 net.cpp:150] Setting up fuse1
I0218 21:49:21.459944  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.459946  9736 net.cpp:165] Memory required for data: 425258800
I0218 21:49:21.459949  9736 layer_factory.hpp:77] Creating layer fuse2
I0218 21:49:21.459955  9736 net.cpp:100] Creating Layer fuse2
I0218 21:49:21.459959  9736 net.cpp:444] fuse2 <- fuse1
I0218 21:49:21.459961  9736 net.cpp:444] fuse2 <- Eltwise12
I0218 21:49:21.459965  9736 net.cpp:418] fuse2 -> fuse2
I0218 21:49:21.459986  9736 net.cpp:150] Setting up fuse2
I0218 21:49:21.459991  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.459993  9736 net.cpp:165] Memory required for data: 426513200
I0218 21:49:21.459996  9736 layer_factory.hpp:77] Creating layer ReLU25
I0218 21:49:21.460000  9736 net.cpp:100] Creating Layer ReLU25
I0218 21:49:21.460003  9736 net.cpp:444] ReLU25 <- fuse2
I0218 21:49:21.460007  9736 net.cpp:405] ReLU25 -> fuse2 (in-place)
I0218 21:49:21.460152  9736 net.cpp:150] Setting up ReLU25
I0218 21:49:21.460161  9736 net.cpp:157] Top shape: 100 64 7 7 (313600)
I0218 21:49:21.460163  9736 net.cpp:165] Memory required for data: 427767600
I0218 21:49:21.460166  9736 layer_factory.hpp:77] Creating layer Pooling1
I0218 21:49:21.460173  9736 net.cpp:100] Creating Layer Pooling1
I0218 21:49:21.460176  9736 net.cpp:444] Pooling1 <- fuse2
I0218 21:49:21.460181  9736 net.cpp:418] Pooling1 -> Pooling1
I0218 21:49:21.460728  9736 net.cpp:150] Setting up Pooling1
I0218 21:49:21.460739  9736 net.cpp:157] Top shape: 100 64 1 1 (6400)
I0218 21:49:21.460743  9736 net.cpp:165] Memory required for data: 427793200
I0218 21:49:21.460747  9736 layer_factory.hpp:77] Creating layer InnerProduct1
I0218 21:49:21.460753  9736 net.cpp:100] Creating Layer InnerProduct1
I0218 21:49:21.460757  9736 net.cpp:444] InnerProduct1 <- Pooling1
I0218 21:49:21.460764  9736 net.cpp:418] InnerProduct1 -> InnerProduct1
I0218 21:49:21.460881  9736 net.cpp:150] Setting up InnerProduct1
I0218 21:49:21.460888  9736 net.cpp:157] Top shape: 100 16 (1600)
I0218 21:49:21.460891  9736 net.cpp:165] Memory required for data: 427799600
I0218 21:49:21.460896  9736 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0218 21:49:21.460902  9736 net.cpp:100] Creating Layer SoftmaxWithLoss1
I0218 21:49:21.460906  9736 net.cpp:444] SoftmaxWithLoss1 <- InnerProduct1
I0218 21:49:21.460908  9736 net.cpp:444] SoftmaxWithLoss1 <- label
I0218 21:49:21.460914  9736 net.cpp:418] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0218 21:49:21.460922  9736 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0218 21:49:21.461153  9736 net.cpp:150] Setting up SoftmaxWithLoss1
I0218 21:49:21.461165  9736 net.cpp:157] Top shape: (1)
I0218 21:49:21.461172  9736 net.cpp:160]     with loss weight 1
I0218 21:49:21.461191  9736 net.cpp:165] Memory required for data: 427799604
I0218 21:49:21.461195  9736 net.cpp:226] SoftmaxWithLoss1 needs backward computation.
I0218 21:49:21.461201  9736 net.cpp:226] InnerProduct1 needs backward computation.
I0218 21:49:21.461205  9736 net.cpp:226] Pooling1 needs backward computation.
I0218 21:49:21.461208  9736 net.cpp:226] ReLU25 needs backward computation.
I0218 21:49:21.461210  9736 net.cpp:226] fuse2 needs backward computation.
I0218 21:49:21.461213  9736 net.cpp:226] fuse1 needs backward computation.
I0218 21:49:21.461217  9736 net.cpp:226] Scale_Convolution_eltwise8 needs backward computation.
I0218 21:49:21.461220  9736 net.cpp:226] BatchNorm_Convolution_eltwise8 needs backward computation.
I0218 21:49:21.461222  9736 net.cpp:226] Convolution_eltwise8 needs backward computation.
I0218 21:49:21.461225  9736 net.cpp:226] Scale_Convolution_eltwise4 needs backward computation.
I0218 21:49:21.461228  9736 net.cpp:226] BatchNorm_Convolution_eltwise4 needs backward computation.
I0218 21:49:21.461231  9736 net.cpp:226] Convolution_eltwise4 needs backward computation.
I0218 21:49:21.461235  9736 net.cpp:226] Eltwise12 needs backward computation.
I0218 21:49:21.461237  9736 net.cpp:226] Scale27 needs backward computation.
I0218 21:49:21.461241  9736 net.cpp:226] BatchNorm27 needs backward computation.
I0218 21:49:21.461243  9736 net.cpp:226] Convolution27 needs backward computation.
I0218 21:49:21.461246  9736 net.cpp:226] ReLU24 needs backward computation.
I0218 21:49:21.461248  9736 net.cpp:226] Scale26 needs backward computation.
I0218 21:49:21.461251  9736 net.cpp:226] BatchNorm26 needs backward computation.
I0218 21:49:21.461253  9736 net.cpp:226] Convolution26 needs backward computation.
I0218 21:49:21.461256  9736 net.cpp:226] Eltwise11_ReLU23_0_split needs backward computation.
I0218 21:49:21.461259  9736 net.cpp:226] ReLU23 needs backward computation.
I0218 21:49:21.461262  9736 net.cpp:226] Eltwise11 needs backward computation.
I0218 21:49:21.461266  9736 net.cpp:226] Scale25 needs backward computation.
I0218 21:49:21.461267  9736 net.cpp:226] BatchNorm25 needs backward computation.
I0218 21:49:21.461271  9736 net.cpp:226] Convolution25 needs backward computation.
I0218 21:49:21.461273  9736 net.cpp:226] ReLU22 needs backward computation.
I0218 21:49:21.461275  9736 net.cpp:226] Scale24 needs backward computation.
I0218 21:49:21.461278  9736 net.cpp:226] BatchNorm24 needs backward computation.
I0218 21:49:21.461280  9736 net.cpp:226] Convolution24 needs backward computation.
I0218 21:49:21.461284  9736 net.cpp:226] Eltwise10_ReLU21_0_split needs backward computation.
I0218 21:49:21.461287  9736 net.cpp:226] ReLU21 needs backward computation.
I0218 21:49:21.461289  9736 net.cpp:226] Eltwise10 needs backward computation.
I0218 21:49:21.461292  9736 net.cpp:226] Scale23 needs backward computation.
I0218 21:49:21.461295  9736 net.cpp:226] BatchNorm23 needs backward computation.
I0218 21:49:21.461298  9736 net.cpp:226] Convolution23 needs backward computation.
I0218 21:49:21.461300  9736 net.cpp:226] ReLU20 needs backward computation.
I0218 21:49:21.461303  9736 net.cpp:226] Scale22 needs backward computation.
I0218 21:49:21.461307  9736 net.cpp:226] BatchNorm22 needs backward computation.
I0218 21:49:21.461308  9736 net.cpp:226] Convolution22 needs backward computation.
I0218 21:49:21.461311  9736 net.cpp:226] Eltwise9_ReLU19_0_split needs backward computation.
I0218 21:49:21.461314  9736 net.cpp:226] ReLU19 needs backward computation.
I0218 21:49:21.461318  9736 net.cpp:226] Eltwise9 needs backward computation.
I0218 21:49:21.461320  9736 net.cpp:226] Scale21 needs backward computation.
I0218 21:49:21.461323  9736 net.cpp:226] BatchNorm21 needs backward computation.
I0218 21:49:21.461325  9736 net.cpp:226] Convolution21 needs backward computation.
I0218 21:49:21.461329  9736 net.cpp:226] ReLU18 needs backward computation.
I0218 21:49:21.461331  9736 net.cpp:226] Scale20 needs backward computation.
I0218 21:49:21.461341  9736 net.cpp:226] BatchNorm20 needs backward computation.
I0218 21:49:21.461344  9736 net.cpp:226] Convolution20 needs backward computation.
I0218 21:49:21.461349  9736 net.cpp:226] Scale19 needs backward computation.
I0218 21:49:21.461352  9736 net.cpp:226] BatchNorm19 needs backward computation.
I0218 21:49:21.461355  9736 net.cpp:226] Convolution19 needs backward computation.
I0218 21:49:21.461359  9736 net.cpp:226] Eltwise8_ReLU17_0_split needs backward computation.
I0218 21:49:21.461361  9736 net.cpp:226] ReLU17 needs backward computation.
I0218 21:49:21.461364  9736 net.cpp:226] Eltwise8 needs backward computation.
I0218 21:49:21.461367  9736 net.cpp:226] Scale18 needs backward computation.
I0218 21:49:21.461370  9736 net.cpp:226] BatchNorm18 needs backward computation.
I0218 21:49:21.461374  9736 net.cpp:226] Convolution18 needs backward computation.
I0218 21:49:21.461375  9736 net.cpp:226] ReLU16 needs backward computation.
I0218 21:49:21.461378  9736 net.cpp:226] Scale17 needs backward computation.
I0218 21:49:21.461381  9736 net.cpp:226] BatchNorm17 needs backward computation.
I0218 21:49:21.461383  9736 net.cpp:226] Convolution17 needs backward computation.
I0218 21:49:21.461386  9736 net.cpp:226] Eltwise7_ReLU15_0_split needs backward computation.
I0218 21:49:21.461390  9736 net.cpp:226] ReLU15 needs backward computation.
I0218 21:49:21.461392  9736 net.cpp:226] Eltwise7 needs backward computation.
I0218 21:49:21.461396  9736 net.cpp:226] Scale16 needs backward computation.
I0218 21:49:21.461400  9736 net.cpp:226] BatchNorm16 needs backward computation.
I0218 21:49:21.461401  9736 net.cpp:226] Convolution16 needs backward computation.
I0218 21:49:21.461405  9736 net.cpp:226] ReLU14 needs backward computation.
I0218 21:49:21.461407  9736 net.cpp:226] Scale15 needs backward computation.
I0218 21:49:21.461410  9736 net.cpp:226] BatchNorm15 needs backward computation.
I0218 21:49:21.461412  9736 net.cpp:226] Convolution15 needs backward computation.
I0218 21:49:21.461416  9736 net.cpp:226] Eltwise6_ReLU13_0_split needs backward computation.
I0218 21:49:21.461418  9736 net.cpp:226] ReLU13 needs backward computation.
I0218 21:49:21.461421  9736 net.cpp:226] Eltwise6 needs backward computation.
I0218 21:49:21.461424  9736 net.cpp:226] Scale14 needs backward computation.
I0218 21:49:21.461427  9736 net.cpp:226] BatchNorm14 needs backward computation.
I0218 21:49:21.461431  9736 net.cpp:226] Convolution14 needs backward computation.
I0218 21:49:21.461432  9736 net.cpp:226] ReLU12 needs backward computation.
I0218 21:49:21.461436  9736 net.cpp:226] Scale13 needs backward computation.
I0218 21:49:21.461437  9736 net.cpp:226] BatchNorm13 needs backward computation.
I0218 21:49:21.461441  9736 net.cpp:226] Convolution13 needs backward computation.
I0218 21:49:21.461443  9736 net.cpp:226] Eltwise5_ReLU11_0_split needs backward computation.
I0218 21:49:21.461449  9736 net.cpp:226] ReLU11 needs backward computation.
I0218 21:49:21.461452  9736 net.cpp:226] Eltwise5 needs backward computation.
I0218 21:49:21.461455  9736 net.cpp:226] Scale12 needs backward computation.
I0218 21:49:21.461458  9736 net.cpp:226] BatchNorm12 needs backward computation.
I0218 21:49:21.461462  9736 net.cpp:226] Convolution12 needs backward computation.
I0218 21:49:21.461463  9736 net.cpp:226] ReLU10 needs backward computation.
I0218 21:49:21.461467  9736 net.cpp:226] Scale11 needs backward computation.
I0218 21:49:21.461469  9736 net.cpp:226] BatchNorm11 needs backward computation.
I0218 21:49:21.461472  9736 net.cpp:226] Convolution11 needs backward computation.
I0218 21:49:21.461475  9736 net.cpp:226] Scale10 needs backward computation.
I0218 21:49:21.461478  9736 net.cpp:226] BatchNorm10 needs backward computation.
I0218 21:49:21.461482  9736 net.cpp:226] Convolution10 needs backward computation.
I0218 21:49:21.461484  9736 net.cpp:226] Eltwise4_ReLU9_0_split needs backward computation.
I0218 21:49:21.461488  9736 net.cpp:226] ReLU9 needs backward computation.
I0218 21:49:21.461493  9736 net.cpp:226] Eltwise4 needs backward computation.
I0218 21:49:21.461499  9736 net.cpp:226] Scale9 needs backward computation.
I0218 21:49:21.461503  9736 net.cpp:226] BatchNorm9 needs backward computation.
I0218 21:49:21.461504  9736 net.cpp:226] Convolution9 needs backward computation.
I0218 21:49:21.461508  9736 net.cpp:226] ReLU8 needs backward computation.
I0218 21:49:21.461510  9736 net.cpp:226] Scale8 needs backward computation.
I0218 21:49:21.461513  9736 net.cpp:226] BatchNorm8 needs backward computation.
I0218 21:49:21.461516  9736 net.cpp:226] Convolution8 needs backward computation.
I0218 21:49:21.461519  9736 net.cpp:226] Eltwise3_ReLU7_0_split needs backward computation.
I0218 21:49:21.461522  9736 net.cpp:226] ReLU7 needs backward computation.
I0218 21:49:21.461526  9736 net.cpp:226] Eltwise3 needs backward computation.
I0218 21:49:21.461529  9736 net.cpp:226] Scale7 needs backward computation.
I0218 21:49:21.461532  9736 net.cpp:226] BatchNorm7 needs backward computation.
I0218 21:49:21.461535  9736 net.cpp:226] Convolution7 needs backward computation.
I0218 21:49:21.461539  9736 net.cpp:226] ReLU6 needs backward computation.
I0218 21:49:21.461541  9736 net.cpp:226] Scale6 needs backward computation.
I0218 21:49:21.461544  9736 net.cpp:226] BatchNorm6 needs backward computation.
I0218 21:49:21.461547  9736 net.cpp:226] Convolution6 needs backward computation.
I0218 21:49:21.461549  9736 net.cpp:226] Eltwise2_ReLU5_0_split needs backward computation.
I0218 21:49:21.461552  9736 net.cpp:226] ReLU5 needs backward computation.
I0218 21:49:21.461556  9736 net.cpp:226] Eltwise2 needs backward computation.
I0218 21:49:21.461560  9736 net.cpp:226] Scale5 needs backward computation.
I0218 21:49:21.461562  9736 net.cpp:226] BatchNorm5 needs backward computation.
I0218 21:49:21.461565  9736 net.cpp:226] Convolution5 needs backward computation.
I0218 21:49:21.461567  9736 net.cpp:226] ReLU4 needs backward computation.
I0218 21:49:21.461570  9736 net.cpp:226] Scale4 needs backward computation.
I0218 21:49:21.461573  9736 net.cpp:226] BatchNorm4 needs backward computation.
I0218 21:49:21.461576  9736 net.cpp:226] Convolution4 needs backward computation.
I0218 21:49:21.461580  9736 net.cpp:226] Eltwise1_ReLU3_0_split needs backward computation.
I0218 21:49:21.461582  9736 net.cpp:226] ReLU3 needs backward computation.
I0218 21:49:21.461585  9736 net.cpp:226] Eltwise1 needs backward computation.
I0218 21:49:21.461588  9736 net.cpp:226] Scale3 needs backward computation.
I0218 21:49:21.461591  9736 net.cpp:226] BatchNorm3 needs backward computation.
I0218 21:49:21.461594  9736 net.cpp:226] Convolution3 needs backward computation.
I0218 21:49:21.461598  9736 net.cpp:226] ReLU2 needs backward computation.
I0218 21:49:21.461601  9736 net.cpp:226] Scale2 needs backward computation.
I0218 21:49:21.461604  9736 net.cpp:226] BatchNorm2 needs backward computation.
I0218 21:49:21.461607  9736 net.cpp:226] Convolution2 needs backward computation.
I0218 21:49:21.461611  9736 net.cpp:226] Convolution1_ReLU1_0_split needs backward computation.
I0218 21:49:21.461613  9736 net.cpp:226] ReLU1 needs backward computation.
I0218 21:49:21.461616  9736 net.cpp:226] Scale1 needs backward computation.
I0218 21:49:21.461619  9736 net.cpp:226] BatchNorm1 needs backward computation.
I0218 21:49:21.461621  9736 net.cpp:226] Convolution1 needs backward computation.
I0218 21:49:21.461625  9736 net.cpp:228] salinas does not need backward computation.
I0218 21:49:21.461628  9736 net.cpp:270] This network produces output SoftmaxWithLoss1
I0218 21:49:21.461683  9736 net.cpp:283] Network initialization done.
I0218 21:49:21.462472  9736 solver.cpp:181] Creating test net (#0) specified by net file: ./prototxt_files/train_salinas.prototxt
I0218 21:49:21.462553  9736 net.cpp:332] The NetState phase (1) differed from the phase (0) specified by a rule in layer salinas
I0218 21:49:21.463055  9736 net.cpp:58] Initializing net from parameters: 
name: "DFFN_salinas"
state {
  phase: TEST
}
layer {
  name: "salinas"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "samples/salinas/test.txt"
    batch_size: 50
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "data"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution11"
  top: "Convolution11"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Convolution11"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Convolution10"
  bottom: "Convolution12"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "Convolution13"
  top: "Convolution13"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Convolution15"
  top: "Convolution15"
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Convolution15"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution16"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution17"
  top: "Convolution17"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Convolution17"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution18"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution20"
  top: "Convolution20"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Convolution19"
  bottom: "Convolution21"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU20"
  type: "ReLU"
  bottom: "Convolution22"
  top: "Convolution22"
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Convolution22"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Eltwise9"
  bottom: "Convolution23"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "Convolution24"
  top: "Convolution24"
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Convolution24"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution25"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "Eltwise11"
  top: "Eltwise11"
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU24"
  type: "ReLU"
  bottom: "Convolution26"
  top: "Convolution26"
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Convolution26"
  top: "Convolution27"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Eltwise11"
  bottom: "Convolution27"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution_eltwise4"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution_eltwise4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm_Convolution_eltwise4"
  type: "BatchNorm"
  bottom: "Convolution_eltwise4"
  top: "Convolution_eltwise4"
}
layer {
  name: "Scale_Convolution_eltwise4"
  type: "Scale"
  bottom: "Convolution_eltwise4"
  top: "Convolution_eltwise4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution_eltwise8"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution_eltwise8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm_Convolution_eltwise8"
  type: "BatchNorm"
  bottom: "Convolution_eltwise8"
  top: "Convolution_eltwise8"
}
layer {
  name: "Scale_Convolution_eltwise8"
  type: "Scale"
  bottom: "Convolution_eltwise8"
  top: "Convolution_eltwise8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "fuse1"
  type: "Eltwise"
  bottom: "Convolution_eltwise4"
  bottom: "Convolution_eltwise8"
  top: "fuse1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "fuse2"
  type: "Eltwise"
  bottom: "fuse1"
  bottom: "Eltwise12"
  top: "fuse2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "fuse2"
  top: "fuse2"
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "fuse2"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "InnerProduct1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 16
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "label"
  top: "SoftmaxWithLoss1"
}
layer {
  name: "Accuracy1"
  type: "Accuracy"
  bottom: "InnerProduct1"
  bottom: "label"
  top: "Accuracy1"
  include {
    phase: TEST
  }
}
I0218 21:49:21.463357  9736 layer_factory.hpp:77] Creating layer salinas
I0218 21:49:21.463367  9736 net.cpp:100] Creating Layer salinas
I0218 21:49:21.463371  9736 net.cpp:418] salinas -> data
I0218 21:49:21.463378  9736 net.cpp:418] salinas -> label
I0218 21:49:21.463383  9736 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: samples/salinas/test.txt
I0218 21:49:21.463402  9736 hdf5_data_layer.cpp:93] Number of HDF5 files: 5
I0218 21:49:21.618899  9736 net.cpp:150] Setting up salinas
I0218 21:49:21.618932  9736 net.cpp:157] Top shape: 50 10 27 27 (364500)
I0218 21:49:21.618937  9736 net.cpp:157] Top shape: 50 1 (50)
I0218 21:49:21.618938  9736 net.cpp:165] Memory required for data: 1458200
I0218 21:49:21.618944  9736 layer_factory.hpp:77] Creating layer label_salinas_1_split
I0218 21:49:21.618963  9736 net.cpp:100] Creating Layer label_salinas_1_split
I0218 21:49:21.618974  9736 net.cpp:444] label_salinas_1_split <- label
I0218 21:49:21.618981  9736 net.cpp:418] label_salinas_1_split -> label_salinas_1_split_0
I0218 21:49:21.618989  9736 net.cpp:418] label_salinas_1_split -> label_salinas_1_split_1
I0218 21:49:21.619029  9736 net.cpp:150] Setting up label_salinas_1_split
I0218 21:49:21.619033  9736 net.cpp:157] Top shape: 50 1 (50)
I0218 21:49:21.619036  9736 net.cpp:157] Top shape: 50 1 (50)
I0218 21:49:21.619040  9736 net.cpp:165] Memory required for data: 1458600
I0218 21:49:21.619042  9736 layer_factory.hpp:77] Creating layer Convolution1
I0218 21:49:21.619053  9736 net.cpp:100] Creating Layer Convolution1
I0218 21:49:21.619056  9736 net.cpp:444] Convolution1 <- data
I0218 21:49:21.619060  9736 net.cpp:418] Convolution1 -> Convolution1
I0218 21:49:21.620659  9736 net.cpp:150] Setting up Convolution1
I0218 21:49:21.620673  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.620676  9736 net.cpp:165] Memory required for data: 3791400
I0218 21:49:21.620685  9736 layer_factory.hpp:77] Creating layer BatchNorm1
I0218 21:49:21.620692  9736 net.cpp:100] Creating Layer BatchNorm1
I0218 21:49:21.620697  9736 net.cpp:444] BatchNorm1 <- Convolution1
I0218 21:49:21.620700  9736 net.cpp:405] BatchNorm1 -> Convolution1 (in-place)
I0218 21:49:21.620888  9736 net.cpp:150] Setting up BatchNorm1
I0218 21:49:21.620895  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.620898  9736 net.cpp:165] Memory required for data: 6124200
I0218 21:49:21.620905  9736 layer_factory.hpp:77] Creating layer Scale1
I0218 21:49:21.620913  9736 net.cpp:100] Creating Layer Scale1
I0218 21:49:21.620915  9736 net.cpp:444] Scale1 <- Convolution1
I0218 21:49:21.620919  9736 net.cpp:405] Scale1 -> Convolution1 (in-place)
I0218 21:49:21.620957  9736 layer_factory.hpp:77] Creating layer Scale1
I0218 21:49:21.621063  9736 net.cpp:150] Setting up Scale1
I0218 21:49:21.621069  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.621073  9736 net.cpp:165] Memory required for data: 8457000
I0218 21:49:21.621076  9736 layer_factory.hpp:77] Creating layer ReLU1
I0218 21:49:21.621081  9736 net.cpp:100] Creating Layer ReLU1
I0218 21:49:21.621084  9736 net.cpp:444] ReLU1 <- Convolution1
I0218 21:49:21.621088  9736 net.cpp:405] ReLU1 -> Convolution1 (in-place)
I0218 21:49:21.621232  9736 net.cpp:150] Setting up ReLU1
I0218 21:49:21.621240  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.621243  9736 net.cpp:165] Memory required for data: 10789800
I0218 21:49:21.621246  9736 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I0218 21:49:21.621251  9736 net.cpp:100] Creating Layer Convolution1_ReLU1_0_split
I0218 21:49:21.621254  9736 net.cpp:444] Convolution1_ReLU1_0_split <- Convolution1
I0218 21:49:21.621259  9736 net.cpp:418] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I0218 21:49:21.621264  9736 net.cpp:418] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I0218 21:49:21.621302  9736 net.cpp:150] Setting up Convolution1_ReLU1_0_split
I0218 21:49:21.621309  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.621311  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.621315  9736 net.cpp:165] Memory required for data: 15455400
I0218 21:49:21.621316  9736 layer_factory.hpp:77] Creating layer Convolution2
I0218 21:49:21.621323  9736 net.cpp:100] Creating Layer Convolution2
I0218 21:49:21.621327  9736 net.cpp:444] Convolution2 <- Convolution1_ReLU1_0_split_0
I0218 21:49:21.621332  9736 net.cpp:418] Convolution2 -> Convolution2
I0218 21:49:21.622747  9736 net.cpp:150] Setting up Convolution2
I0218 21:49:21.622761  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.622764  9736 net.cpp:165] Memory required for data: 17788200
I0218 21:49:21.622771  9736 layer_factory.hpp:77] Creating layer BatchNorm2
I0218 21:49:21.622778  9736 net.cpp:100] Creating Layer BatchNorm2
I0218 21:49:21.622782  9736 net.cpp:444] BatchNorm2 <- Convolution2
I0218 21:49:21.622792  9736 net.cpp:405] BatchNorm2 -> Convolution2 (in-place)
I0218 21:49:21.622973  9736 net.cpp:150] Setting up BatchNorm2
I0218 21:49:21.622979  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.622982  9736 net.cpp:165] Memory required for data: 20121000
I0218 21:49:21.622989  9736 layer_factory.hpp:77] Creating layer Scale2
I0218 21:49:21.622994  9736 net.cpp:100] Creating Layer Scale2
I0218 21:49:21.622997  9736 net.cpp:444] Scale2 <- Convolution2
I0218 21:49:21.623001  9736 net.cpp:405] Scale2 -> Convolution2 (in-place)
I0218 21:49:21.623037  9736 layer_factory.hpp:77] Creating layer Scale2
I0218 21:49:21.623139  9736 net.cpp:150] Setting up Scale2
I0218 21:49:21.623145  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.623148  9736 net.cpp:165] Memory required for data: 22453800
I0218 21:49:21.623153  9736 layer_factory.hpp:77] Creating layer ReLU2
I0218 21:49:21.623158  9736 net.cpp:100] Creating Layer ReLU2
I0218 21:49:21.623160  9736 net.cpp:444] ReLU2 <- Convolution2
I0218 21:49:21.623164  9736 net.cpp:405] ReLU2 -> Convolution2 (in-place)
I0218 21:49:21.623689  9736 net.cpp:150] Setting up ReLU2
I0218 21:49:21.623700  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.623703  9736 net.cpp:165] Memory required for data: 24786600
I0218 21:49:21.623706  9736 layer_factory.hpp:77] Creating layer Convolution3
I0218 21:49:21.623715  9736 net.cpp:100] Creating Layer Convolution3
I0218 21:49:21.623718  9736 net.cpp:444] Convolution3 <- Convolution2
I0218 21:49:21.623723  9736 net.cpp:418] Convolution3 -> Convolution3
I0218 21:49:21.625138  9736 net.cpp:150] Setting up Convolution3
I0218 21:49:21.625151  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.625154  9736 net.cpp:165] Memory required for data: 27119400
I0218 21:49:21.625160  9736 layer_factory.hpp:77] Creating layer BatchNorm3
I0218 21:49:21.625166  9736 net.cpp:100] Creating Layer BatchNorm3
I0218 21:49:21.625169  9736 net.cpp:444] BatchNorm3 <- Convolution3
I0218 21:49:21.625174  9736 net.cpp:405] BatchNorm3 -> Convolution3 (in-place)
I0218 21:49:21.625347  9736 net.cpp:150] Setting up BatchNorm3
I0218 21:49:21.625353  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.625356  9736 net.cpp:165] Memory required for data: 29452200
I0218 21:49:21.625365  9736 layer_factory.hpp:77] Creating layer Scale3
I0218 21:49:21.625370  9736 net.cpp:100] Creating Layer Scale3
I0218 21:49:21.625372  9736 net.cpp:444] Scale3 <- Convolution3
I0218 21:49:21.625376  9736 net.cpp:405] Scale3 -> Convolution3 (in-place)
I0218 21:49:21.625413  9736 layer_factory.hpp:77] Creating layer Scale3
I0218 21:49:21.625515  9736 net.cpp:150] Setting up Scale3
I0218 21:49:21.625520  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.625524  9736 net.cpp:165] Memory required for data: 31785000
I0218 21:49:21.625528  9736 layer_factory.hpp:77] Creating layer Eltwise1
I0218 21:49:21.625533  9736 net.cpp:100] Creating Layer Eltwise1
I0218 21:49:21.625536  9736 net.cpp:444] Eltwise1 <- Convolution1_ReLU1_0_split_1
I0218 21:49:21.625540  9736 net.cpp:444] Eltwise1 <- Convolution3
I0218 21:49:21.625545  9736 net.cpp:418] Eltwise1 -> Eltwise1
I0218 21:49:21.625567  9736 net.cpp:150] Setting up Eltwise1
I0218 21:49:21.625572  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.625576  9736 net.cpp:165] Memory required for data: 34117800
I0218 21:49:21.625578  9736 layer_factory.hpp:77] Creating layer ReLU3
I0218 21:49:21.625582  9736 net.cpp:100] Creating Layer ReLU3
I0218 21:49:21.625586  9736 net.cpp:444] ReLU3 <- Eltwise1
I0218 21:49:21.625589  9736 net.cpp:405] ReLU3 -> Eltwise1 (in-place)
I0218 21:49:21.625728  9736 net.cpp:150] Setting up ReLU3
I0218 21:49:21.625736  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.625738  9736 net.cpp:165] Memory required for data: 36450600
I0218 21:49:21.625741  9736 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I0218 21:49:21.625747  9736 net.cpp:100] Creating Layer Eltwise1_ReLU3_0_split
I0218 21:49:21.625754  9736 net.cpp:444] Eltwise1_ReLU3_0_split <- Eltwise1
I0218 21:49:21.625764  9736 net.cpp:418] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I0218 21:49:21.625771  9736 net.cpp:418] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I0218 21:49:21.625809  9736 net.cpp:150] Setting up Eltwise1_ReLU3_0_split
I0218 21:49:21.625814  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.625818  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.625820  9736 net.cpp:165] Memory required for data: 41116200
I0218 21:49:21.625823  9736 layer_factory.hpp:77] Creating layer Convolution4
I0218 21:49:21.625830  9736 net.cpp:100] Creating Layer Convolution4
I0218 21:49:21.625833  9736 net.cpp:444] Convolution4 <- Eltwise1_ReLU3_0_split_0
I0218 21:49:21.625838  9736 net.cpp:418] Convolution4 -> Convolution4
I0218 21:49:21.627614  9736 net.cpp:150] Setting up Convolution4
I0218 21:49:21.627626  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.627629  9736 net.cpp:165] Memory required for data: 43449000
I0218 21:49:21.627635  9736 layer_factory.hpp:77] Creating layer BatchNorm4
I0218 21:49:21.627642  9736 net.cpp:100] Creating Layer BatchNorm4
I0218 21:49:21.627646  9736 net.cpp:444] BatchNorm4 <- Convolution4
I0218 21:49:21.627651  9736 net.cpp:405] BatchNorm4 -> Convolution4 (in-place)
I0218 21:49:21.627838  9736 net.cpp:150] Setting up BatchNorm4
I0218 21:49:21.627845  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.627847  9736 net.cpp:165] Memory required for data: 45781800
I0218 21:49:21.627852  9736 layer_factory.hpp:77] Creating layer Scale4
I0218 21:49:21.627859  9736 net.cpp:100] Creating Layer Scale4
I0218 21:49:21.627862  9736 net.cpp:444] Scale4 <- Convolution4
I0218 21:49:21.627866  9736 net.cpp:405] Scale4 -> Convolution4 (in-place)
I0218 21:49:21.627903  9736 layer_factory.hpp:77] Creating layer Scale4
I0218 21:49:21.628011  9736 net.cpp:150] Setting up Scale4
I0218 21:49:21.628017  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.628021  9736 net.cpp:165] Memory required for data: 48114600
I0218 21:49:21.628026  9736 layer_factory.hpp:77] Creating layer ReLU4
I0218 21:49:21.628031  9736 net.cpp:100] Creating Layer ReLU4
I0218 21:49:21.628034  9736 net.cpp:444] ReLU4 <- Convolution4
I0218 21:49:21.628037  9736 net.cpp:405] ReLU4 -> Convolution4 (in-place)
I0218 21:49:21.628185  9736 net.cpp:150] Setting up ReLU4
I0218 21:49:21.628192  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.628195  9736 net.cpp:165] Memory required for data: 50447400
I0218 21:49:21.628197  9736 layer_factory.hpp:77] Creating layer Convolution5
I0218 21:49:21.628206  9736 net.cpp:100] Creating Layer Convolution5
I0218 21:49:21.628211  9736 net.cpp:444] Convolution5 <- Convolution4
I0218 21:49:21.628216  9736 net.cpp:418] Convolution5 -> Convolution5
I0218 21:49:21.629649  9736 net.cpp:150] Setting up Convolution5
I0218 21:49:21.629662  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.629664  9736 net.cpp:165] Memory required for data: 52780200
I0218 21:49:21.629670  9736 layer_factory.hpp:77] Creating layer BatchNorm5
I0218 21:49:21.629675  9736 net.cpp:100] Creating Layer BatchNorm5
I0218 21:49:21.629679  9736 net.cpp:444] BatchNorm5 <- Convolution5
I0218 21:49:21.629685  9736 net.cpp:405] BatchNorm5 -> Convolution5 (in-place)
I0218 21:49:21.629868  9736 net.cpp:150] Setting up BatchNorm5
I0218 21:49:21.629874  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.629876  9736 net.cpp:165] Memory required for data: 55113000
I0218 21:49:21.629885  9736 layer_factory.hpp:77] Creating layer Scale5
I0218 21:49:21.629890  9736 net.cpp:100] Creating Layer Scale5
I0218 21:49:21.629894  9736 net.cpp:444] Scale5 <- Convolution5
I0218 21:49:21.629897  9736 net.cpp:405] Scale5 -> Convolution5 (in-place)
I0218 21:49:21.629936  9736 layer_factory.hpp:77] Creating layer Scale5
I0218 21:49:21.630044  9736 net.cpp:150] Setting up Scale5
I0218 21:49:21.630051  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.630054  9736 net.cpp:165] Memory required for data: 57445800
I0218 21:49:21.630066  9736 layer_factory.hpp:77] Creating layer Eltwise2
I0218 21:49:21.630072  9736 net.cpp:100] Creating Layer Eltwise2
I0218 21:49:21.630075  9736 net.cpp:444] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I0218 21:49:21.630079  9736 net.cpp:444] Eltwise2 <- Convolution5
I0218 21:49:21.630084  9736 net.cpp:418] Eltwise2 -> Eltwise2
I0218 21:49:21.630111  9736 net.cpp:150] Setting up Eltwise2
I0218 21:49:21.630121  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.630126  9736 net.cpp:165] Memory required for data: 59778600
I0218 21:49:21.630131  9736 layer_factory.hpp:77] Creating layer ReLU5
I0218 21:49:21.630134  9736 net.cpp:100] Creating Layer ReLU5
I0218 21:49:21.630137  9736 net.cpp:444] ReLU5 <- Eltwise2
I0218 21:49:21.630141  9736 net.cpp:405] ReLU5 -> Eltwise2 (in-place)
I0218 21:49:21.630666  9736 net.cpp:150] Setting up ReLU5
I0218 21:49:21.630676  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.630679  9736 net.cpp:165] Memory required for data: 62111400
I0218 21:49:21.630682  9736 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I0218 21:49:21.630689  9736 net.cpp:100] Creating Layer Eltwise2_ReLU5_0_split
I0218 21:49:21.630692  9736 net.cpp:444] Eltwise2_ReLU5_0_split <- Eltwise2
I0218 21:49:21.630697  9736 net.cpp:418] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I0218 21:49:21.630702  9736 net.cpp:418] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I0218 21:49:21.630745  9736 net.cpp:150] Setting up Eltwise2_ReLU5_0_split
I0218 21:49:21.630753  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.630755  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.630759  9736 net.cpp:165] Memory required for data: 66777000
I0218 21:49:21.630761  9736 layer_factory.hpp:77] Creating layer Convolution6
I0218 21:49:21.630769  9736 net.cpp:100] Creating Layer Convolution6
I0218 21:49:21.630772  9736 net.cpp:444] Convolution6 <- Eltwise2_ReLU5_0_split_0
I0218 21:49:21.630779  9736 net.cpp:418] Convolution6 -> Convolution6
I0218 21:49:21.632223  9736 net.cpp:150] Setting up Convolution6
I0218 21:49:21.632236  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.632238  9736 net.cpp:165] Memory required for data: 69109800
I0218 21:49:21.632244  9736 layer_factory.hpp:77] Creating layer BatchNorm6
I0218 21:49:21.632251  9736 net.cpp:100] Creating Layer BatchNorm6
I0218 21:49:21.632254  9736 net.cpp:444] BatchNorm6 <- Convolution6
I0218 21:49:21.632259  9736 net.cpp:405] BatchNorm6 -> Convolution6 (in-place)
I0218 21:49:21.632444  9736 net.cpp:150] Setting up BatchNorm6
I0218 21:49:21.632452  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.632454  9736 net.cpp:165] Memory required for data: 71442600
I0218 21:49:21.632459  9736 layer_factory.hpp:77] Creating layer Scale6
I0218 21:49:21.632465  9736 net.cpp:100] Creating Layer Scale6
I0218 21:49:21.632469  9736 net.cpp:444] Scale6 <- Convolution6
I0218 21:49:21.632473  9736 net.cpp:405] Scale6 -> Convolution6 (in-place)
I0218 21:49:21.632511  9736 layer_factory.hpp:77] Creating layer Scale6
I0218 21:49:21.632624  9736 net.cpp:150] Setting up Scale6
I0218 21:49:21.632630  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.632633  9736 net.cpp:165] Memory required for data: 73775400
I0218 21:49:21.632638  9736 layer_factory.hpp:77] Creating layer ReLU6
I0218 21:49:21.632642  9736 net.cpp:100] Creating Layer ReLU6
I0218 21:49:21.632645  9736 net.cpp:444] ReLU6 <- Convolution6
I0218 21:49:21.632650  9736 net.cpp:405] ReLU6 -> Convolution6 (in-place)
I0218 21:49:21.632795  9736 net.cpp:150] Setting up ReLU6
I0218 21:49:21.632802  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.632805  9736 net.cpp:165] Memory required for data: 76108200
I0218 21:49:21.632808  9736 layer_factory.hpp:77] Creating layer Convolution7
I0218 21:49:21.632817  9736 net.cpp:100] Creating Layer Convolution7
I0218 21:49:21.632820  9736 net.cpp:444] Convolution7 <- Convolution6
I0218 21:49:21.632827  9736 net.cpp:418] Convolution7 -> Convolution7
I0218 21:49:21.634320  9736 net.cpp:150] Setting up Convolution7
I0218 21:49:21.634333  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.634336  9736 net.cpp:165] Memory required for data: 78441000
I0218 21:49:21.634342  9736 layer_factory.hpp:77] Creating layer BatchNorm7
I0218 21:49:21.634351  9736 net.cpp:100] Creating Layer BatchNorm7
I0218 21:49:21.634356  9736 net.cpp:444] BatchNorm7 <- Convolution7
I0218 21:49:21.634361  9736 net.cpp:405] BatchNorm7 -> Convolution7 (in-place)
I0218 21:49:21.634548  9736 net.cpp:150] Setting up BatchNorm7
I0218 21:49:21.634554  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.634557  9736 net.cpp:165] Memory required for data: 80773800
I0218 21:49:21.634563  9736 layer_factory.hpp:77] Creating layer Scale7
I0218 21:49:21.634569  9736 net.cpp:100] Creating Layer Scale7
I0218 21:49:21.634572  9736 net.cpp:444] Scale7 <- Convolution7
I0218 21:49:21.634577  9736 net.cpp:405] Scale7 -> Convolution7 (in-place)
I0218 21:49:21.634614  9736 layer_factory.hpp:77] Creating layer Scale7
I0218 21:49:21.634733  9736 net.cpp:150] Setting up Scale7
I0218 21:49:21.634740  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.634743  9736 net.cpp:165] Memory required for data: 83106600
I0218 21:49:21.634747  9736 layer_factory.hpp:77] Creating layer Eltwise3
I0218 21:49:21.634753  9736 net.cpp:100] Creating Layer Eltwise3
I0218 21:49:21.634757  9736 net.cpp:444] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I0218 21:49:21.634762  9736 net.cpp:444] Eltwise3 <- Convolution7
I0218 21:49:21.634765  9736 net.cpp:418] Eltwise3 -> Eltwise3
I0218 21:49:21.634793  9736 net.cpp:150] Setting up Eltwise3
I0218 21:49:21.634799  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.634800  9736 net.cpp:165] Memory required for data: 85439400
I0218 21:49:21.634804  9736 layer_factory.hpp:77] Creating layer ReLU7
I0218 21:49:21.634807  9736 net.cpp:100] Creating Layer ReLU7
I0218 21:49:21.634810  9736 net.cpp:444] ReLU7 <- Eltwise3
I0218 21:49:21.634814  9736 net.cpp:405] ReLU7 -> Eltwise3 (in-place)
I0218 21:49:21.634963  9736 net.cpp:150] Setting up ReLU7
I0218 21:49:21.634970  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.634972  9736 net.cpp:165] Memory required for data: 87772200
I0218 21:49:21.634975  9736 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I0218 21:49:21.634980  9736 net.cpp:100] Creating Layer Eltwise3_ReLU7_0_split
I0218 21:49:21.634984  9736 net.cpp:444] Eltwise3_ReLU7_0_split <- Eltwise3
I0218 21:49:21.634989  9736 net.cpp:418] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I0218 21:49:21.634994  9736 net.cpp:418] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I0218 21:49:21.635033  9736 net.cpp:150] Setting up Eltwise3_ReLU7_0_split
I0218 21:49:21.635038  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.635042  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.635044  9736 net.cpp:165] Memory required for data: 92437800
I0218 21:49:21.635046  9736 layer_factory.hpp:77] Creating layer Convolution8
I0218 21:49:21.635056  9736 net.cpp:100] Creating Layer Convolution8
I0218 21:49:21.635058  9736 net.cpp:444] Convolution8 <- Eltwise3_ReLU7_0_split_0
I0218 21:49:21.635064  9736 net.cpp:418] Convolution8 -> Convolution8
I0218 21:49:21.636864  9736 net.cpp:150] Setting up Convolution8
I0218 21:49:21.636878  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.636880  9736 net.cpp:165] Memory required for data: 94770600
I0218 21:49:21.636886  9736 layer_factory.hpp:77] Creating layer BatchNorm8
I0218 21:49:21.636891  9736 net.cpp:100] Creating Layer BatchNorm8
I0218 21:49:21.636895  9736 net.cpp:444] BatchNorm8 <- Convolution8
I0218 21:49:21.636900  9736 net.cpp:405] BatchNorm8 -> Convolution8 (in-place)
I0218 21:49:21.637092  9736 net.cpp:150] Setting up BatchNorm8
I0218 21:49:21.637099  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.637102  9736 net.cpp:165] Memory required for data: 97103400
I0218 21:49:21.637107  9736 layer_factory.hpp:77] Creating layer Scale8
I0218 21:49:21.637121  9736 net.cpp:100] Creating Layer Scale8
I0218 21:49:21.637125  9736 net.cpp:444] Scale8 <- Convolution8
I0218 21:49:21.637130  9736 net.cpp:405] Scale8 -> Convolution8 (in-place)
I0218 21:49:21.637171  9736 layer_factory.hpp:77] Creating layer Scale8
I0218 21:49:21.637290  9736 net.cpp:150] Setting up Scale8
I0218 21:49:21.637295  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.637298  9736 net.cpp:165] Memory required for data: 99436200
I0218 21:49:21.637303  9736 layer_factory.hpp:77] Creating layer ReLU8
I0218 21:49:21.637308  9736 net.cpp:100] Creating Layer ReLU8
I0218 21:49:21.637311  9736 net.cpp:444] ReLU8 <- Convolution8
I0218 21:49:21.637315  9736 net.cpp:405] ReLU8 -> Convolution8 (in-place)
I0218 21:49:21.637842  9736 net.cpp:150] Setting up ReLU8
I0218 21:49:21.637853  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.637856  9736 net.cpp:165] Memory required for data: 101769000
I0218 21:49:21.637859  9736 layer_factory.hpp:77] Creating layer Convolution9
I0218 21:49:21.637868  9736 net.cpp:100] Creating Layer Convolution9
I0218 21:49:21.637871  9736 net.cpp:444] Convolution9 <- Convolution8
I0218 21:49:21.637877  9736 net.cpp:418] Convolution9 -> Convolution9
I0218 21:49:21.639343  9736 net.cpp:150] Setting up Convolution9
I0218 21:49:21.639355  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.639358  9736 net.cpp:165] Memory required for data: 104101800
I0218 21:49:21.639364  9736 layer_factory.hpp:77] Creating layer BatchNorm9
I0218 21:49:21.639371  9736 net.cpp:100] Creating Layer BatchNorm9
I0218 21:49:21.639374  9736 net.cpp:444] BatchNorm9 <- Convolution9
I0218 21:49:21.639380  9736 net.cpp:405] BatchNorm9 -> Convolution9 (in-place)
I0218 21:49:21.639580  9736 net.cpp:150] Setting up BatchNorm9
I0218 21:49:21.639587  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.639590  9736 net.cpp:165] Memory required for data: 106434600
I0218 21:49:21.639596  9736 layer_factory.hpp:77] Creating layer Scale9
I0218 21:49:21.639602  9736 net.cpp:100] Creating Layer Scale9
I0218 21:49:21.639606  9736 net.cpp:444] Scale9 <- Convolution9
I0218 21:49:21.639611  9736 net.cpp:405] Scale9 -> Convolution9 (in-place)
I0218 21:49:21.639649  9736 layer_factory.hpp:77] Creating layer Scale9
I0218 21:49:21.639763  9736 net.cpp:150] Setting up Scale9
I0218 21:49:21.639770  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.639772  9736 net.cpp:165] Memory required for data: 108767400
I0218 21:49:21.639777  9736 layer_factory.hpp:77] Creating layer Eltwise4
I0218 21:49:21.639784  9736 net.cpp:100] Creating Layer Eltwise4
I0218 21:49:21.639787  9736 net.cpp:444] Eltwise4 <- Eltwise3_ReLU7_0_split_1
I0218 21:49:21.639791  9736 net.cpp:444] Eltwise4 <- Convolution9
I0218 21:49:21.639796  9736 net.cpp:418] Eltwise4 -> Eltwise4
I0218 21:49:21.639820  9736 net.cpp:150] Setting up Eltwise4
I0218 21:49:21.639827  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.639829  9736 net.cpp:165] Memory required for data: 111100200
I0218 21:49:21.639832  9736 layer_factory.hpp:77] Creating layer ReLU9
I0218 21:49:21.639837  9736 net.cpp:100] Creating Layer ReLU9
I0218 21:49:21.639840  9736 net.cpp:444] ReLU9 <- Eltwise4
I0218 21:49:21.639844  9736 net.cpp:405] ReLU9 -> Eltwise4 (in-place)
I0218 21:49:21.639989  9736 net.cpp:150] Setting up ReLU9
I0218 21:49:21.639997  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.640000  9736 net.cpp:165] Memory required for data: 113433000
I0218 21:49:21.640003  9736 layer_factory.hpp:77] Creating layer Eltwise4_ReLU9_0_split
I0218 21:49:21.640009  9736 net.cpp:100] Creating Layer Eltwise4_ReLU9_0_split
I0218 21:49:21.640012  9736 net.cpp:444] Eltwise4_ReLU9_0_split <- Eltwise4
I0218 21:49:21.640018  9736 net.cpp:418] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_0
I0218 21:49:21.640023  9736 net.cpp:418] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_1
I0218 21:49:21.640028  9736 net.cpp:418] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_2
I0218 21:49:21.640084  9736 net.cpp:150] Setting up Eltwise4_ReLU9_0_split
I0218 21:49:21.640095  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.640100  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.640102  9736 net.cpp:157] Top shape: 50 16 27 27 (583200)
I0218 21:49:21.640105  9736 net.cpp:165] Memory required for data: 120431400
I0218 21:49:21.640107  9736 layer_factory.hpp:77] Creating layer Convolution10
I0218 21:49:21.640115  9736 net.cpp:100] Creating Layer Convolution10
I0218 21:49:21.640120  9736 net.cpp:444] Convolution10 <- Eltwise4_ReLU9_0_split_0
I0218 21:49:21.640125  9736 net.cpp:418] Convolution10 -> Convolution10
I0218 21:49:21.641607  9736 net.cpp:150] Setting up Convolution10
I0218 21:49:21.641618  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.641621  9736 net.cpp:165] Memory required for data: 121685800
I0218 21:49:21.641633  9736 layer_factory.hpp:77] Creating layer BatchNorm10
I0218 21:49:21.641639  9736 net.cpp:100] Creating Layer BatchNorm10
I0218 21:49:21.641644  9736 net.cpp:444] BatchNorm10 <- Convolution10
I0218 21:49:21.641649  9736 net.cpp:405] BatchNorm10 -> Convolution10 (in-place)
I0218 21:49:21.641844  9736 net.cpp:150] Setting up BatchNorm10
I0218 21:49:21.641850  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.641852  9736 net.cpp:165] Memory required for data: 122940200
I0218 21:49:21.641858  9736 layer_factory.hpp:77] Creating layer Scale10
I0218 21:49:21.641865  9736 net.cpp:100] Creating Layer Scale10
I0218 21:49:21.641867  9736 net.cpp:444] Scale10 <- Convolution10
I0218 21:49:21.641871  9736 net.cpp:405] Scale10 -> Convolution10 (in-place)
I0218 21:49:21.641911  9736 layer_factory.hpp:77] Creating layer Scale10
I0218 21:49:21.642025  9736 net.cpp:150] Setting up Scale10
I0218 21:49:21.642032  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.642035  9736 net.cpp:165] Memory required for data: 124194600
I0218 21:49:21.642040  9736 layer_factory.hpp:77] Creating layer Convolution11
I0218 21:49:21.642046  9736 net.cpp:100] Creating Layer Convolution11
I0218 21:49:21.642050  9736 net.cpp:444] Convolution11 <- Eltwise4_ReLU9_0_split_1
I0218 21:49:21.642056  9736 net.cpp:418] Convolution11 -> Convolution11
I0218 21:49:21.643537  9736 net.cpp:150] Setting up Convolution11
I0218 21:49:21.643549  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.643553  9736 net.cpp:165] Memory required for data: 125449000
I0218 21:49:21.643558  9736 layer_factory.hpp:77] Creating layer BatchNorm11
I0218 21:49:21.643565  9736 net.cpp:100] Creating Layer BatchNorm11
I0218 21:49:21.643568  9736 net.cpp:444] BatchNorm11 <- Convolution11
I0218 21:49:21.643574  9736 net.cpp:405] BatchNorm11 -> Convolution11 (in-place)
I0218 21:49:21.643764  9736 net.cpp:150] Setting up BatchNorm11
I0218 21:49:21.643770  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.643772  9736 net.cpp:165] Memory required for data: 126703400
I0218 21:49:21.643779  9736 layer_factory.hpp:77] Creating layer Scale11
I0218 21:49:21.643784  9736 net.cpp:100] Creating Layer Scale11
I0218 21:49:21.643787  9736 net.cpp:444] Scale11 <- Convolution11
I0218 21:49:21.643791  9736 net.cpp:405] Scale11 -> Convolution11 (in-place)
I0218 21:49:21.643831  9736 layer_factory.hpp:77] Creating layer Scale11
I0218 21:49:21.643941  9736 net.cpp:150] Setting up Scale11
I0218 21:49:21.643949  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.643950  9736 net.cpp:165] Memory required for data: 127957800
I0218 21:49:21.643955  9736 layer_factory.hpp:77] Creating layer ReLU10
I0218 21:49:21.643959  9736 net.cpp:100] Creating Layer ReLU10
I0218 21:49:21.643962  9736 net.cpp:444] ReLU10 <- Convolution11
I0218 21:49:21.643967  9736 net.cpp:405] ReLU10 -> Convolution11 (in-place)
I0218 21:49:21.644115  9736 net.cpp:150] Setting up ReLU10
I0218 21:49:21.644124  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.644125  9736 net.cpp:165] Memory required for data: 129212200
I0218 21:49:21.644129  9736 layer_factory.hpp:77] Creating layer Convolution12
I0218 21:49:21.644145  9736 net.cpp:100] Creating Layer Convolution12
I0218 21:49:21.644150  9736 net.cpp:444] Convolution12 <- Convolution11
I0218 21:49:21.644157  9736 net.cpp:418] Convolution12 -> Convolution12
I0218 21:49:21.646023  9736 net.cpp:150] Setting up Convolution12
I0218 21:49:21.646036  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.646039  9736 net.cpp:165] Memory required for data: 130466600
I0218 21:49:21.646044  9736 layer_factory.hpp:77] Creating layer BatchNorm12
I0218 21:49:21.646050  9736 net.cpp:100] Creating Layer BatchNorm12
I0218 21:49:21.646054  9736 net.cpp:444] BatchNorm12 <- Convolution12
I0218 21:49:21.646060  9736 net.cpp:405] BatchNorm12 -> Convolution12 (in-place)
I0218 21:49:21.646266  9736 net.cpp:150] Setting up BatchNorm12
I0218 21:49:21.646275  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.646277  9736 net.cpp:165] Memory required for data: 131721000
I0218 21:49:21.646283  9736 layer_factory.hpp:77] Creating layer Scale12
I0218 21:49:21.646289  9736 net.cpp:100] Creating Layer Scale12
I0218 21:49:21.646292  9736 net.cpp:444] Scale12 <- Convolution12
I0218 21:49:21.646297  9736 net.cpp:405] Scale12 -> Convolution12 (in-place)
I0218 21:49:21.646337  9736 layer_factory.hpp:77] Creating layer Scale12
I0218 21:49:21.646450  9736 net.cpp:150] Setting up Scale12
I0218 21:49:21.646456  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.646459  9736 net.cpp:165] Memory required for data: 132975400
I0218 21:49:21.646464  9736 layer_factory.hpp:77] Creating layer Eltwise5
I0218 21:49:21.646468  9736 net.cpp:100] Creating Layer Eltwise5
I0218 21:49:21.646471  9736 net.cpp:444] Eltwise5 <- Convolution10
I0218 21:49:21.646476  9736 net.cpp:444] Eltwise5 <- Convolution12
I0218 21:49:21.646481  9736 net.cpp:418] Eltwise5 -> Eltwise5
I0218 21:49:21.646504  9736 net.cpp:150] Setting up Eltwise5
I0218 21:49:21.646510  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.646512  9736 net.cpp:165] Memory required for data: 134229800
I0218 21:49:21.646515  9736 layer_factory.hpp:77] Creating layer ReLU11
I0218 21:49:21.646522  9736 net.cpp:100] Creating Layer ReLU11
I0218 21:49:21.646524  9736 net.cpp:444] ReLU11 <- Eltwise5
I0218 21:49:21.646528  9736 net.cpp:405] ReLU11 -> Eltwise5 (in-place)
I0218 21:49:21.647055  9736 net.cpp:150] Setting up ReLU11
I0218 21:49:21.647066  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.647069  9736 net.cpp:165] Memory required for data: 135484200
I0218 21:49:21.647073  9736 layer_factory.hpp:77] Creating layer Eltwise5_ReLU11_0_split
I0218 21:49:21.647078  9736 net.cpp:100] Creating Layer Eltwise5_ReLU11_0_split
I0218 21:49:21.647081  9736 net.cpp:444] Eltwise5_ReLU11_0_split <- Eltwise5
I0218 21:49:21.647087  9736 net.cpp:418] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_0
I0218 21:49:21.647096  9736 net.cpp:418] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_1
I0218 21:49:21.647140  9736 net.cpp:150] Setting up Eltwise5_ReLU11_0_split
I0218 21:49:21.647147  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.647150  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.647153  9736 net.cpp:165] Memory required for data: 137993000
I0218 21:49:21.647156  9736 layer_factory.hpp:77] Creating layer Convolution13
I0218 21:49:21.647164  9736 net.cpp:100] Creating Layer Convolution13
I0218 21:49:21.647168  9736 net.cpp:444] Convolution13 <- Eltwise5_ReLU11_0_split_0
I0218 21:49:21.647173  9736 net.cpp:418] Convolution13 -> Convolution13
I0218 21:49:21.648324  9736 net.cpp:150] Setting up Convolution13
I0218 21:49:21.648337  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.648340  9736 net.cpp:165] Memory required for data: 139247400
I0218 21:49:21.648346  9736 layer_factory.hpp:77] Creating layer BatchNorm13
I0218 21:49:21.648352  9736 net.cpp:100] Creating Layer BatchNorm13
I0218 21:49:21.648355  9736 net.cpp:444] BatchNorm13 <- Convolution13
I0218 21:49:21.648361  9736 net.cpp:405] BatchNorm13 -> Convolution13 (in-place)
I0218 21:49:21.648562  9736 net.cpp:150] Setting up BatchNorm13
I0218 21:49:21.648574  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.648577  9736 net.cpp:165] Memory required for data: 140501800
I0218 21:49:21.648583  9736 layer_factory.hpp:77] Creating layer Scale13
I0218 21:49:21.648588  9736 net.cpp:100] Creating Layer Scale13
I0218 21:49:21.648591  9736 net.cpp:444] Scale13 <- Convolution13
I0218 21:49:21.648597  9736 net.cpp:405] Scale13 -> Convolution13 (in-place)
I0218 21:49:21.648638  9736 layer_factory.hpp:77] Creating layer Scale13
I0218 21:49:21.648751  9736 net.cpp:150] Setting up Scale13
I0218 21:49:21.648757  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.648759  9736 net.cpp:165] Memory required for data: 141756200
I0218 21:49:21.648764  9736 layer_factory.hpp:77] Creating layer ReLU12
I0218 21:49:21.648769  9736 net.cpp:100] Creating Layer ReLU12
I0218 21:49:21.648772  9736 net.cpp:444] ReLU12 <- Convolution13
I0218 21:49:21.648777  9736 net.cpp:405] ReLU12 -> Convolution13 (in-place)
I0218 21:49:21.649319  9736 net.cpp:150] Setting up ReLU12
I0218 21:49:21.649332  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.649335  9736 net.cpp:165] Memory required for data: 143010600
I0218 21:49:21.649338  9736 layer_factory.hpp:77] Creating layer Convolution14
I0218 21:49:21.649350  9736 net.cpp:100] Creating Layer Convolution14
I0218 21:49:21.649355  9736 net.cpp:444] Convolution14 <- Convolution13
I0218 21:49:21.649360  9736 net.cpp:418] Convolution14 -> Convolution14
I0218 21:49:21.650961  9736 net.cpp:150] Setting up Convolution14
I0218 21:49:21.650974  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.650976  9736 net.cpp:165] Memory required for data: 144265000
I0218 21:49:21.650984  9736 layer_factory.hpp:77] Creating layer BatchNorm14
I0218 21:49:21.650990  9736 net.cpp:100] Creating Layer BatchNorm14
I0218 21:49:21.650993  9736 net.cpp:444] BatchNorm14 <- Convolution14
I0218 21:49:21.651000  9736 net.cpp:405] BatchNorm14 -> Convolution14 (in-place)
I0218 21:49:21.651194  9736 net.cpp:150] Setting up BatchNorm14
I0218 21:49:21.651201  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.651202  9736 net.cpp:165] Memory required for data: 145519400
I0218 21:49:21.651208  9736 layer_factory.hpp:77] Creating layer Scale14
I0218 21:49:21.651213  9736 net.cpp:100] Creating Layer Scale14
I0218 21:49:21.651216  9736 net.cpp:444] Scale14 <- Convolution14
I0218 21:49:21.651221  9736 net.cpp:405] Scale14 -> Convolution14 (in-place)
I0218 21:49:21.651260  9736 layer_factory.hpp:77] Creating layer Scale14
I0218 21:49:21.651373  9736 net.cpp:150] Setting up Scale14
I0218 21:49:21.651379  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.651381  9736 net.cpp:165] Memory required for data: 146773800
I0218 21:49:21.651386  9736 layer_factory.hpp:77] Creating layer Eltwise6
I0218 21:49:21.651391  9736 net.cpp:100] Creating Layer Eltwise6
I0218 21:49:21.651394  9736 net.cpp:444] Eltwise6 <- Eltwise5_ReLU11_0_split_1
I0218 21:49:21.651397  9736 net.cpp:444] Eltwise6 <- Convolution14
I0218 21:49:21.651405  9736 net.cpp:418] Eltwise6 -> Eltwise6
I0218 21:49:21.651432  9736 net.cpp:150] Setting up Eltwise6
I0218 21:49:21.651437  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.651440  9736 net.cpp:165] Memory required for data: 148028200
I0218 21:49:21.651443  9736 layer_factory.hpp:77] Creating layer ReLU13
I0218 21:49:21.651448  9736 net.cpp:100] Creating Layer ReLU13
I0218 21:49:21.651450  9736 net.cpp:444] ReLU13 <- Eltwise6
I0218 21:49:21.651453  9736 net.cpp:405] ReLU13 -> Eltwise6 (in-place)
I0218 21:49:21.651614  9736 net.cpp:150] Setting up ReLU13
I0218 21:49:21.651623  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.651625  9736 net.cpp:165] Memory required for data: 149282600
I0218 21:49:21.651628  9736 layer_factory.hpp:77] Creating layer Eltwise6_ReLU13_0_split
I0218 21:49:21.651633  9736 net.cpp:100] Creating Layer Eltwise6_ReLU13_0_split
I0218 21:49:21.651636  9736 net.cpp:444] Eltwise6_ReLU13_0_split <- Eltwise6
I0218 21:49:21.651652  9736 net.cpp:418] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_0
I0218 21:49:21.651659  9736 net.cpp:418] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_1
I0218 21:49:21.651700  9736 net.cpp:150] Setting up Eltwise6_ReLU13_0_split
I0218 21:49:21.651706  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.651710  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.651712  9736 net.cpp:165] Memory required for data: 151791400
I0218 21:49:21.651715  9736 layer_factory.hpp:77] Creating layer Convolution15
I0218 21:49:21.651723  9736 net.cpp:100] Creating Layer Convolution15
I0218 21:49:21.651727  9736 net.cpp:444] Convolution15 <- Eltwise6_ReLU13_0_split_0
I0218 21:49:21.651734  9736 net.cpp:418] Convolution15 -> Convolution15
I0218 21:49:21.653235  9736 net.cpp:150] Setting up Convolution15
I0218 21:49:21.653247  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.653249  9736 net.cpp:165] Memory required for data: 153045800
I0218 21:49:21.653255  9736 layer_factory.hpp:77] Creating layer BatchNorm15
I0218 21:49:21.653262  9736 net.cpp:100] Creating Layer BatchNorm15
I0218 21:49:21.653265  9736 net.cpp:444] BatchNorm15 <- Convolution15
I0218 21:49:21.653270  9736 net.cpp:405] BatchNorm15 -> Convolution15 (in-place)
I0218 21:49:21.653462  9736 net.cpp:150] Setting up BatchNorm15
I0218 21:49:21.653468  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.653471  9736 net.cpp:165] Memory required for data: 154300200
I0218 21:49:21.653477  9736 layer_factory.hpp:77] Creating layer Scale15
I0218 21:49:21.653481  9736 net.cpp:100] Creating Layer Scale15
I0218 21:49:21.653486  9736 net.cpp:444] Scale15 <- Convolution15
I0218 21:49:21.653488  9736 net.cpp:405] Scale15 -> Convolution15 (in-place)
I0218 21:49:21.653528  9736 layer_factory.hpp:77] Creating layer Scale15
I0218 21:49:21.653640  9736 net.cpp:150] Setting up Scale15
I0218 21:49:21.653646  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.653648  9736 net.cpp:165] Memory required for data: 155554600
I0218 21:49:21.653653  9736 layer_factory.hpp:77] Creating layer ReLU14
I0218 21:49:21.653657  9736 net.cpp:100] Creating Layer ReLU14
I0218 21:49:21.653661  9736 net.cpp:444] ReLU14 <- Convolution15
I0218 21:49:21.653666  9736 net.cpp:405] ReLU14 -> Convolution15 (in-place)
I0218 21:49:21.654191  9736 net.cpp:150] Setting up ReLU14
I0218 21:49:21.654202  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.654206  9736 net.cpp:165] Memory required for data: 156809000
I0218 21:49:21.654209  9736 layer_factory.hpp:77] Creating layer Convolution16
I0218 21:49:21.654217  9736 net.cpp:100] Creating Layer Convolution16
I0218 21:49:21.654220  9736 net.cpp:444] Convolution16 <- Convolution15
I0218 21:49:21.654227  9736 net.cpp:418] Convolution16 -> Convolution16
I0218 21:49:21.655714  9736 net.cpp:150] Setting up Convolution16
I0218 21:49:21.655726  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.655730  9736 net.cpp:165] Memory required for data: 158063400
I0218 21:49:21.655735  9736 layer_factory.hpp:77] Creating layer BatchNorm16
I0218 21:49:21.655742  9736 net.cpp:100] Creating Layer BatchNorm16
I0218 21:49:21.655745  9736 net.cpp:444] BatchNorm16 <- Convolution16
I0218 21:49:21.655750  9736 net.cpp:405] BatchNorm16 -> Convolution16 (in-place)
I0218 21:49:21.655944  9736 net.cpp:150] Setting up BatchNorm16
I0218 21:49:21.655951  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.655953  9736 net.cpp:165] Memory required for data: 159317800
I0218 21:49:21.655959  9736 layer_factory.hpp:77] Creating layer Scale16
I0218 21:49:21.655966  9736 net.cpp:100] Creating Layer Scale16
I0218 21:49:21.655968  9736 net.cpp:444] Scale16 <- Convolution16
I0218 21:49:21.655972  9736 net.cpp:405] Scale16 -> Convolution16 (in-place)
I0218 21:49:21.656013  9736 layer_factory.hpp:77] Creating layer Scale16
I0218 21:49:21.656123  9736 net.cpp:150] Setting up Scale16
I0218 21:49:21.656129  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.656136  9736 net.cpp:165] Memory required for data: 160572200
I0218 21:49:21.656145  9736 layer_factory.hpp:77] Creating layer Eltwise7
I0218 21:49:21.656152  9736 net.cpp:100] Creating Layer Eltwise7
I0218 21:49:21.656155  9736 net.cpp:444] Eltwise7 <- Eltwise6_ReLU13_0_split_1
I0218 21:49:21.656159  9736 net.cpp:444] Eltwise7 <- Convolution16
I0218 21:49:21.656163  9736 net.cpp:418] Eltwise7 -> Eltwise7
I0218 21:49:21.656190  9736 net.cpp:150] Setting up Eltwise7
I0218 21:49:21.656195  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.656198  9736 net.cpp:165] Memory required for data: 161826600
I0218 21:49:21.656200  9736 layer_factory.hpp:77] Creating layer ReLU15
I0218 21:49:21.656204  9736 net.cpp:100] Creating Layer ReLU15
I0218 21:49:21.656208  9736 net.cpp:444] ReLU15 <- Eltwise7
I0218 21:49:21.656213  9736 net.cpp:405] ReLU15 -> Eltwise7 (in-place)
I0218 21:49:21.656726  9736 net.cpp:150] Setting up ReLU15
I0218 21:49:21.656736  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.656739  9736 net.cpp:165] Memory required for data: 163081000
I0218 21:49:21.656742  9736 layer_factory.hpp:77] Creating layer Eltwise7_ReLU15_0_split
I0218 21:49:21.656749  9736 net.cpp:100] Creating Layer Eltwise7_ReLU15_0_split
I0218 21:49:21.656754  9736 net.cpp:444] Eltwise7_ReLU15_0_split <- Eltwise7
I0218 21:49:21.656757  9736 net.cpp:418] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_0
I0218 21:49:21.656764  9736 net.cpp:418] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_1
I0218 21:49:21.656807  9736 net.cpp:150] Setting up Eltwise7_ReLU15_0_split
I0218 21:49:21.656812  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.656816  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.656818  9736 net.cpp:165] Memory required for data: 165589800
I0218 21:49:21.656821  9736 layer_factory.hpp:77] Creating layer Convolution17
I0218 21:49:21.656829  9736 net.cpp:100] Creating Layer Convolution17
I0218 21:49:21.656832  9736 net.cpp:444] Convolution17 <- Eltwise7_ReLU15_0_split_0
I0218 21:49:21.656838  9736 net.cpp:418] Convolution17 -> Convolution17
I0218 21:49:21.658361  9736 net.cpp:150] Setting up Convolution17
I0218 21:49:21.658373  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.658376  9736 net.cpp:165] Memory required for data: 166844200
I0218 21:49:21.658382  9736 layer_factory.hpp:77] Creating layer BatchNorm17
I0218 21:49:21.658388  9736 net.cpp:100] Creating Layer BatchNorm17
I0218 21:49:21.658392  9736 net.cpp:444] BatchNorm17 <- Convolution17
I0218 21:49:21.658396  9736 net.cpp:405] BatchNorm17 -> Convolution17 (in-place)
I0218 21:49:21.658593  9736 net.cpp:150] Setting up BatchNorm17
I0218 21:49:21.658601  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.658603  9736 net.cpp:165] Memory required for data: 168098600
I0218 21:49:21.658609  9736 layer_factory.hpp:77] Creating layer Scale17
I0218 21:49:21.658613  9736 net.cpp:100] Creating Layer Scale17
I0218 21:49:21.658617  9736 net.cpp:444] Scale17 <- Convolution17
I0218 21:49:21.658620  9736 net.cpp:405] Scale17 -> Convolution17 (in-place)
I0218 21:49:21.658663  9736 layer_factory.hpp:77] Creating layer Scale17
I0218 21:49:21.658776  9736 net.cpp:150] Setting up Scale17
I0218 21:49:21.658782  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.658785  9736 net.cpp:165] Memory required for data: 169353000
I0218 21:49:21.658790  9736 layer_factory.hpp:77] Creating layer ReLU16
I0218 21:49:21.658794  9736 net.cpp:100] Creating Layer ReLU16
I0218 21:49:21.658797  9736 net.cpp:444] ReLU16 <- Convolution17
I0218 21:49:21.658800  9736 net.cpp:405] ReLU16 -> Convolution17 (in-place)
I0218 21:49:21.658948  9736 net.cpp:150] Setting up ReLU16
I0218 21:49:21.658955  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.658957  9736 net.cpp:165] Memory required for data: 170607400
I0218 21:49:21.658962  9736 layer_factory.hpp:77] Creating layer Convolution18
I0218 21:49:21.658969  9736 net.cpp:100] Creating Layer Convolution18
I0218 21:49:21.658977  9736 net.cpp:444] Convolution18 <- Convolution17
I0218 21:49:21.658987  9736 net.cpp:418] Convolution18 -> Convolution18
I0218 21:49:21.660595  9736 net.cpp:150] Setting up Convolution18
I0218 21:49:21.660609  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.660611  9736 net.cpp:165] Memory required for data: 171861800
I0218 21:49:21.660616  9736 layer_factory.hpp:77] Creating layer BatchNorm18
I0218 21:49:21.660624  9736 net.cpp:100] Creating Layer BatchNorm18
I0218 21:49:21.660627  9736 net.cpp:444] BatchNorm18 <- Convolution18
I0218 21:49:21.660632  9736 net.cpp:405] BatchNorm18 -> Convolution18 (in-place)
I0218 21:49:21.660833  9736 net.cpp:150] Setting up BatchNorm18
I0218 21:49:21.660840  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.660843  9736 net.cpp:165] Memory required for data: 173116200
I0218 21:49:21.660848  9736 layer_factory.hpp:77] Creating layer Scale18
I0218 21:49:21.660854  9736 net.cpp:100] Creating Layer Scale18
I0218 21:49:21.660857  9736 net.cpp:444] Scale18 <- Convolution18
I0218 21:49:21.660861  9736 net.cpp:405] Scale18 -> Convolution18 (in-place)
I0218 21:49:21.661223  9736 layer_factory.hpp:77] Creating layer Scale18
I0218 21:49:21.661315  9736 net.cpp:150] Setting up Scale18
I0218 21:49:21.661322  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.661325  9736 net.cpp:165] Memory required for data: 174370600
I0218 21:49:21.661330  9736 layer_factory.hpp:77] Creating layer Eltwise8
I0218 21:49:21.661334  9736 net.cpp:100] Creating Layer Eltwise8
I0218 21:49:21.661339  9736 net.cpp:444] Eltwise8 <- Eltwise7_ReLU15_0_split_1
I0218 21:49:21.661342  9736 net.cpp:444] Eltwise8 <- Convolution18
I0218 21:49:21.661350  9736 net.cpp:418] Eltwise8 -> Eltwise8
I0218 21:49:21.661367  9736 net.cpp:150] Setting up Eltwise8
I0218 21:49:21.661372  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.661375  9736 net.cpp:165] Memory required for data: 175625000
I0218 21:49:21.661377  9736 layer_factory.hpp:77] Creating layer ReLU17
I0218 21:49:21.661382  9736 net.cpp:100] Creating Layer ReLU17
I0218 21:49:21.661386  9736 net.cpp:444] ReLU17 <- Eltwise8
I0218 21:49:21.661388  9736 net.cpp:405] ReLU17 -> Eltwise8 (in-place)
I0218 21:49:21.661906  9736 net.cpp:150] Setting up ReLU17
I0218 21:49:21.661916  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.661919  9736 net.cpp:165] Memory required for data: 176879400
I0218 21:49:21.661922  9736 layer_factory.hpp:77] Creating layer Eltwise8_ReLU17_0_split
I0218 21:49:21.661928  9736 net.cpp:100] Creating Layer Eltwise8_ReLU17_0_split
I0218 21:49:21.661931  9736 net.cpp:444] Eltwise8_ReLU17_0_split <- Eltwise8
I0218 21:49:21.661937  9736 net.cpp:418] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_0
I0218 21:49:21.661943  9736 net.cpp:418] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_1
I0218 21:49:21.661947  9736 net.cpp:418] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_2
I0218 21:49:21.661985  9736 net.cpp:150] Setting up Eltwise8_ReLU17_0_split
I0218 21:49:21.661991  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.661994  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.661998  9736 net.cpp:157] Top shape: 50 32 14 14 (313600)
I0218 21:49:21.661999  9736 net.cpp:165] Memory required for data: 180642600
I0218 21:49:21.662003  9736 layer_factory.hpp:77] Creating layer Convolution19
I0218 21:49:21.662011  9736 net.cpp:100] Creating Layer Convolution19
I0218 21:49:21.662014  9736 net.cpp:444] Convolution19 <- Eltwise8_ReLU17_0_split_0
I0218 21:49:21.662019  9736 net.cpp:418] Convolution19 -> Convolution19
I0218 21:49:21.663066  9736 net.cpp:150] Setting up Convolution19
I0218 21:49:21.663079  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.663081  9736 net.cpp:165] Memory required for data: 181269800
I0218 21:49:21.663086  9736 layer_factory.hpp:77] Creating layer BatchNorm19
I0218 21:49:21.663094  9736 net.cpp:100] Creating Layer BatchNorm19
I0218 21:49:21.663098  9736 net.cpp:444] BatchNorm19 <- Convolution19
I0218 21:49:21.663106  9736 net.cpp:405] BatchNorm19 -> Convolution19 (in-place)
I0218 21:49:21.663249  9736 net.cpp:150] Setting up BatchNorm19
I0218 21:49:21.663255  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.663259  9736 net.cpp:165] Memory required for data: 181897000
I0218 21:49:21.663270  9736 layer_factory.hpp:77] Creating layer Scale19
I0218 21:49:21.663276  9736 net.cpp:100] Creating Layer Scale19
I0218 21:49:21.663280  9736 net.cpp:444] Scale19 <- Convolution19
I0218 21:49:21.663285  9736 net.cpp:405] Scale19 -> Convolution19 (in-place)
I0218 21:49:21.663314  9736 layer_factory.hpp:77] Creating layer Scale19
I0218 21:49:21.663390  9736 net.cpp:150] Setting up Scale19
I0218 21:49:21.663396  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.663398  9736 net.cpp:165] Memory required for data: 182524200
I0218 21:49:21.663403  9736 layer_factory.hpp:77] Creating layer Convolution20
I0218 21:49:21.663411  9736 net.cpp:100] Creating Layer Convolution20
I0218 21:49:21.663415  9736 net.cpp:444] Convolution20 <- Eltwise8_ReLU17_0_split_1
I0218 21:49:21.663420  9736 net.cpp:418] Convolution20 -> Convolution20
I0218 21:49:21.664935  9736 net.cpp:150] Setting up Convolution20
I0218 21:49:21.664947  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.664950  9736 net.cpp:165] Memory required for data: 183151400
I0218 21:49:21.664957  9736 layer_factory.hpp:77] Creating layer BatchNorm20
I0218 21:49:21.664963  9736 net.cpp:100] Creating Layer BatchNorm20
I0218 21:49:21.664966  9736 net.cpp:444] BatchNorm20 <- Convolution20
I0218 21:49:21.664970  9736 net.cpp:405] BatchNorm20 -> Convolution20 (in-place)
I0218 21:49:21.665128  9736 net.cpp:150] Setting up BatchNorm20
I0218 21:49:21.665138  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.665139  9736 net.cpp:165] Memory required for data: 183778600
I0218 21:49:21.665146  9736 layer_factory.hpp:77] Creating layer Scale20
I0218 21:49:21.665151  9736 net.cpp:100] Creating Layer Scale20
I0218 21:49:21.665154  9736 net.cpp:444] Scale20 <- Convolution20
I0218 21:49:21.665158  9736 net.cpp:405] Scale20 -> Convolution20 (in-place)
I0218 21:49:21.665189  9736 layer_factory.hpp:77] Creating layer Scale20
I0218 21:49:21.665269  9736 net.cpp:150] Setting up Scale20
I0218 21:49:21.665277  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.665278  9736 net.cpp:165] Memory required for data: 184405800
I0218 21:49:21.665283  9736 layer_factory.hpp:77] Creating layer ReLU18
I0218 21:49:21.665287  9736 net.cpp:100] Creating Layer ReLU18
I0218 21:49:21.665290  9736 net.cpp:444] ReLU18 <- Convolution20
I0218 21:49:21.665294  9736 net.cpp:405] ReLU18 -> Convolution20 (in-place)
I0218 21:49:21.666152  9736 net.cpp:150] Setting up ReLU18
I0218 21:49:21.666164  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.666167  9736 net.cpp:165] Memory required for data: 185033000
I0218 21:49:21.666170  9736 layer_factory.hpp:77] Creating layer Convolution21
I0218 21:49:21.666179  9736 net.cpp:100] Creating Layer Convolution21
I0218 21:49:21.666182  9736 net.cpp:444] Convolution21 <- Convolution20
I0218 21:49:21.666188  9736 net.cpp:418] Convolution21 -> Convolution21
I0218 21:49:21.668205  9736 net.cpp:150] Setting up Convolution21
I0218 21:49:21.668218  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.668222  9736 net.cpp:165] Memory required for data: 185660200
I0218 21:49:21.668228  9736 layer_factory.hpp:77] Creating layer BatchNorm21
I0218 21:49:21.668233  9736 net.cpp:100] Creating Layer BatchNorm21
I0218 21:49:21.668237  9736 net.cpp:444] BatchNorm21 <- Convolution21
I0218 21:49:21.668242  9736 net.cpp:405] BatchNorm21 -> Convolution21 (in-place)
I0218 21:49:21.668385  9736 net.cpp:150] Setting up BatchNorm21
I0218 21:49:21.668391  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.668395  9736 net.cpp:165] Memory required for data: 186287400
I0218 21:49:21.668399  9736 layer_factory.hpp:77] Creating layer Scale21
I0218 21:49:21.668404  9736 net.cpp:100] Creating Layer Scale21
I0218 21:49:21.668411  9736 net.cpp:444] Scale21 <- Convolution21
I0218 21:49:21.668422  9736 net.cpp:405] Scale21 -> Convolution21 (in-place)
I0218 21:49:21.668452  9736 layer_factory.hpp:77] Creating layer Scale21
I0218 21:49:21.668532  9736 net.cpp:150] Setting up Scale21
I0218 21:49:21.668537  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.668540  9736 net.cpp:165] Memory required for data: 186914600
I0218 21:49:21.668545  9736 layer_factory.hpp:77] Creating layer Eltwise9
I0218 21:49:21.668550  9736 net.cpp:100] Creating Layer Eltwise9
I0218 21:49:21.668552  9736 net.cpp:444] Eltwise9 <- Convolution19
I0218 21:49:21.668556  9736 net.cpp:444] Eltwise9 <- Convolution21
I0218 21:49:21.668561  9736 net.cpp:418] Eltwise9 -> Eltwise9
I0218 21:49:21.668579  9736 net.cpp:150] Setting up Eltwise9
I0218 21:49:21.668584  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.668586  9736 net.cpp:165] Memory required for data: 187541800
I0218 21:49:21.668589  9736 layer_factory.hpp:77] Creating layer ReLU19
I0218 21:49:21.668593  9736 net.cpp:100] Creating Layer ReLU19
I0218 21:49:21.668596  9736 net.cpp:444] ReLU19 <- Eltwise9
I0218 21:49:21.668601  9736 net.cpp:405] ReLU19 -> Eltwise9 (in-place)
I0218 21:49:21.668757  9736 net.cpp:150] Setting up ReLU19
I0218 21:49:21.668766  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.668768  9736 net.cpp:165] Memory required for data: 188169000
I0218 21:49:21.668771  9736 layer_factory.hpp:77] Creating layer Eltwise9_ReLU19_0_split
I0218 21:49:21.668776  9736 net.cpp:100] Creating Layer Eltwise9_ReLU19_0_split
I0218 21:49:21.668779  9736 net.cpp:444] Eltwise9_ReLU19_0_split <- Eltwise9
I0218 21:49:21.668784  9736 net.cpp:418] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_0
I0218 21:49:21.668790  9736 net.cpp:418] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_1
I0218 21:49:21.668828  9736 net.cpp:150] Setting up Eltwise9_ReLU19_0_split
I0218 21:49:21.668833  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.668835  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.668838  9736 net.cpp:165] Memory required for data: 189423400
I0218 21:49:21.668840  9736 layer_factory.hpp:77] Creating layer Convolution22
I0218 21:49:21.668848  9736 net.cpp:100] Creating Layer Convolution22
I0218 21:49:21.668850  9736 net.cpp:444] Convolution22 <- Eltwise9_ReLU19_0_split_0
I0218 21:49:21.668857  9736 net.cpp:418] Convolution22 -> Convolution22
I0218 21:49:21.670852  9736 net.cpp:150] Setting up Convolution22
I0218 21:49:21.670866  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.670868  9736 net.cpp:165] Memory required for data: 190050600
I0218 21:49:21.670874  9736 layer_factory.hpp:77] Creating layer BatchNorm22
I0218 21:49:21.670881  9736 net.cpp:100] Creating Layer BatchNorm22
I0218 21:49:21.670884  9736 net.cpp:444] BatchNorm22 <- Convolution22
I0218 21:49:21.670888  9736 net.cpp:405] BatchNorm22 -> Convolution22 (in-place)
I0218 21:49:21.671037  9736 net.cpp:150] Setting up BatchNorm22
I0218 21:49:21.671043  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.671046  9736 net.cpp:165] Memory required for data: 190677800
I0218 21:49:21.671051  9736 layer_factory.hpp:77] Creating layer Scale22
I0218 21:49:21.671056  9736 net.cpp:100] Creating Layer Scale22
I0218 21:49:21.671059  9736 net.cpp:444] Scale22 <- Convolution22
I0218 21:49:21.671062  9736 net.cpp:405] Scale22 -> Convolution22 (in-place)
I0218 21:49:21.671092  9736 layer_factory.hpp:77] Creating layer Scale22
I0218 21:49:21.671173  9736 net.cpp:150] Setting up Scale22
I0218 21:49:21.671180  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.671182  9736 net.cpp:165] Memory required for data: 191305000
I0218 21:49:21.671186  9736 layer_factory.hpp:77] Creating layer ReLU20
I0218 21:49:21.671192  9736 net.cpp:100] Creating Layer ReLU20
I0218 21:49:21.671195  9736 net.cpp:444] ReLU20 <- Convolution22
I0218 21:49:21.671198  9736 net.cpp:405] ReLU20 -> Convolution22 (in-place)
I0218 21:49:21.671355  9736 net.cpp:150] Setting up ReLU20
I0218 21:49:21.671370  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.671376  9736 net.cpp:165] Memory required for data: 191932200
I0218 21:49:21.671380  9736 layer_factory.hpp:77] Creating layer Convolution23
I0218 21:49:21.671387  9736 net.cpp:100] Creating Layer Convolution23
I0218 21:49:21.671391  9736 net.cpp:444] Convolution23 <- Convolution22
I0218 21:49:21.671396  9736 net.cpp:418] Convolution23 -> Convolution23
I0218 21:49:21.673449  9736 net.cpp:150] Setting up Convolution23
I0218 21:49:21.673462  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.673466  9736 net.cpp:165] Memory required for data: 192559400
I0218 21:49:21.673471  9736 layer_factory.hpp:77] Creating layer BatchNorm23
I0218 21:49:21.673478  9736 net.cpp:100] Creating Layer BatchNorm23
I0218 21:49:21.673481  9736 net.cpp:444] BatchNorm23 <- Convolution23
I0218 21:49:21.673486  9736 net.cpp:405] BatchNorm23 -> Convolution23 (in-place)
I0218 21:49:21.673630  9736 net.cpp:150] Setting up BatchNorm23
I0218 21:49:21.673636  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.673638  9736 net.cpp:165] Memory required for data: 193186600
I0218 21:49:21.673645  9736 layer_factory.hpp:77] Creating layer Scale23
I0218 21:49:21.673650  9736 net.cpp:100] Creating Layer Scale23
I0218 21:49:21.673652  9736 net.cpp:444] Scale23 <- Convolution23
I0218 21:49:21.673655  9736 net.cpp:405] Scale23 -> Convolution23 (in-place)
I0218 21:49:21.673717  9736 layer_factory.hpp:77] Creating layer Scale23
I0218 21:49:21.673799  9736 net.cpp:150] Setting up Scale23
I0218 21:49:21.673804  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.673807  9736 net.cpp:165] Memory required for data: 193813800
I0218 21:49:21.673811  9736 layer_factory.hpp:77] Creating layer Eltwise10
I0218 21:49:21.673816  9736 net.cpp:100] Creating Layer Eltwise10
I0218 21:49:21.673820  9736 net.cpp:444] Eltwise10 <- Eltwise9_ReLU19_0_split_1
I0218 21:49:21.673822  9736 net.cpp:444] Eltwise10 <- Convolution23
I0218 21:49:21.673827  9736 net.cpp:418] Eltwise10 -> Eltwise10
I0218 21:49:21.673846  9736 net.cpp:150] Setting up Eltwise10
I0218 21:49:21.673851  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.673852  9736 net.cpp:165] Memory required for data: 194441000
I0218 21:49:21.673856  9736 layer_factory.hpp:77] Creating layer ReLU21
I0218 21:49:21.673861  9736 net.cpp:100] Creating Layer ReLU21
I0218 21:49:21.673862  9736 net.cpp:444] ReLU21 <- Eltwise10
I0218 21:49:21.673866  9736 net.cpp:405] ReLU21 -> Eltwise10 (in-place)
I0218 21:49:21.674408  9736 net.cpp:150] Setting up ReLU21
I0218 21:49:21.674418  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.674422  9736 net.cpp:165] Memory required for data: 195068200
I0218 21:49:21.674424  9736 layer_factory.hpp:77] Creating layer Eltwise10_ReLU21_0_split
I0218 21:49:21.674430  9736 net.cpp:100] Creating Layer Eltwise10_ReLU21_0_split
I0218 21:49:21.674433  9736 net.cpp:444] Eltwise10_ReLU21_0_split <- Eltwise10
I0218 21:49:21.674438  9736 net.cpp:418] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_0
I0218 21:49:21.674445  9736 net.cpp:418] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_1
I0218 21:49:21.674491  9736 net.cpp:150] Setting up Eltwise10_ReLU21_0_split
I0218 21:49:21.674496  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.674499  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.674501  9736 net.cpp:165] Memory required for data: 196322600
I0218 21:49:21.674504  9736 layer_factory.hpp:77] Creating layer Convolution24
I0218 21:49:21.674511  9736 net.cpp:100] Creating Layer Convolution24
I0218 21:49:21.674515  9736 net.cpp:444] Convolution24 <- Eltwise10_ReLU21_0_split_0
I0218 21:49:21.674520  9736 net.cpp:418] Convolution24 -> Convolution24
I0218 21:49:21.676461  9736 net.cpp:150] Setting up Convolution24
I0218 21:49:21.676473  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.676476  9736 net.cpp:165] Memory required for data: 196949800
I0218 21:49:21.676482  9736 layer_factory.hpp:77] Creating layer BatchNorm24
I0218 21:49:21.676492  9736 net.cpp:100] Creating Layer BatchNorm24
I0218 21:49:21.676501  9736 net.cpp:444] BatchNorm24 <- Convolution24
I0218 21:49:21.676506  9736 net.cpp:405] BatchNorm24 -> Convolution24 (in-place)
I0218 21:49:21.676664  9736 net.cpp:150] Setting up BatchNorm24
I0218 21:49:21.676671  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.676673  9736 net.cpp:165] Memory required for data: 197577000
I0218 21:49:21.676678  9736 layer_factory.hpp:77] Creating layer Scale24
I0218 21:49:21.676683  9736 net.cpp:100] Creating Layer Scale24
I0218 21:49:21.676687  9736 net.cpp:444] Scale24 <- Convolution24
I0218 21:49:21.676689  9736 net.cpp:405] Scale24 -> Convolution24 (in-place)
I0218 21:49:21.676719  9736 layer_factory.hpp:77] Creating layer Scale24
I0218 21:49:21.676800  9736 net.cpp:150] Setting up Scale24
I0218 21:49:21.676806  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.676808  9736 net.cpp:165] Memory required for data: 198204200
I0218 21:49:21.676813  9736 layer_factory.hpp:77] Creating layer ReLU22
I0218 21:49:21.676817  9736 net.cpp:100] Creating Layer ReLU22
I0218 21:49:21.676820  9736 net.cpp:444] ReLU22 <- Convolution24
I0218 21:49:21.676823  9736 net.cpp:405] ReLU22 -> Convolution24 (in-place)
I0218 21:49:21.676976  9736 net.cpp:150] Setting up ReLU22
I0218 21:49:21.676983  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.676986  9736 net.cpp:165] Memory required for data: 198831400
I0218 21:49:21.676990  9736 layer_factory.hpp:77] Creating layer Convolution25
I0218 21:49:21.676996  9736 net.cpp:100] Creating Layer Convolution25
I0218 21:49:21.677000  9736 net.cpp:444] Convolution25 <- Convolution24
I0218 21:49:21.677006  9736 net.cpp:418] Convolution25 -> Convolution25
I0218 21:49:21.679023  9736 net.cpp:150] Setting up Convolution25
I0218 21:49:21.679034  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.679038  9736 net.cpp:165] Memory required for data: 199458600
I0218 21:49:21.679044  9736 layer_factory.hpp:77] Creating layer BatchNorm25
I0218 21:49:21.679049  9736 net.cpp:100] Creating Layer BatchNorm25
I0218 21:49:21.679052  9736 net.cpp:444] BatchNorm25 <- Convolution25
I0218 21:49:21.679057  9736 net.cpp:405] BatchNorm25 -> Convolution25 (in-place)
I0218 21:49:21.679201  9736 net.cpp:150] Setting up BatchNorm25
I0218 21:49:21.679208  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.679209  9736 net.cpp:165] Memory required for data: 200085800
I0218 21:49:21.679215  9736 layer_factory.hpp:77] Creating layer Scale25
I0218 21:49:21.679220  9736 net.cpp:100] Creating Layer Scale25
I0218 21:49:21.679224  9736 net.cpp:444] Scale25 <- Convolution25
I0218 21:49:21.679227  9736 net.cpp:405] Scale25 -> Convolution25 (in-place)
I0218 21:49:21.679257  9736 layer_factory.hpp:77] Creating layer Scale25
I0218 21:49:21.679338  9736 net.cpp:150] Setting up Scale25
I0218 21:49:21.679344  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.679347  9736 net.cpp:165] Memory required for data: 200713000
I0218 21:49:21.679350  9736 layer_factory.hpp:77] Creating layer Eltwise11
I0218 21:49:21.679356  9736 net.cpp:100] Creating Layer Eltwise11
I0218 21:49:21.679359  9736 net.cpp:444] Eltwise11 <- Eltwise10_ReLU21_0_split_1
I0218 21:49:21.679363  9736 net.cpp:444] Eltwise11 <- Convolution25
I0218 21:49:21.679366  9736 net.cpp:418] Eltwise11 -> Eltwise11
I0218 21:49:21.679386  9736 net.cpp:150] Setting up Eltwise11
I0218 21:49:21.679390  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.679392  9736 net.cpp:165] Memory required for data: 201340200
I0218 21:49:21.679395  9736 layer_factory.hpp:77] Creating layer ReLU23
I0218 21:49:21.679399  9736 net.cpp:100] Creating Layer ReLU23
I0218 21:49:21.679402  9736 net.cpp:444] ReLU23 <- Eltwise11
I0218 21:49:21.679406  9736 net.cpp:405] ReLU23 -> Eltwise11 (in-place)
I0218 21:49:21.679571  9736 net.cpp:150] Setting up ReLU23
I0218 21:49:21.679580  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.679582  9736 net.cpp:165] Memory required for data: 201967400
I0218 21:49:21.679585  9736 layer_factory.hpp:77] Creating layer Eltwise11_ReLU23_0_split
I0218 21:49:21.679600  9736 net.cpp:100] Creating Layer Eltwise11_ReLU23_0_split
I0218 21:49:21.679605  9736 net.cpp:444] Eltwise11_ReLU23_0_split <- Eltwise11
I0218 21:49:21.679610  9736 net.cpp:418] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_0
I0218 21:49:21.679636  9736 net.cpp:418] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_1
I0218 21:49:21.679667  9736 net.cpp:150] Setting up Eltwise11_ReLU23_0_split
I0218 21:49:21.679673  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.679677  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.679679  9736 net.cpp:165] Memory required for data: 203221800
I0218 21:49:21.679682  9736 layer_factory.hpp:77] Creating layer Convolution26
I0218 21:49:21.679690  9736 net.cpp:100] Creating Layer Convolution26
I0218 21:49:21.679693  9736 net.cpp:444] Convolution26 <- Eltwise11_ReLU23_0_split_0
I0218 21:49:21.679698  9736 net.cpp:418] Convolution26 -> Convolution26
I0218 21:49:21.682060  9736 net.cpp:150] Setting up Convolution26
I0218 21:49:21.682075  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.682078  9736 net.cpp:165] Memory required for data: 203849000
I0218 21:49:21.682085  9736 layer_factory.hpp:77] Creating layer BatchNorm26
I0218 21:49:21.682090  9736 net.cpp:100] Creating Layer BatchNorm26
I0218 21:49:21.682094  9736 net.cpp:444] BatchNorm26 <- Convolution26
I0218 21:49:21.682099  9736 net.cpp:405] BatchNorm26 -> Convolution26 (in-place)
I0218 21:49:21.682250  9736 net.cpp:150] Setting up BatchNorm26
I0218 21:49:21.682256  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.682260  9736 net.cpp:165] Memory required for data: 204476200
I0218 21:49:21.682265  9736 layer_factory.hpp:77] Creating layer Scale26
I0218 21:49:21.682269  9736 net.cpp:100] Creating Layer Scale26
I0218 21:49:21.682272  9736 net.cpp:444] Scale26 <- Convolution26
I0218 21:49:21.682277  9736 net.cpp:405] Scale26 -> Convolution26 (in-place)
I0218 21:49:21.682307  9736 layer_factory.hpp:77] Creating layer Scale26
I0218 21:49:21.682397  9736 net.cpp:150] Setting up Scale26
I0218 21:49:21.682404  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.682406  9736 net.cpp:165] Memory required for data: 205103400
I0218 21:49:21.682411  9736 layer_factory.hpp:77] Creating layer ReLU24
I0218 21:49:21.682415  9736 net.cpp:100] Creating Layer ReLU24
I0218 21:49:21.682418  9736 net.cpp:444] ReLU24 <- Convolution26
I0218 21:49:21.682423  9736 net.cpp:405] ReLU24 -> Convolution26 (in-place)
I0218 21:49:21.682963  9736 net.cpp:150] Setting up ReLU24
I0218 21:49:21.682973  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.682976  9736 net.cpp:165] Memory required for data: 205730600
I0218 21:49:21.682979  9736 layer_factory.hpp:77] Creating layer Convolution27
I0218 21:49:21.682987  9736 net.cpp:100] Creating Layer Convolution27
I0218 21:49:21.682991  9736 net.cpp:444] Convolution27 <- Convolution26
I0218 21:49:21.682997  9736 net.cpp:418] Convolution27 -> Convolution27
I0218 21:49:21.684983  9736 net.cpp:150] Setting up Convolution27
I0218 21:49:21.684995  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.684998  9736 net.cpp:165] Memory required for data: 206357800
I0218 21:49:21.685004  9736 layer_factory.hpp:77] Creating layer BatchNorm27
I0218 21:49:21.685016  9736 net.cpp:100] Creating Layer BatchNorm27
I0218 21:49:21.685020  9736 net.cpp:444] BatchNorm27 <- Convolution27
I0218 21:49:21.685025  9736 net.cpp:405] BatchNorm27 -> Convolution27 (in-place)
I0218 21:49:21.685174  9736 net.cpp:150] Setting up BatchNorm27
I0218 21:49:21.685181  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.685184  9736 net.cpp:165] Memory required for data: 206985000
I0218 21:49:21.685189  9736 layer_factory.hpp:77] Creating layer Scale27
I0218 21:49:21.685195  9736 net.cpp:100] Creating Layer Scale27
I0218 21:49:21.685199  9736 net.cpp:444] Scale27 <- Convolution27
I0218 21:49:21.685202  9736 net.cpp:405] Scale27 -> Convolution27 (in-place)
I0218 21:49:21.685241  9736 layer_factory.hpp:77] Creating layer Scale27
I0218 21:49:21.685334  9736 net.cpp:150] Setting up Scale27
I0218 21:49:21.685340  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.685343  9736 net.cpp:165] Memory required for data: 207612200
I0218 21:49:21.685348  9736 layer_factory.hpp:77] Creating layer Eltwise12
I0218 21:49:21.685353  9736 net.cpp:100] Creating Layer Eltwise12
I0218 21:49:21.685358  9736 net.cpp:444] Eltwise12 <- Eltwise11_ReLU23_0_split_1
I0218 21:49:21.685361  9736 net.cpp:444] Eltwise12 <- Convolution27
I0218 21:49:21.685365  9736 net.cpp:418] Eltwise12 -> Eltwise12
I0218 21:49:21.685385  9736 net.cpp:150] Setting up Eltwise12
I0218 21:49:21.685389  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.685392  9736 net.cpp:165] Memory required for data: 208239400
I0218 21:49:21.685395  9736 layer_factory.hpp:77] Creating layer Convolution_eltwise4
I0218 21:49:21.685402  9736 net.cpp:100] Creating Layer Convolution_eltwise4
I0218 21:49:21.685406  9736 net.cpp:444] Convolution_eltwise4 <- Eltwise4_ReLU9_0_split_2
I0218 21:49:21.685411  9736 net.cpp:418] Convolution_eltwise4 -> Convolution_eltwise4
I0218 21:49:21.686542  9736 net.cpp:150] Setting up Convolution_eltwise4
I0218 21:49:21.686553  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.686556  9736 net.cpp:165] Memory required for data: 208866600
I0218 21:49:21.686561  9736 layer_factory.hpp:77] Creating layer BatchNorm_Convolution_eltwise4
I0218 21:49:21.686568  9736 net.cpp:100] Creating Layer BatchNorm_Convolution_eltwise4
I0218 21:49:21.686571  9736 net.cpp:444] BatchNorm_Convolution_eltwise4 <- Convolution_eltwise4
I0218 21:49:21.686576  9736 net.cpp:405] BatchNorm_Convolution_eltwise4 -> Convolution_eltwise4 (in-place)
I0218 21:49:21.686723  9736 net.cpp:150] Setting up BatchNorm_Convolution_eltwise4
I0218 21:49:21.686729  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.686731  9736 net.cpp:165] Memory required for data: 209493800
I0218 21:49:21.686738  9736 layer_factory.hpp:77] Creating layer Scale_Convolution_eltwise4
I0218 21:49:21.686743  9736 net.cpp:100] Creating Layer Scale_Convolution_eltwise4
I0218 21:49:21.686745  9736 net.cpp:444] Scale_Convolution_eltwise4 <- Convolution_eltwise4
I0218 21:49:21.686749  9736 net.cpp:405] Scale_Convolution_eltwise4 -> Convolution_eltwise4 (in-place)
I0218 21:49:21.686781  9736 layer_factory.hpp:77] Creating layer Scale_Convolution_eltwise4
I0218 21:49:21.686867  9736 net.cpp:150] Setting up Scale_Convolution_eltwise4
I0218 21:49:21.686873  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.686875  9736 net.cpp:165] Memory required for data: 210121000
I0218 21:49:21.686880  9736 layer_factory.hpp:77] Creating layer Convolution_eltwise8
I0218 21:49:21.686888  9736 net.cpp:100] Creating Layer Convolution_eltwise8
I0218 21:49:21.686892  9736 net.cpp:444] Convolution_eltwise8 <- Eltwise8_ReLU17_0_split_2
I0218 21:49:21.686897  9736 net.cpp:418] Convolution_eltwise8 -> Convolution_eltwise8
I0218 21:49:21.688786  9736 net.cpp:150] Setting up Convolution_eltwise8
I0218 21:49:21.688799  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.688802  9736 net.cpp:165] Memory required for data: 210748200
I0218 21:49:21.688807  9736 layer_factory.hpp:77] Creating layer BatchNorm_Convolution_eltwise8
I0218 21:49:21.688814  9736 net.cpp:100] Creating Layer BatchNorm_Convolution_eltwise8
I0218 21:49:21.688817  9736 net.cpp:444] BatchNorm_Convolution_eltwise8 <- Convolution_eltwise8
I0218 21:49:21.688822  9736 net.cpp:405] BatchNorm_Convolution_eltwise8 -> Convolution_eltwise8 (in-place)
I0218 21:49:21.688969  9736 net.cpp:150] Setting up BatchNorm_Convolution_eltwise8
I0218 21:49:21.688975  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.688977  9736 net.cpp:165] Memory required for data: 211375400
I0218 21:49:21.688982  9736 layer_factory.hpp:77] Creating layer Scale_Convolution_eltwise8
I0218 21:49:21.688987  9736 net.cpp:100] Creating Layer Scale_Convolution_eltwise8
I0218 21:49:21.688990  9736 net.cpp:444] Scale_Convolution_eltwise8 <- Convolution_eltwise8
I0218 21:49:21.689002  9736 net.cpp:405] Scale_Convolution_eltwise8 -> Convolution_eltwise8 (in-place)
I0218 21:49:21.689039  9736 layer_factory.hpp:77] Creating layer Scale_Convolution_eltwise8
I0218 21:49:21.689132  9736 net.cpp:150] Setting up Scale_Convolution_eltwise8
I0218 21:49:21.689139  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.689141  9736 net.cpp:165] Memory required for data: 212002600
I0218 21:49:21.689146  9736 layer_factory.hpp:77] Creating layer fuse1
I0218 21:49:21.689151  9736 net.cpp:100] Creating Layer fuse1
I0218 21:49:21.689153  9736 net.cpp:444] fuse1 <- Convolution_eltwise4
I0218 21:49:21.689157  9736 net.cpp:444] fuse1 <- Convolution_eltwise8
I0218 21:49:21.689162  9736 net.cpp:418] fuse1 -> fuse1
I0218 21:49:21.689180  9736 net.cpp:150] Setting up fuse1
I0218 21:49:21.689185  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.689188  9736 net.cpp:165] Memory required for data: 212629800
I0218 21:49:21.689190  9736 layer_factory.hpp:77] Creating layer fuse2
I0218 21:49:21.689194  9736 net.cpp:100] Creating Layer fuse2
I0218 21:49:21.689198  9736 net.cpp:444] fuse2 <- fuse1
I0218 21:49:21.689200  9736 net.cpp:444] fuse2 <- Eltwise12
I0218 21:49:21.689204  9736 net.cpp:418] fuse2 -> fuse2
I0218 21:49:21.689221  9736 net.cpp:150] Setting up fuse2
I0218 21:49:21.689225  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.689229  9736 net.cpp:165] Memory required for data: 213257000
I0218 21:49:21.689230  9736 layer_factory.hpp:77] Creating layer ReLU25
I0218 21:49:21.689234  9736 net.cpp:100] Creating Layer ReLU25
I0218 21:49:21.689237  9736 net.cpp:444] ReLU25 <- fuse2
I0218 21:49:21.689241  9736 net.cpp:405] ReLU25 -> fuse2 (in-place)
I0218 21:49:21.689770  9736 net.cpp:150] Setting up ReLU25
I0218 21:49:21.689780  9736 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0218 21:49:21.689783  9736 net.cpp:165] Memory required for data: 213884200
I0218 21:49:21.689786  9736 layer_factory.hpp:77] Creating layer Pooling1
I0218 21:49:21.689795  9736 net.cpp:100] Creating Layer Pooling1
I0218 21:49:21.689797  9736 net.cpp:444] Pooling1 <- fuse2
I0218 21:49:21.689802  9736 net.cpp:418] Pooling1 -> Pooling1
I0218 21:49:21.689965  9736 net.cpp:150] Setting up Pooling1
I0218 21:49:21.689972  9736 net.cpp:157] Top shape: 50 64 1 1 (3200)
I0218 21:49:21.689975  9736 net.cpp:165] Memory required for data: 213897000
I0218 21:49:21.689977  9736 layer_factory.hpp:77] Creating layer InnerProduct1
I0218 21:49:21.689983  9736 net.cpp:100] Creating Layer InnerProduct1
I0218 21:49:21.689986  9736 net.cpp:444] InnerProduct1 <- Pooling1
I0218 21:49:21.689992  9736 net.cpp:418] InnerProduct1 -> InnerProduct1
I0218 21:49:21.690106  9736 net.cpp:150] Setting up InnerProduct1
I0218 21:49:21.690112  9736 net.cpp:157] Top shape: 50 16 (800)
I0218 21:49:21.690115  9736 net.cpp:165] Memory required for data: 213900200
I0218 21:49:21.690119  9736 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I0218 21:49:21.690125  9736 net.cpp:100] Creating Layer InnerProduct1_InnerProduct1_0_split
I0218 21:49:21.690129  9736 net.cpp:444] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I0218 21:49:21.690134  9736 net.cpp:418] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I0218 21:49:21.690140  9736 net.cpp:418] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I0218 21:49:21.690171  9736 net.cpp:150] Setting up InnerProduct1_InnerProduct1_0_split
I0218 21:49:21.690189  9736 net.cpp:157] Top shape: 50 16 (800)
I0218 21:49:21.690191  9736 net.cpp:157] Top shape: 50 16 (800)
I0218 21:49:21.690194  9736 net.cpp:165] Memory required for data: 213906600
I0218 21:49:21.690196  9736 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0218 21:49:21.690201  9736 net.cpp:100] Creating Layer SoftmaxWithLoss1
I0218 21:49:21.690204  9736 net.cpp:444] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I0218 21:49:21.690208  9736 net.cpp:444] SoftmaxWithLoss1 <- label_salinas_1_split_0
I0218 21:49:21.690217  9736 net.cpp:418] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0218 21:49:21.690227  9736 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0218 21:49:21.690845  9736 net.cpp:150] Setting up SoftmaxWithLoss1
I0218 21:49:21.690853  9736 net.cpp:157] Top shape: (1)
I0218 21:49:21.690856  9736 net.cpp:160]     with loss weight 1
I0218 21:49:21.690865  9736 net.cpp:165] Memory required for data: 213906604
I0218 21:49:21.690867  9736 layer_factory.hpp:77] Creating layer Accuracy1
I0218 21:49:21.690874  9736 net.cpp:100] Creating Layer Accuracy1
I0218 21:49:21.690878  9736 net.cpp:444] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I0218 21:49:21.690882  9736 net.cpp:444] Accuracy1 <- label_salinas_1_split_1
I0218 21:49:21.690886  9736 net.cpp:418] Accuracy1 -> Accuracy1
I0218 21:49:21.690894  9736 net.cpp:150] Setting up Accuracy1
I0218 21:49:21.690898  9736 net.cpp:157] Top shape: (1)
I0218 21:49:21.690901  9736 net.cpp:165] Memory required for data: 213906608
I0218 21:49:21.690903  9736 net.cpp:228] Accuracy1 does not need backward computation.
I0218 21:49:21.690907  9736 net.cpp:226] SoftmaxWithLoss1 needs backward computation.
I0218 21:49:21.690910  9736 net.cpp:226] InnerProduct1_InnerProduct1_0_split needs backward computation.
I0218 21:49:21.690913  9736 net.cpp:226] InnerProduct1 needs backward computation.
I0218 21:49:21.690915  9736 net.cpp:226] Pooling1 needs backward computation.
I0218 21:49:21.690918  9736 net.cpp:226] ReLU25 needs backward computation.
I0218 21:49:21.690922  9736 net.cpp:226] fuse2 needs backward computation.
I0218 21:49:21.690923  9736 net.cpp:226] fuse1 needs backward computation.
I0218 21:49:21.690927  9736 net.cpp:226] Scale_Convolution_eltwise8 needs backward computation.
I0218 21:49:21.690928  9736 net.cpp:226] BatchNorm_Convolution_eltwise8 needs backward computation.
I0218 21:49:21.690932  9736 net.cpp:226] Convolution_eltwise8 needs backward computation.
I0218 21:49:21.690934  9736 net.cpp:226] Scale_Convolution_eltwise4 needs backward computation.
I0218 21:49:21.690937  9736 net.cpp:226] BatchNorm_Convolution_eltwise4 needs backward computation.
I0218 21:49:21.690938  9736 net.cpp:226] Convolution_eltwise4 needs backward computation.
I0218 21:49:21.690942  9736 net.cpp:226] Eltwise12 needs backward computation.
I0218 21:49:21.690944  9736 net.cpp:226] Scale27 needs backward computation.
I0218 21:49:21.690948  9736 net.cpp:226] BatchNorm27 needs backward computation.
I0218 21:49:21.690949  9736 net.cpp:226] Convolution27 needs backward computation.
I0218 21:49:21.690953  9736 net.cpp:226] ReLU24 needs backward computation.
I0218 21:49:21.690954  9736 net.cpp:226] Scale26 needs backward computation.
I0218 21:49:21.690956  9736 net.cpp:226] BatchNorm26 needs backward computation.
I0218 21:49:21.690959  9736 net.cpp:226] Convolution26 needs backward computation.
I0218 21:49:21.690963  9736 net.cpp:226] Eltwise11_ReLU23_0_split needs backward computation.
I0218 21:49:21.690964  9736 net.cpp:226] ReLU23 needs backward computation.
I0218 21:49:21.690968  9736 net.cpp:226] Eltwise11 needs backward computation.
I0218 21:49:21.690970  9736 net.cpp:226] Scale25 needs backward computation.
I0218 21:49:21.690973  9736 net.cpp:226] BatchNorm25 needs backward computation.
I0218 21:49:21.690975  9736 net.cpp:226] Convolution25 needs backward computation.
I0218 21:49:21.690977  9736 net.cpp:226] ReLU22 needs backward computation.
I0218 21:49:21.690979  9736 net.cpp:226] Scale24 needs backward computation.
I0218 21:49:21.690982  9736 net.cpp:226] BatchNorm24 needs backward computation.
I0218 21:49:21.690984  9736 net.cpp:226] Convolution24 needs backward computation.
I0218 21:49:21.690989  9736 net.cpp:226] Eltwise10_ReLU21_0_split needs backward computation.
I0218 21:49:21.690990  9736 net.cpp:226] ReLU21 needs backward computation.
I0218 21:49:21.690994  9736 net.cpp:226] Eltwise10 needs backward computation.
I0218 21:49:21.690996  9736 net.cpp:226] Scale23 needs backward computation.
I0218 21:49:21.690999  9736 net.cpp:226] BatchNorm23 needs backward computation.
I0218 21:49:21.691004  9736 net.cpp:226] Convolution23 needs backward computation.
I0218 21:49:21.691012  9736 net.cpp:226] ReLU20 needs backward computation.
I0218 21:49:21.691015  9736 net.cpp:226] Scale22 needs backward computation.
I0218 21:49:21.691017  9736 net.cpp:226] BatchNorm22 needs backward computation.
I0218 21:49:21.691020  9736 net.cpp:226] Convolution22 needs backward computation.
I0218 21:49:21.691023  9736 net.cpp:226] Eltwise9_ReLU19_0_split needs backward computation.
I0218 21:49:21.691026  9736 net.cpp:226] ReLU19 needs backward computation.
I0218 21:49:21.691028  9736 net.cpp:226] Eltwise9 needs backward computation.
I0218 21:49:21.691032  9736 net.cpp:226] Scale21 needs backward computation.
I0218 21:49:21.691035  9736 net.cpp:226] BatchNorm21 needs backward computation.
I0218 21:49:21.691038  9736 net.cpp:226] Convolution21 needs backward computation.
I0218 21:49:21.691041  9736 net.cpp:226] ReLU18 needs backward computation.
I0218 21:49:21.691043  9736 net.cpp:226] Scale20 needs backward computation.
I0218 21:49:21.691046  9736 net.cpp:226] BatchNorm20 needs backward computation.
I0218 21:49:21.691048  9736 net.cpp:226] Convolution20 needs backward computation.
I0218 21:49:21.691051  9736 net.cpp:226] Scale19 needs backward computation.
I0218 21:49:21.691054  9736 net.cpp:226] BatchNorm19 needs backward computation.
I0218 21:49:21.691057  9736 net.cpp:226] Convolution19 needs backward computation.
I0218 21:49:21.691059  9736 net.cpp:226] Eltwise8_ReLU17_0_split needs backward computation.
I0218 21:49:21.691062  9736 net.cpp:226] ReLU17 needs backward computation.
I0218 21:49:21.691066  9736 net.cpp:226] Eltwise8 needs backward computation.
I0218 21:49:21.691068  9736 net.cpp:226] Scale18 needs backward computation.
I0218 21:49:21.691071  9736 net.cpp:226] BatchNorm18 needs backward computation.
I0218 21:49:21.691073  9736 net.cpp:226] Convolution18 needs backward computation.
I0218 21:49:21.691076  9736 net.cpp:226] ReLU16 needs backward computation.
I0218 21:49:21.691079  9736 net.cpp:226] Scale17 needs backward computation.
I0218 21:49:21.691082  9736 net.cpp:226] BatchNorm17 needs backward computation.
I0218 21:49:21.691084  9736 net.cpp:226] Convolution17 needs backward computation.
I0218 21:49:21.691087  9736 net.cpp:226] Eltwise7_ReLU15_0_split needs backward computation.
I0218 21:49:21.691090  9736 net.cpp:226] ReLU15 needs backward computation.
I0218 21:49:21.691093  9736 net.cpp:226] Eltwise7 needs backward computation.
I0218 21:49:21.691097  9736 net.cpp:226] Scale16 needs backward computation.
I0218 21:49:21.691098  9736 net.cpp:226] BatchNorm16 needs backward computation.
I0218 21:49:21.691102  9736 net.cpp:226] Convolution16 needs backward computation.
I0218 21:49:21.691104  9736 net.cpp:226] ReLU14 needs backward computation.
I0218 21:49:21.691107  9736 net.cpp:226] Scale15 needs backward computation.
I0218 21:49:21.691108  9736 net.cpp:226] BatchNorm15 needs backward computation.
I0218 21:49:21.691112  9736 net.cpp:226] Convolution15 needs backward computation.
I0218 21:49:21.691114  9736 net.cpp:226] Eltwise6_ReLU13_0_split needs backward computation.
I0218 21:49:21.691118  9736 net.cpp:226] ReLU13 needs backward computation.
I0218 21:49:21.691119  9736 net.cpp:226] Eltwise6 needs backward computation.
I0218 21:49:21.691123  9736 net.cpp:226] Scale14 needs backward computation.
I0218 21:49:21.691125  9736 net.cpp:226] BatchNorm14 needs backward computation.
I0218 21:49:21.691128  9736 net.cpp:226] Convolution14 needs backward computation.
I0218 21:49:21.691131  9736 net.cpp:226] ReLU12 needs backward computation.
I0218 21:49:21.691135  9736 net.cpp:226] Scale13 needs backward computation.
I0218 21:49:21.691138  9736 net.cpp:226] BatchNorm13 needs backward computation.
I0218 21:49:21.691139  9736 net.cpp:226] Convolution13 needs backward computation.
I0218 21:49:21.691143  9736 net.cpp:226] Eltwise5_ReLU11_0_split needs backward computation.
I0218 21:49:21.691146  9736 net.cpp:226] ReLU11 needs backward computation.
I0218 21:49:21.691148  9736 net.cpp:226] Eltwise5 needs backward computation.
I0218 21:49:21.691154  9736 net.cpp:226] Scale12 needs backward computation.
I0218 21:49:21.691159  9736 net.cpp:226] BatchNorm12 needs backward computation.
I0218 21:49:21.691162  9736 net.cpp:226] Convolution12 needs backward computation.
I0218 21:49:21.691164  9736 net.cpp:226] ReLU10 needs backward computation.
I0218 21:49:21.691167  9736 net.cpp:226] Scale11 needs backward computation.
I0218 21:49:21.691169  9736 net.cpp:226] BatchNorm11 needs backward computation.
I0218 21:49:21.691172  9736 net.cpp:226] Convolution11 needs backward computation.
I0218 21:49:21.691176  9736 net.cpp:226] Scale10 needs backward computation.
I0218 21:49:21.691179  9736 net.cpp:226] BatchNorm10 needs backward computation.
I0218 21:49:21.691181  9736 net.cpp:226] Convolution10 needs backward computation.
I0218 21:49:21.691184  9736 net.cpp:226] Eltwise4_ReLU9_0_split needs backward computation.
I0218 21:49:21.691187  9736 net.cpp:226] ReLU9 needs backward computation.
I0218 21:49:21.691190  9736 net.cpp:226] Eltwise4 needs backward computation.
I0218 21:49:21.691192  9736 net.cpp:226] Scale9 needs backward computation.
I0218 21:49:21.691196  9736 net.cpp:226] BatchNorm9 needs backward computation.
I0218 21:49:21.691198  9736 net.cpp:226] Convolution9 needs backward computation.
I0218 21:49:21.691201  9736 net.cpp:226] ReLU8 needs backward computation.
I0218 21:49:21.691203  9736 net.cpp:226] Scale8 needs backward computation.
I0218 21:49:21.691206  9736 net.cpp:226] BatchNorm8 needs backward computation.
I0218 21:49:21.691208  9736 net.cpp:226] Convolution8 needs backward computation.
I0218 21:49:21.691211  9736 net.cpp:226] Eltwise3_ReLU7_0_split needs backward computation.
I0218 21:49:21.691215  9736 net.cpp:226] ReLU7 needs backward computation.
I0218 21:49:21.691217  9736 net.cpp:226] Eltwise3 needs backward computation.
I0218 21:49:21.691220  9736 net.cpp:226] Scale7 needs backward computation.
I0218 21:49:21.691222  9736 net.cpp:226] BatchNorm7 needs backward computation.
I0218 21:49:21.691226  9736 net.cpp:226] Convolution7 needs backward computation.
I0218 21:49:21.691228  9736 net.cpp:226] ReLU6 needs backward computation.
I0218 21:49:21.691231  9736 net.cpp:226] Scale6 needs backward computation.
I0218 21:49:21.691233  9736 net.cpp:226] BatchNorm6 needs backward computation.
I0218 21:49:21.691236  9736 net.cpp:226] Convolution6 needs backward computation.
I0218 21:49:21.691239  9736 net.cpp:226] Eltwise2_ReLU5_0_split needs backward computation.
I0218 21:49:21.691242  9736 net.cpp:226] ReLU5 needs backward computation.
I0218 21:49:21.691244  9736 net.cpp:226] Eltwise2 needs backward computation.
I0218 21:49:21.691247  9736 net.cpp:226] Scale5 needs backward computation.
I0218 21:49:21.691251  9736 net.cpp:226] BatchNorm5 needs backward computation.
I0218 21:49:21.691253  9736 net.cpp:226] Convolution5 needs backward computation.
I0218 21:49:21.691256  9736 net.cpp:226] ReLU4 needs backward computation.
I0218 21:49:21.691258  9736 net.cpp:226] Scale4 needs backward computation.
I0218 21:49:21.691262  9736 net.cpp:226] BatchNorm4 needs backward computation.
I0218 21:49:21.691264  9736 net.cpp:226] Convolution4 needs backward computation.
I0218 21:49:21.691267  9736 net.cpp:226] Eltwise1_ReLU3_0_split needs backward computation.
I0218 21:49:21.691270  9736 net.cpp:226] ReLU3 needs backward computation.
I0218 21:49:21.691273  9736 net.cpp:226] Eltwise1 needs backward computation.
I0218 21:49:21.691277  9736 net.cpp:226] Scale3 needs backward computation.
I0218 21:49:21.691279  9736 net.cpp:226] BatchNorm3 needs backward computation.
I0218 21:49:21.691282  9736 net.cpp:226] Convolution3 needs backward computation.
I0218 21:49:21.691285  9736 net.cpp:226] ReLU2 needs backward computation.
I0218 21:49:21.691287  9736 net.cpp:226] Scale2 needs backward computation.
I0218 21:49:21.691290  9736 net.cpp:226] BatchNorm2 needs backward computation.
I0218 21:49:21.691293  9736 net.cpp:226] Convolution2 needs backward computation.
I0218 21:49:21.691296  9736 net.cpp:226] Convolution1_ReLU1_0_split needs backward computation.
I0218 21:49:21.691300  9736 net.cpp:226] ReLU1 needs backward computation.
I0218 21:49:21.691306  9736 net.cpp:226] Scale1 needs backward computation.
I0218 21:49:21.691309  9736 net.cpp:226] BatchNorm1 needs backward computation.
I0218 21:49:21.691313  9736 net.cpp:226] Convolution1 needs backward computation.
I0218 21:49:21.691315  9736 net.cpp:228] label_salinas_1_split does not need backward computation.
I0218 21:49:21.691318  9736 net.cpp:228] salinas does not need backward computation.
I0218 21:49:21.691320  9736 net.cpp:270] This network produces output Accuracy1
I0218 21:49:21.691324  9736 net.cpp:270] This network produces output SoftmaxWithLoss1
I0218 21:49:21.691375  9736 net.cpp:283] Network initialization done.
I0218 21:49:21.691660  9736 solver.cpp:60] Solver scaffolding done.
I0218 21:49:21.696771  9736 caffe.cpp:252] Starting Optimization
I0218 21:49:21.696780  9736 solver.cpp:279] Solving DFFN_salinas
I0218 21:49:21.696784  9736 solver.cpp:280] Learning Rate Policy: multistep
I0218 21:49:21.700655  9736 solver.cpp:337] Iteration 0, Testing net (#0)
I0218 21:49:32.736809  9736 solver.cpp:404]     Test net output #0: Accuracy1 = 0.0333707
I0218 21:49:32.736847  9736 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 87.3361 (* 1 = 87.3361 loss)
I0218 21:49:32.867023  9736 solver.cpp:228] Iteration 0, loss = 2.73205
I0218 21:49:32.867044  9736 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 2.73205 (* 1 = 2.73205 loss)
I0218 21:49:32.867056  9736 sgd_solver.cpp:106] Iteration 0, lr = 0.1
I0218 21:50:57.344533  9736 solver.cpp:228] Iteration 1000, loss = 0.000323965
I0218 21:50:57.344624  9736 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000324028 (* 1 = 0.000324028 loss)
I0218 21:50:57.344632  9736 sgd_solver.cpp:106] Iteration 1000, lr = 0.1
I0218 21:52:21.858155  9736 solver.cpp:228] Iteration 2000, loss = 0.00016302
I0218 21:52:21.858275  9736 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000163083 (* 1 = 0.000163083 loss)
I0218 21:52:21.858283  9736 sgd_solver.cpp:106] Iteration 2000, lr = 0.1
I0218 21:53:47.073596  9736 solver.cpp:228] Iteration 3000, loss = 0.000317179
I0218 21:53:47.073714  9736 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000317241 (* 1 = 0.000317241 loss)
I0218 21:53:47.073722  9736 sgd_solver.cpp:106] Iteration 3000, lr = 0.1
I0218 21:55:12.007401  9736 solver.cpp:228] Iteration 4000, loss = 0.00015505
I0218 21:55:12.007508  9736 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000155112 (* 1 = 0.000155112 loss)
I0218 21:55:12.007516  9736 sgd_solver.cpp:106] Iteration 4000, lr = 0.1
I0218 21:56:36.943339  9736 solver.cpp:228] Iteration 5000, loss = 0.000261351
I0218 21:56:36.943440  9736 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000261413 (* 1 = 0.000261413 loss)
I0218 21:56:36.943447  9736 sgd_solver.cpp:46] MultiStep Status: Iteration 5000, step = 1
I0218 21:56:36.943451  9736 sgd_solver.cpp:106] Iteration 5000, lr = 0.01
I0218 21:58:01.847062  9736 solver.cpp:228] Iteration 6000, loss = 0.00016548
I0218 21:58:01.847168  9736 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000165542 (* 1 = 0.000165542 loss)
I0218 21:58:01.847175  9736 sgd_solver.cpp:106] Iteration 6000, lr = 0.01
I0218 21:59:27.442752  9736 solver.cpp:228] Iteration 7000, loss = 8.71155e-05
I0218 21:59:27.442863  9736 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 8.71776e-05 (* 1 = 8.71776e-05 loss)
I0218 21:59:27.442872  9736 sgd_solver.cpp:106] Iteration 7000, lr = 0.01
I0218 22:00:52.626258  9736 solver.cpp:228] Iteration 8000, loss = 0.000312018
I0218 22:00:52.626370  9736 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00031208 (* 1 = 0.00031208 loss)
I0218 22:00:52.626379  9736 sgd_solver.cpp:106] Iteration 8000, lr = 0.01
I0218 22:02:17.822649  9736 solver.cpp:228] Iteration 9000, loss = 0.000109
I0218 22:02:17.822767  9736 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000109062 (* 1 = 0.000109062 loss)
I0218 22:02:17.822777  9736 sgd_solver.cpp:106] Iteration 9000, lr = 0.01
I0218 22:03:43.015519  9736 solver.cpp:228] Iteration 10000, loss = 0.000237123
I0218 22:03:43.015636  9736 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000237185 (* 1 = 0.000237185 loss)
I0218 22:03:43.015643  9736 sgd_solver.cpp:46] MultiStep Status: Iteration 10000, step = 2
I0218 22:03:43.015647  9736 sgd_solver.cpp:106] Iteration 10000, lr = 0.001
I0218 22:05:08.205027  9736 solver.cpp:228] Iteration 11000, loss = 0.00014677
I0218 22:05:08.205142  9736 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000146832 (* 1 = 0.000146832 loss)
I0218 22:05:08.205150  9736 sgd_solver.cpp:106] Iteration 11000, lr = 0.001
I0218 22:06:33.116233  9736 solver.cpp:228] Iteration 12000, loss = 0.000168913
I0218 22:06:33.116354  9736 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000168975 (* 1 = 0.000168975 loss)
I0218 22:06:33.116363  9736 sgd_solver.cpp:106] Iteration 12000, lr = 0.001
I0218 22:07:58.042589  9736 solver.cpp:228] Iteration 13000, loss = 0.000141889
I0218 22:07:58.042701  9736 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000141951 (* 1 = 0.000141951 loss)
I0218 22:07:58.042711  9736 sgd_solver.cpp:106] Iteration 13000, lr = 0.001
I0218 22:09:22.957106  9736 solver.cpp:228] Iteration 14000, loss = 0.000136231
I0218 22:09:22.957226  9736 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000136293 (* 1 = 0.000136293 loss)
I0218 22:09:22.957234  9736 sgd_solver.cpp:106] Iteration 14000, lr = 0.001
I0218 22:10:48.248234  9736 solver.cpp:228] Iteration 15000, loss = 0.000293327
I0218 22:10:48.248347  9736 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000293389 (* 1 = 0.000293389 loss)
I0218 22:10:48.248355  9736 sgd_solver.cpp:46] MultiStep Status: Iteration 15000, step = 3
I0218 22:10:48.248359  9736 sgd_solver.cpp:106] Iteration 15000, lr = 0.0001
I0218 22:12:14.180445  9736 solver.cpp:228] Iteration 16000, loss = 0.00022131
I0218 22:12:14.180559  9736 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000221371 (* 1 = 0.000221371 loss)
I0218 22:12:14.180567  9736 sgd_solver.cpp:106] Iteration 16000, lr = 0.0001
I0218 22:13:39.158113  9736 solver.cpp:228] Iteration 17000, loss = 0.000205662
I0218 22:13:39.158236  9736 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000205723 (* 1 = 0.000205723 loss)
I0218 22:13:39.158241  9736 sgd_solver.cpp:106] Iteration 17000, lr = 0.0001
I0218 22:15:03.879518  9736 solver.cpp:228] Iteration 18000, loss = 0.000243197
I0218 22:15:03.879635  9736 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000243259 (* 1 = 0.000243259 loss)
I0218 22:15:03.879642  9736 sgd_solver.cpp:106] Iteration 18000, lr = 0.0001
I0218 22:16:28.606940  9736 solver.cpp:228] Iteration 19000, loss = 0.000123844
I0218 22:16:28.607046  9736 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000123906 (* 1 = 0.000123906 loss)
I0218 22:16:28.607053  9736 sgd_solver.cpp:106] Iteration 19000, lr = 0.0001
I0218 22:17:53.333061  9736 solver.cpp:454] Snapshotting to binary proto file ./snapshot/salinas/_iter_20000.caffemodel
I0218 22:17:53.346355  9736 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshot/salinas/_iter_20000.solverstate
I0218 22:17:53.367797  9736 solver.cpp:317] Iteration 20000, loss = 0.000133104
I0218 22:17:53.367820  9736 solver.cpp:337] Iteration 20000, Testing net (#0)
I0218 22:18:05.013808  9736 solver.cpp:404]     Test net output #0: Accuracy1 = 0.985198
I0218 22:18:05.013866  9736 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.0465091 (* 1 = 0.0465091 loss)
I0218 22:18:05.013870  9736 solver.cpp:322] Optimization Done.
I0218 22:18:05.013873  9736 caffe.cpp:255] Optimization Done.
