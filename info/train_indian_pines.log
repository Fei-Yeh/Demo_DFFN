I0117 22:13:14.259886  7680 caffe.cpp:218] Using GPUs 0
I0117 22:13:14.417891  7680 caffe.cpp:223] GPU 0: GeForce GTX TITAN X
I0117 22:13:16.252941  7680 solver.cpp:44] Initializing solver from parameters: 
test_iter: 461
test_interval: 20000
base_lr: 0.1
display: 1000
max_iter: 20000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 20000
snapshot_prefix: "./snapshot/indian_pines/"
solver_mode: GPU
device_id: 0
net: "./prototxt_files/train_indian_pines.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 5000
stepvalue: 10000
stepvalue: 15000
stepvalue: 20000
I0117 22:13:16.253517  7680 solver.cpp:87] Creating training net from net file: ./prototxt_files/train_indian_pines.prototxt
I0117 22:13:16.276407  7680 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: ./prototxt_files/train_indian_pines.prototxt
I0117 22:13:16.276473  7680 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0117 22:13:16.290906  7680 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer indian
I0117 22:13:16.291004  7680 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I0117 22:13:16.292121  7680 net.cpp:51] Initializing net from parameters: 
name: "DFFN"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "indian"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "caffe-master/data/indian_pines/train.txt"
    batch_size: 100
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "data"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution11"
  top: "Convolution11"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Convolution11"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Convolution10"
  bottom: "Convolution12"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "Convolution13"
  top: "Convolution13"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Convolution15"
  top: "Convolution15"
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Convolution15"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution16"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution17"
  top: "Convolution17"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Convolution17"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution18"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution20"
  top: "Convolution20"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Convolution19"
  bottom: "Convolution21"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU20"
  type: "ReLU"
  bottom: "Convolution22"
  top: "Convolution22"
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Convolution22"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Eltwise9"
  bottom: "Convolution23"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "Convolution24"
  top: "Convolution24"
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Convolution24"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution25"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "Eltwise11"
  top: "Eltwise11"
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU24"
  type: "ReLU"
  bottom: "Convolution26"
  top: "Convolution26"
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Convolution26"
  top: "Convolution27"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Eltwise11"
  bottom: "Convolution27"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution_eltwise4"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution_eltwise4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm_Convolution_eltwise4"
  type: "BatchNorm"
  bottom: "Convolution_eltwise4"
  top: "Convolution_eltwise4"
}
layer {
  name: "Scale_Convolution_eltwise4"
  type: "Scale"
  bottom: "Convolution_eltwise4"
  top: "Convolution_eltwise4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution_eltwise8"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution_eltwise8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm_Convolution_eltwise8"
  type: "BatchNorm"
  bottom: "Convolution_eltwise8"
  top: "Convolution_eltwise8"
}
layer {
  name: "Scale_Convolution_eltwise8"
  type: "Scale"
  bottom: "Convolution_eltwise8"
  top: "Convolution_eltwise8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "fuse1"
  type: "Eltwise"
  bottom: "Convolution_eltwise4"
  bottom: "Convolution_eltwise8"
  top: "fuse1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "fuse2"
  type: "Eltwise"
  bottom: "fuse1"
  bottom: "Eltwise12"
  top: "fuse2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "fuse2"
  top: "fuse2"
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "fuse2"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "InnerProduct1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 16
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "label"
  top: "SoftmaxWithLoss1"
}
I0117 22:13:16.295286  7680 layer_factory.hpp:77] Creating layer indian
I0117 22:13:16.295333  7680 net.cpp:84] Creating Layer indian
I0117 22:13:16.295351  7680 net.cpp:380] indian -> data
I0117 22:13:16.295384  7680 net.cpp:380] indian -> label
I0117 22:13:16.295426  7680 hdf5_data_layer.cpp:80] Loading list of HDF5 filenames from: caffe-master/data/indian_pines/train.txt
I0117 22:13:16.304155  7680 hdf5_data_layer.cpp:94] Number of HDF5 files: 1
I0117 22:13:16.345008  7680 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0117 22:13:16.353798  7680 net.cpp:122] Setting up indian
I0117 22:13:16.353866  7680 net.cpp:129] Top shape: 100 3 25 25 (187500)
I0117 22:13:16.353885  7680 net.cpp:129] Top shape: 100 1 (100)
I0117 22:13:16.353905  7680 net.cpp:137] Memory required for data: 750400
I0117 22:13:16.353920  7680 layer_factory.hpp:77] Creating layer Convolution1
I0117 22:13:16.353967  7680 net.cpp:84] Creating Layer Convolution1
I0117 22:13:16.353983  7680 net.cpp:406] Convolution1 <- data
I0117 22:13:16.354007  7680 net.cpp:380] Convolution1 -> Convolution1
I0117 22:13:17.315043  7680 net.cpp:122] Setting up Convolution1
I0117 22:13:17.315104  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.315112  7680 net.cpp:137] Memory required for data: 4750400
I0117 22:13:17.315142  7680 layer_factory.hpp:77] Creating layer BatchNorm1
I0117 22:13:17.315167  7680 net.cpp:84] Creating Layer BatchNorm1
I0117 22:13:17.315174  7680 net.cpp:406] BatchNorm1 <- Convolution1
I0117 22:13:17.315182  7680 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I0117 22:13:17.315372  7680 net.cpp:122] Setting up BatchNorm1
I0117 22:13:17.315405  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.315412  7680 net.cpp:137] Memory required for data: 8750400
I0117 22:13:17.315443  7680 layer_factory.hpp:77] Creating layer Scale1
I0117 22:13:17.315452  7680 net.cpp:84] Creating Layer Scale1
I0117 22:13:17.315457  7680 net.cpp:406] Scale1 <- Convolution1
I0117 22:13:17.315464  7680 net.cpp:367] Scale1 -> Convolution1 (in-place)
I0117 22:13:17.315512  7680 layer_factory.hpp:77] Creating layer Scale1
I0117 22:13:17.315618  7680 net.cpp:122] Setting up Scale1
I0117 22:13:17.315629  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.315634  7680 net.cpp:137] Memory required for data: 12750400
I0117 22:13:17.315641  7680 layer_factory.hpp:77] Creating layer ReLU1
I0117 22:13:17.315650  7680 net.cpp:84] Creating Layer ReLU1
I0117 22:13:17.315655  7680 net.cpp:406] ReLU1 <- Convolution1
I0117 22:13:17.315661  7680 net.cpp:367] ReLU1 -> Convolution1 (in-place)
I0117 22:13:17.316339  7680 net.cpp:122] Setting up ReLU1
I0117 22:13:17.316364  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.316370  7680 net.cpp:137] Memory required for data: 16750400
I0117 22:13:17.316375  7680 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I0117 22:13:17.316382  7680 net.cpp:84] Creating Layer Convolution1_ReLU1_0_split
I0117 22:13:17.316388  7680 net.cpp:406] Convolution1_ReLU1_0_split <- Convolution1
I0117 22:13:17.316395  7680 net.cpp:380] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I0117 22:13:17.316412  7680 net.cpp:380] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I0117 22:13:17.316459  7680 net.cpp:122] Setting up Convolution1_ReLU1_0_split
I0117 22:13:17.316468  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.316474  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.316479  7680 net.cpp:137] Memory required for data: 24750400
I0117 22:13:17.316493  7680 layer_factory.hpp:77] Creating layer Convolution2
I0117 22:13:17.316517  7680 net.cpp:84] Creating Layer Convolution2
I0117 22:13:17.316522  7680 net.cpp:406] Convolution2 <- Convolution1_ReLU1_0_split_0
I0117 22:13:17.316531  7680 net.cpp:380] Convolution2 -> Convolution2
I0117 22:13:17.318203  7680 net.cpp:122] Setting up Convolution2
I0117 22:13:17.318236  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.318243  7680 net.cpp:137] Memory required for data: 28750400
I0117 22:13:17.318258  7680 layer_factory.hpp:77] Creating layer BatchNorm2
I0117 22:13:17.318269  7680 net.cpp:84] Creating Layer BatchNorm2
I0117 22:13:17.318274  7680 net.cpp:406] BatchNorm2 <- Convolution2
I0117 22:13:17.318282  7680 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I0117 22:13:17.318449  7680 net.cpp:122] Setting up BatchNorm2
I0117 22:13:17.318459  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.318464  7680 net.cpp:137] Memory required for data: 32750400
I0117 22:13:17.318475  7680 layer_factory.hpp:77] Creating layer Scale2
I0117 22:13:17.318485  7680 net.cpp:84] Creating Layer Scale2
I0117 22:13:17.318490  7680 net.cpp:406] Scale2 <- Convolution2
I0117 22:13:17.318497  7680 net.cpp:367] Scale2 -> Convolution2 (in-place)
I0117 22:13:17.318536  7680 layer_factory.hpp:77] Creating layer Scale2
I0117 22:13:17.318637  7680 net.cpp:122] Setting up Scale2
I0117 22:13:17.318647  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.318652  7680 net.cpp:137] Memory required for data: 36750400
I0117 22:13:17.318660  7680 layer_factory.hpp:77] Creating layer ReLU2
I0117 22:13:17.318667  7680 net.cpp:84] Creating Layer ReLU2
I0117 22:13:17.318672  7680 net.cpp:406] ReLU2 <- Convolution2
I0117 22:13:17.318680  7680 net.cpp:367] ReLU2 -> Convolution2 (in-place)
I0117 22:13:17.318835  7680 net.cpp:122] Setting up ReLU2
I0117 22:13:17.318846  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.318851  7680 net.cpp:137] Memory required for data: 40750400
I0117 22:13:17.318856  7680 layer_factory.hpp:77] Creating layer Convolution3
I0117 22:13:17.318868  7680 net.cpp:84] Creating Layer Convolution3
I0117 22:13:17.318874  7680 net.cpp:406] Convolution3 <- Convolution2
I0117 22:13:17.318882  7680 net.cpp:380] Convolution3 -> Convolution3
I0117 22:13:17.320538  7680 net.cpp:122] Setting up Convolution3
I0117 22:13:17.320576  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.320583  7680 net.cpp:137] Memory required for data: 44750400
I0117 22:13:17.320595  7680 layer_factory.hpp:77] Creating layer BatchNorm3
I0117 22:13:17.320606  7680 net.cpp:84] Creating Layer BatchNorm3
I0117 22:13:17.320613  7680 net.cpp:406] BatchNorm3 <- Convolution3
I0117 22:13:17.320622  7680 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I0117 22:13:17.320786  7680 net.cpp:122] Setting up BatchNorm3
I0117 22:13:17.320797  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.320802  7680 net.cpp:137] Memory required for data: 48750400
I0117 22:13:17.320816  7680 layer_factory.hpp:77] Creating layer Scale3
I0117 22:13:17.320825  7680 net.cpp:84] Creating Layer Scale3
I0117 22:13:17.320830  7680 net.cpp:406] Scale3 <- Convolution3
I0117 22:13:17.320837  7680 net.cpp:367] Scale3 -> Convolution3 (in-place)
I0117 22:13:17.320880  7680 layer_factory.hpp:77] Creating layer Scale3
I0117 22:13:17.320979  7680 net.cpp:122] Setting up Scale3
I0117 22:13:17.320989  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.320994  7680 net.cpp:137] Memory required for data: 52750400
I0117 22:13:17.321002  7680 layer_factory.hpp:77] Creating layer Eltwise1
I0117 22:13:17.321009  7680 net.cpp:84] Creating Layer Eltwise1
I0117 22:13:17.321015  7680 net.cpp:406] Eltwise1 <- Convolution1_ReLU1_0_split_1
I0117 22:13:17.321022  7680 net.cpp:406] Eltwise1 <- Convolution3
I0117 22:13:17.321027  7680 net.cpp:380] Eltwise1 -> Eltwise1
I0117 22:13:17.321056  7680 net.cpp:122] Setting up Eltwise1
I0117 22:13:17.321065  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.321079  7680 net.cpp:137] Memory required for data: 56750400
I0117 22:13:17.321091  7680 layer_factory.hpp:77] Creating layer ReLU3
I0117 22:13:17.321099  7680 net.cpp:84] Creating Layer ReLU3
I0117 22:13:17.321104  7680 net.cpp:406] ReLU3 <- Eltwise1
I0117 22:13:17.321110  7680 net.cpp:367] ReLU3 -> Eltwise1 (in-place)
I0117 22:13:17.321708  7680 net.cpp:122] Setting up ReLU3
I0117 22:13:17.321722  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.321727  7680 net.cpp:137] Memory required for data: 60750400
I0117 22:13:17.321732  7680 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I0117 22:13:17.321739  7680 net.cpp:84] Creating Layer Eltwise1_ReLU3_0_split
I0117 22:13:17.321744  7680 net.cpp:406] Eltwise1_ReLU3_0_split <- Eltwise1
I0117 22:13:17.321751  7680 net.cpp:380] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I0117 22:13:17.321761  7680 net.cpp:380] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I0117 22:13:17.321799  7680 net.cpp:122] Setting up Eltwise1_ReLU3_0_split
I0117 22:13:17.321808  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.321815  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.321820  7680 net.cpp:137] Memory required for data: 68750400
I0117 22:13:17.321825  7680 layer_factory.hpp:77] Creating layer Convolution4
I0117 22:13:17.321838  7680 net.cpp:84] Creating Layer Convolution4
I0117 22:13:17.321844  7680 net.cpp:406] Convolution4 <- Eltwise1_ReLU3_0_split_0
I0117 22:13:17.321852  7680 net.cpp:380] Convolution4 -> Convolution4
I0117 22:13:17.323040  7680 net.cpp:122] Setting up Convolution4
I0117 22:13:17.323071  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.323077  7680 net.cpp:137] Memory required for data: 72750400
I0117 22:13:17.323089  7680 layer_factory.hpp:77] Creating layer BatchNorm4
I0117 22:13:17.323099  7680 net.cpp:84] Creating Layer BatchNorm4
I0117 22:13:17.323107  7680 net.cpp:406] BatchNorm4 <- Convolution4
I0117 22:13:17.323113  7680 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I0117 22:13:17.323287  7680 net.cpp:122] Setting up BatchNorm4
I0117 22:13:17.323298  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.323303  7680 net.cpp:137] Memory required for data: 76750400
I0117 22:13:17.323320  7680 layer_factory.hpp:77] Creating layer Scale4
I0117 22:13:17.323329  7680 net.cpp:84] Creating Layer Scale4
I0117 22:13:17.323334  7680 net.cpp:406] Scale4 <- Convolution4
I0117 22:13:17.323341  7680 net.cpp:367] Scale4 -> Convolution4 (in-place)
I0117 22:13:17.323398  7680 layer_factory.hpp:77] Creating layer Scale4
I0117 22:13:17.323509  7680 net.cpp:122] Setting up Scale4
I0117 22:13:17.323519  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.323524  7680 net.cpp:137] Memory required for data: 80750400
I0117 22:13:17.323532  7680 layer_factory.hpp:77] Creating layer ReLU4
I0117 22:13:17.323539  7680 net.cpp:84] Creating Layer ReLU4
I0117 22:13:17.323544  7680 net.cpp:406] ReLU4 <- Convolution4
I0117 22:13:17.323550  7680 net.cpp:367] ReLU4 -> Convolution4 (in-place)
I0117 22:13:17.324156  7680 net.cpp:122] Setting up ReLU4
I0117 22:13:17.324169  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.324174  7680 net.cpp:137] Memory required for data: 84750400
I0117 22:13:17.324179  7680 layer_factory.hpp:77] Creating layer Convolution5
I0117 22:13:17.324192  7680 net.cpp:84] Creating Layer Convolution5
I0117 22:13:17.324196  7680 net.cpp:406] Convolution5 <- Convolution4
I0117 22:13:17.324205  7680 net.cpp:380] Convolution5 -> Convolution5
I0117 22:13:17.325835  7680 net.cpp:122] Setting up Convolution5
I0117 22:13:17.325871  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.325879  7680 net.cpp:137] Memory required for data: 88750400
I0117 22:13:17.325891  7680 layer_factory.hpp:77] Creating layer BatchNorm5
I0117 22:13:17.325902  7680 net.cpp:84] Creating Layer BatchNorm5
I0117 22:13:17.325909  7680 net.cpp:406] BatchNorm5 <- Convolution5
I0117 22:13:17.325917  7680 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I0117 22:13:17.326105  7680 net.cpp:122] Setting up BatchNorm5
I0117 22:13:17.326128  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.326133  7680 net.cpp:137] Memory required for data: 92750400
I0117 22:13:17.326149  7680 layer_factory.hpp:77] Creating layer Scale5
I0117 22:13:17.326159  7680 net.cpp:84] Creating Layer Scale5
I0117 22:13:17.326164  7680 net.cpp:406] Scale5 <- Convolution5
I0117 22:13:17.326171  7680 net.cpp:367] Scale5 -> Convolution5 (in-place)
I0117 22:13:17.326215  7680 layer_factory.hpp:77] Creating layer Scale5
I0117 22:13:17.326319  7680 net.cpp:122] Setting up Scale5
I0117 22:13:17.326329  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.326334  7680 net.cpp:137] Memory required for data: 96750400
I0117 22:13:17.326342  7680 layer_factory.hpp:77] Creating layer Eltwise2
I0117 22:13:17.326351  7680 net.cpp:84] Creating Layer Eltwise2
I0117 22:13:17.326356  7680 net.cpp:406] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I0117 22:13:17.326362  7680 net.cpp:406] Eltwise2 <- Convolution5
I0117 22:13:17.326370  7680 net.cpp:380] Eltwise2 -> Eltwise2
I0117 22:13:17.326395  7680 net.cpp:122] Setting up Eltwise2
I0117 22:13:17.326405  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.326409  7680 net.cpp:137] Memory required for data: 100750400
I0117 22:13:17.326414  7680 layer_factory.hpp:77] Creating layer ReLU5
I0117 22:13:17.326421  7680 net.cpp:84] Creating Layer ReLU5
I0117 22:13:17.326426  7680 net.cpp:406] ReLU5 <- Eltwise2
I0117 22:13:17.326432  7680 net.cpp:367] ReLU5 -> Eltwise2 (in-place)
I0117 22:13:17.326581  7680 net.cpp:122] Setting up ReLU5
I0117 22:13:17.326591  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.326597  7680 net.cpp:137] Memory required for data: 104750400
I0117 22:13:17.326602  7680 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I0117 22:13:17.326611  7680 net.cpp:84] Creating Layer Eltwise2_ReLU5_0_split
I0117 22:13:17.326616  7680 net.cpp:406] Eltwise2_ReLU5_0_split <- Eltwise2
I0117 22:13:17.326622  7680 net.cpp:380] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I0117 22:13:17.326632  7680 net.cpp:380] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I0117 22:13:17.326666  7680 net.cpp:122] Setting up Eltwise2_ReLU5_0_split
I0117 22:13:17.326675  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.326681  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.326686  7680 net.cpp:137] Memory required for data: 112750400
I0117 22:13:17.326691  7680 layer_factory.hpp:77] Creating layer Convolution6
I0117 22:13:17.326702  7680 net.cpp:84] Creating Layer Convolution6
I0117 22:13:17.326709  7680 net.cpp:406] Convolution6 <- Eltwise2_ReLU5_0_split_0
I0117 22:13:17.326716  7680 net.cpp:380] Convolution6 -> Convolution6
I0117 22:13:17.328352  7680 net.cpp:122] Setting up Convolution6
I0117 22:13:17.328390  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.328397  7680 net.cpp:137] Memory required for data: 116750400
I0117 22:13:17.328410  7680 layer_factory.hpp:77] Creating layer BatchNorm6
I0117 22:13:17.328421  7680 net.cpp:84] Creating Layer BatchNorm6
I0117 22:13:17.328428  7680 net.cpp:406] BatchNorm6 <- Convolution6
I0117 22:13:17.328438  7680 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I0117 22:13:17.328630  7680 net.cpp:122] Setting up BatchNorm6
I0117 22:13:17.328642  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.328647  7680 net.cpp:137] Memory required for data: 120750400
I0117 22:13:17.328657  7680 layer_factory.hpp:77] Creating layer Scale6
I0117 22:13:17.328666  7680 net.cpp:84] Creating Layer Scale6
I0117 22:13:17.328672  7680 net.cpp:406] Scale6 <- Convolution6
I0117 22:13:17.328678  7680 net.cpp:367] Scale6 -> Convolution6 (in-place)
I0117 22:13:17.328718  7680 layer_factory.hpp:77] Creating layer Scale6
I0117 22:13:17.328820  7680 net.cpp:122] Setting up Scale6
I0117 22:13:17.328830  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.328835  7680 net.cpp:137] Memory required for data: 124750400
I0117 22:13:17.328851  7680 layer_factory.hpp:77] Creating layer ReLU6
I0117 22:13:17.328866  7680 net.cpp:84] Creating Layer ReLU6
I0117 22:13:17.328871  7680 net.cpp:406] ReLU6 <- Convolution6
I0117 22:13:17.328877  7680 net.cpp:367] ReLU6 -> Convolution6 (in-place)
I0117 22:13:17.329473  7680 net.cpp:122] Setting up ReLU6
I0117 22:13:17.329484  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.329489  7680 net.cpp:137] Memory required for data: 128750400
I0117 22:13:17.329495  7680 layer_factory.hpp:77] Creating layer Convolution7
I0117 22:13:17.329524  7680 net.cpp:84] Creating Layer Convolution7
I0117 22:13:17.329530  7680 net.cpp:406] Convolution7 <- Convolution6
I0117 22:13:17.329545  7680 net.cpp:380] Convolution7 -> Convolution7
I0117 22:13:17.330826  7680 net.cpp:122] Setting up Convolution7
I0117 22:13:17.330844  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.330850  7680 net.cpp:137] Memory required for data: 132750400
I0117 22:13:17.330859  7680 layer_factory.hpp:77] Creating layer BatchNorm7
I0117 22:13:17.330868  7680 net.cpp:84] Creating Layer BatchNorm7
I0117 22:13:17.330873  7680 net.cpp:406] BatchNorm7 <- Convolution7
I0117 22:13:17.330881  7680 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I0117 22:13:17.331048  7680 net.cpp:122] Setting up BatchNorm7
I0117 22:13:17.331058  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.331064  7680 net.cpp:137] Memory required for data: 136750400
I0117 22:13:17.331073  7680 layer_factory.hpp:77] Creating layer Scale7
I0117 22:13:17.331086  7680 net.cpp:84] Creating Layer Scale7
I0117 22:13:17.331091  7680 net.cpp:406] Scale7 <- Convolution7
I0117 22:13:17.331099  7680 net.cpp:367] Scale7 -> Convolution7 (in-place)
I0117 22:13:17.331140  7680 layer_factory.hpp:77] Creating layer Scale7
I0117 22:13:17.331243  7680 net.cpp:122] Setting up Scale7
I0117 22:13:17.331251  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.331257  7680 net.cpp:137] Memory required for data: 140750400
I0117 22:13:17.331264  7680 layer_factory.hpp:77] Creating layer Eltwise3
I0117 22:13:17.331274  7680 net.cpp:84] Creating Layer Eltwise3
I0117 22:13:17.331279  7680 net.cpp:406] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I0117 22:13:17.331285  7680 net.cpp:406] Eltwise3 <- Convolution7
I0117 22:13:17.331292  7680 net.cpp:380] Eltwise3 -> Eltwise3
I0117 22:13:17.331317  7680 net.cpp:122] Setting up Eltwise3
I0117 22:13:17.331326  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.331331  7680 net.cpp:137] Memory required for data: 144750400
I0117 22:13:17.331336  7680 layer_factory.hpp:77] Creating layer ReLU7
I0117 22:13:17.331343  7680 net.cpp:84] Creating Layer ReLU7
I0117 22:13:17.331348  7680 net.cpp:406] ReLU7 <- Eltwise3
I0117 22:13:17.331356  7680 net.cpp:367] ReLU7 -> Eltwise3 (in-place)
I0117 22:13:17.331981  7680 net.cpp:122] Setting up ReLU7
I0117 22:13:17.331998  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.332003  7680 net.cpp:137] Memory required for data: 148750400
I0117 22:13:17.332010  7680 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I0117 22:13:17.332017  7680 net.cpp:84] Creating Layer Eltwise3_ReLU7_0_split
I0117 22:13:17.332022  7680 net.cpp:406] Eltwise3_ReLU7_0_split <- Eltwise3
I0117 22:13:17.332031  7680 net.cpp:380] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I0117 22:13:17.332039  7680 net.cpp:380] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I0117 22:13:17.332077  7680 net.cpp:122] Setting up Eltwise3_ReLU7_0_split
I0117 22:13:17.332087  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.332093  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.332098  7680 net.cpp:137] Memory required for data: 156750400
I0117 22:13:17.332103  7680 layer_factory.hpp:77] Creating layer Convolution8
I0117 22:13:17.332114  7680 net.cpp:84] Creating Layer Convolution8
I0117 22:13:17.332119  7680 net.cpp:406] Convolution8 <- Eltwise3_ReLU7_0_split_0
I0117 22:13:17.332128  7680 net.cpp:380] Convolution8 -> Convolution8
I0117 22:13:17.333714  7680 net.cpp:122] Setting up Convolution8
I0117 22:13:17.333751  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.333757  7680 net.cpp:137] Memory required for data: 160750400
I0117 22:13:17.333768  7680 layer_factory.hpp:77] Creating layer BatchNorm8
I0117 22:13:17.333778  7680 net.cpp:84] Creating Layer BatchNorm8
I0117 22:13:17.333784  7680 net.cpp:406] BatchNorm8 <- Convolution8
I0117 22:13:17.333792  7680 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I0117 22:13:17.333992  7680 net.cpp:122] Setting up BatchNorm8
I0117 22:13:17.334003  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.334008  7680 net.cpp:137] Memory required for data: 164750400
I0117 22:13:17.334018  7680 layer_factory.hpp:77] Creating layer Scale8
I0117 22:13:17.334028  7680 net.cpp:84] Creating Layer Scale8
I0117 22:13:17.334033  7680 net.cpp:406] Scale8 <- Convolution8
I0117 22:13:17.334040  7680 net.cpp:367] Scale8 -> Convolution8 (in-place)
I0117 22:13:17.334084  7680 layer_factory.hpp:77] Creating layer Scale8
I0117 22:13:17.334204  7680 net.cpp:122] Setting up Scale8
I0117 22:13:17.334214  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.334219  7680 net.cpp:137] Memory required for data: 168750400
I0117 22:13:17.334228  7680 layer_factory.hpp:77] Creating layer ReLU8
I0117 22:13:17.334234  7680 net.cpp:84] Creating Layer ReLU8
I0117 22:13:17.334239  7680 net.cpp:406] ReLU8 <- Convolution8
I0117 22:13:17.334245  7680 net.cpp:367] ReLU8 -> Convolution8 (in-place)
I0117 22:13:17.334832  7680 net.cpp:122] Setting up ReLU8
I0117 22:13:17.334846  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.334851  7680 net.cpp:137] Memory required for data: 172750400
I0117 22:13:17.334857  7680 layer_factory.hpp:77] Creating layer Convolution9
I0117 22:13:17.334869  7680 net.cpp:84] Creating Layer Convolution9
I0117 22:13:17.334874  7680 net.cpp:406] Convolution9 <- Convolution8
I0117 22:13:17.334882  7680 net.cpp:380] Convolution9 -> Convolution9
I0117 22:13:17.336549  7680 net.cpp:122] Setting up Convolution9
I0117 22:13:17.336578  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.336585  7680 net.cpp:137] Memory required for data: 176750400
I0117 22:13:17.336596  7680 layer_factory.hpp:77] Creating layer BatchNorm9
I0117 22:13:17.336606  7680 net.cpp:84] Creating Layer BatchNorm9
I0117 22:13:17.336611  7680 net.cpp:406] BatchNorm9 <- Convolution9
I0117 22:13:17.336619  7680 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I0117 22:13:17.336797  7680 net.cpp:122] Setting up BatchNorm9
I0117 22:13:17.336808  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.336813  7680 net.cpp:137] Memory required for data: 180750400
I0117 22:13:17.336823  7680 layer_factory.hpp:77] Creating layer Scale9
I0117 22:13:17.336833  7680 net.cpp:84] Creating Layer Scale9
I0117 22:13:17.336838  7680 net.cpp:406] Scale9 <- Convolution9
I0117 22:13:17.336844  7680 net.cpp:367] Scale9 -> Convolution9 (in-place)
I0117 22:13:17.336889  7680 layer_factory.hpp:77] Creating layer Scale9
I0117 22:13:17.337014  7680 net.cpp:122] Setting up Scale9
I0117 22:13:17.337025  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.337030  7680 net.cpp:137] Memory required for data: 184750400
I0117 22:13:17.337039  7680 layer_factory.hpp:77] Creating layer Eltwise4
I0117 22:13:17.337057  7680 net.cpp:84] Creating Layer Eltwise4
I0117 22:13:17.337062  7680 net.cpp:406] Eltwise4 <- Eltwise3_ReLU7_0_split_1
I0117 22:13:17.337069  7680 net.cpp:406] Eltwise4 <- Convolution9
I0117 22:13:17.337085  7680 net.cpp:380] Eltwise4 -> Eltwise4
I0117 22:13:17.337111  7680 net.cpp:122] Setting up Eltwise4
I0117 22:13:17.337121  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.337133  7680 net.cpp:137] Memory required for data: 188750400
I0117 22:13:17.337138  7680 layer_factory.hpp:77] Creating layer ReLU9
I0117 22:13:17.337153  7680 net.cpp:84] Creating Layer ReLU9
I0117 22:13:17.337159  7680 net.cpp:406] ReLU9 <- Eltwise4
I0117 22:13:17.337175  7680 net.cpp:367] ReLU9 -> Eltwise4 (in-place)
I0117 22:13:17.337882  7680 net.cpp:122] Setting up ReLU9
I0117 22:13:17.337896  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.337901  7680 net.cpp:137] Memory required for data: 192750400
I0117 22:13:17.337906  7680 layer_factory.hpp:77] Creating layer Eltwise4_ReLU9_0_split
I0117 22:13:17.337915  7680 net.cpp:84] Creating Layer Eltwise4_ReLU9_0_split
I0117 22:13:17.337920  7680 net.cpp:406] Eltwise4_ReLU9_0_split <- Eltwise4
I0117 22:13:17.337929  7680 net.cpp:380] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_0
I0117 22:13:17.337937  7680 net.cpp:380] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_1
I0117 22:13:17.337945  7680 net.cpp:380] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_2
I0117 22:13:17.337999  7680 net.cpp:122] Setting up Eltwise4_ReLU9_0_split
I0117 22:13:17.338008  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.338014  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.338019  7680 net.cpp:129] Top shape: 100 16 25 25 (1000000)
I0117 22:13:17.338024  7680 net.cpp:137] Memory required for data: 204750400
I0117 22:13:17.338029  7680 layer_factory.hpp:77] Creating layer Convolution10
I0117 22:13:17.338042  7680 net.cpp:84] Creating Layer Convolution10
I0117 22:13:17.338048  7680 net.cpp:406] Convolution10 <- Eltwise4_ReLU9_0_split_0
I0117 22:13:17.338057  7680 net.cpp:380] Convolution10 -> Convolution10
I0117 22:13:17.339721  7680 net.cpp:122] Setting up Convolution10
I0117 22:13:17.339756  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.339762  7680 net.cpp:137] Memory required for data: 206913600
I0117 22:13:17.339784  7680 layer_factory.hpp:77] Creating layer BatchNorm10
I0117 22:13:17.339797  7680 net.cpp:84] Creating Layer BatchNorm10
I0117 22:13:17.339803  7680 net.cpp:406] BatchNorm10 <- Convolution10
I0117 22:13:17.339812  7680 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I0117 22:13:17.340001  7680 net.cpp:122] Setting up BatchNorm10
I0117 22:13:17.340013  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.340018  7680 net.cpp:137] Memory required for data: 209076800
I0117 22:13:17.340029  7680 layer_factory.hpp:77] Creating layer Scale10
I0117 22:13:17.340039  7680 net.cpp:84] Creating Layer Scale10
I0117 22:13:17.340045  7680 net.cpp:406] Scale10 <- Convolution10
I0117 22:13:17.340052  7680 net.cpp:367] Scale10 -> Convolution10 (in-place)
I0117 22:13:17.340100  7680 layer_factory.hpp:77] Creating layer Scale10
I0117 22:13:17.340209  7680 net.cpp:122] Setting up Scale10
I0117 22:13:17.340219  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.340224  7680 net.cpp:137] Memory required for data: 211240000
I0117 22:13:17.340234  7680 layer_factory.hpp:77] Creating layer Convolution11
I0117 22:13:17.340246  7680 net.cpp:84] Creating Layer Convolution11
I0117 22:13:17.340253  7680 net.cpp:406] Convolution11 <- Eltwise4_ReLU9_0_split_1
I0117 22:13:17.340261  7680 net.cpp:380] Convolution11 -> Convolution11
I0117 22:13:17.342666  7680 net.cpp:122] Setting up Convolution11
I0117 22:13:17.342684  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.342689  7680 net.cpp:137] Memory required for data: 213403200
I0117 22:13:17.342700  7680 layer_factory.hpp:77] Creating layer BatchNorm11
I0117 22:13:17.342707  7680 net.cpp:84] Creating Layer BatchNorm11
I0117 22:13:17.342713  7680 net.cpp:406] BatchNorm11 <- Convolution11
I0117 22:13:17.342720  7680 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I0117 22:13:17.342880  7680 net.cpp:122] Setting up BatchNorm11
I0117 22:13:17.342890  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.342895  7680 net.cpp:137] Memory required for data: 215566400
I0117 22:13:17.342903  7680 layer_factory.hpp:77] Creating layer Scale11
I0117 22:13:17.342911  7680 net.cpp:84] Creating Layer Scale11
I0117 22:13:17.342916  7680 net.cpp:406] Scale11 <- Convolution11
I0117 22:13:17.342922  7680 net.cpp:367] Scale11 -> Convolution11 (in-place)
I0117 22:13:17.342959  7680 layer_factory.hpp:77] Creating layer Scale11
I0117 22:13:17.343077  7680 net.cpp:122] Setting up Scale11
I0117 22:13:17.343087  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.343092  7680 net.cpp:137] Memory required for data: 217729600
I0117 22:13:17.343101  7680 layer_factory.hpp:77] Creating layer ReLU10
I0117 22:13:17.343107  7680 net.cpp:84] Creating Layer ReLU10
I0117 22:13:17.343112  7680 net.cpp:406] ReLU10 <- Convolution11
I0117 22:13:17.343118  7680 net.cpp:367] ReLU10 -> Convolution11 (in-place)
I0117 22:13:17.343701  7680 net.cpp:122] Setting up ReLU10
I0117 22:13:17.343713  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.343719  7680 net.cpp:137] Memory required for data: 219892800
I0117 22:13:17.343724  7680 layer_factory.hpp:77] Creating layer Convolution12
I0117 22:13:17.343734  7680 net.cpp:84] Creating Layer Convolution12
I0117 22:13:17.343739  7680 net.cpp:406] Convolution12 <- Convolution11
I0117 22:13:17.343746  7680 net.cpp:380] Convolution12 -> Convolution12
I0117 22:13:17.345949  7680 net.cpp:122] Setting up Convolution12
I0117 22:13:17.345963  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.345968  7680 net.cpp:137] Memory required for data: 222056000
I0117 22:13:17.345976  7680 layer_factory.hpp:77] Creating layer BatchNorm12
I0117 22:13:17.345984  7680 net.cpp:84] Creating Layer BatchNorm12
I0117 22:13:17.345989  7680 net.cpp:406] BatchNorm12 <- Convolution12
I0117 22:13:17.345996  7680 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I0117 22:13:17.346154  7680 net.cpp:122] Setting up BatchNorm12
I0117 22:13:17.346163  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.346168  7680 net.cpp:137] Memory required for data: 224219200
I0117 22:13:17.346177  7680 layer_factory.hpp:77] Creating layer Scale12
I0117 22:13:17.346184  7680 net.cpp:84] Creating Layer Scale12
I0117 22:13:17.346189  7680 net.cpp:406] Scale12 <- Convolution12
I0117 22:13:17.346195  7680 net.cpp:367] Scale12 -> Convolution12 (in-place)
I0117 22:13:17.346230  7680 layer_factory.hpp:77] Creating layer Scale12
I0117 22:13:17.346323  7680 net.cpp:122] Setting up Scale12
I0117 22:13:17.346333  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.346338  7680 net.cpp:137] Memory required for data: 226382400
I0117 22:13:17.346344  7680 layer_factory.hpp:77] Creating layer Eltwise5
I0117 22:13:17.346352  7680 net.cpp:84] Creating Layer Eltwise5
I0117 22:13:17.346359  7680 net.cpp:406] Eltwise5 <- Convolution10
I0117 22:13:17.346364  7680 net.cpp:406] Eltwise5 <- Convolution12
I0117 22:13:17.346370  7680 net.cpp:380] Eltwise5 -> Eltwise5
I0117 22:13:17.346395  7680 net.cpp:122] Setting up Eltwise5
I0117 22:13:17.346402  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.346407  7680 net.cpp:137] Memory required for data: 228545600
I0117 22:13:17.346412  7680 layer_factory.hpp:77] Creating layer ReLU11
I0117 22:13:17.346418  7680 net.cpp:84] Creating Layer ReLU11
I0117 22:13:17.346423  7680 net.cpp:406] ReLU11 <- Eltwise5
I0117 22:13:17.346429  7680 net.cpp:367] ReLU11 -> Eltwise5 (in-place)
I0117 22:13:17.346982  7680 net.cpp:122] Setting up ReLU11
I0117 22:13:17.346994  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.346999  7680 net.cpp:137] Memory required for data: 230708800
I0117 22:13:17.347004  7680 layer_factory.hpp:77] Creating layer Eltwise5_ReLU11_0_split
I0117 22:13:17.347012  7680 net.cpp:84] Creating Layer Eltwise5_ReLU11_0_split
I0117 22:13:17.347017  7680 net.cpp:406] Eltwise5_ReLU11_0_split <- Eltwise5
I0117 22:13:17.347023  7680 net.cpp:380] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_0
I0117 22:13:17.347031  7680 net.cpp:380] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_1
I0117 22:13:17.347067  7680 net.cpp:122] Setting up Eltwise5_ReLU11_0_split
I0117 22:13:17.347076  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.347082  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.347086  7680 net.cpp:137] Memory required for data: 235035200
I0117 22:13:17.347095  7680 layer_factory.hpp:77] Creating layer Convolution13
I0117 22:13:17.347113  7680 net.cpp:84] Creating Layer Convolution13
I0117 22:13:17.347120  7680 net.cpp:406] Convolution13 <- Eltwise5_ReLU11_0_split_0
I0117 22:13:17.347126  7680 net.cpp:380] Convolution13 -> Convolution13
I0117 22:13:17.348659  7680 net.cpp:122] Setting up Convolution13
I0117 22:13:17.348675  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.348680  7680 net.cpp:137] Memory required for data: 237198400
I0117 22:13:17.348687  7680 layer_factory.hpp:77] Creating layer BatchNorm13
I0117 22:13:17.348695  7680 net.cpp:84] Creating Layer BatchNorm13
I0117 22:13:17.348701  7680 net.cpp:406] BatchNorm13 <- Convolution13
I0117 22:13:17.348716  7680 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I0117 22:13:17.348883  7680 net.cpp:122] Setting up BatchNorm13
I0117 22:13:17.348892  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.348896  7680 net.cpp:137] Memory required for data: 239361600
I0117 22:13:17.348906  7680 layer_factory.hpp:77] Creating layer Scale13
I0117 22:13:17.348912  7680 net.cpp:84] Creating Layer Scale13
I0117 22:13:17.348917  7680 net.cpp:406] Scale13 <- Convolution13
I0117 22:13:17.348923  7680 net.cpp:367] Scale13 -> Convolution13 (in-place)
I0117 22:13:17.348959  7680 layer_factory.hpp:77] Creating layer Scale13
I0117 22:13:17.349054  7680 net.cpp:122] Setting up Scale13
I0117 22:13:17.349063  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.349067  7680 net.cpp:137] Memory required for data: 241524800
I0117 22:13:17.349076  7680 layer_factory.hpp:77] Creating layer ReLU12
I0117 22:13:17.349082  7680 net.cpp:84] Creating Layer ReLU12
I0117 22:13:17.349087  7680 net.cpp:406] ReLU12 <- Convolution13
I0117 22:13:17.349093  7680 net.cpp:367] ReLU12 -> Convolution13 (in-place)
I0117 22:13:17.349231  7680 net.cpp:122] Setting up ReLU12
I0117 22:13:17.349241  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.349244  7680 net.cpp:137] Memory required for data: 243688000
I0117 22:13:17.349249  7680 layer_factory.hpp:77] Creating layer Convolution14
I0117 22:13:17.349259  7680 net.cpp:84] Creating Layer Convolution14
I0117 22:13:17.349264  7680 net.cpp:406] Convolution14 <- Convolution13
I0117 22:13:17.349272  7680 net.cpp:380] Convolution14 -> Convolution14
I0117 22:13:17.350797  7680 net.cpp:122] Setting up Convolution14
I0117 22:13:17.350809  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.350816  7680 net.cpp:137] Memory required for data: 245851200
I0117 22:13:17.350831  7680 layer_factory.hpp:77] Creating layer BatchNorm14
I0117 22:13:17.350844  7680 net.cpp:84] Creating Layer BatchNorm14
I0117 22:13:17.350850  7680 net.cpp:406] BatchNorm14 <- Convolution14
I0117 22:13:17.350857  7680 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I0117 22:13:17.351022  7680 net.cpp:122] Setting up BatchNorm14
I0117 22:13:17.351032  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.351037  7680 net.cpp:137] Memory required for data: 248014400
I0117 22:13:17.351045  7680 layer_factory.hpp:77] Creating layer Scale14
I0117 22:13:17.351052  7680 net.cpp:84] Creating Layer Scale14
I0117 22:13:17.351066  7680 net.cpp:406] Scale14 <- Convolution14
I0117 22:13:17.351073  7680 net.cpp:367] Scale14 -> Convolution14 (in-place)
I0117 22:13:17.351107  7680 layer_factory.hpp:77] Creating layer Scale14
I0117 22:13:17.351203  7680 net.cpp:122] Setting up Scale14
I0117 22:13:17.351212  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.351217  7680 net.cpp:137] Memory required for data: 250177600
I0117 22:13:17.351224  7680 layer_factory.hpp:77] Creating layer Eltwise6
I0117 22:13:17.351231  7680 net.cpp:84] Creating Layer Eltwise6
I0117 22:13:17.351236  7680 net.cpp:406] Eltwise6 <- Eltwise5_ReLU11_0_split_1
I0117 22:13:17.351243  7680 net.cpp:406] Eltwise6 <- Convolution14
I0117 22:13:17.351249  7680 net.cpp:380] Eltwise6 -> Eltwise6
I0117 22:13:17.351274  7680 net.cpp:122] Setting up Eltwise6
I0117 22:13:17.351281  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.351290  7680 net.cpp:137] Memory required for data: 252340800
I0117 22:13:17.351301  7680 layer_factory.hpp:77] Creating layer ReLU13
I0117 22:13:17.351308  7680 net.cpp:84] Creating Layer ReLU13
I0117 22:13:17.351313  7680 net.cpp:406] ReLU13 <- Eltwise6
I0117 22:13:17.351320  7680 net.cpp:367] ReLU13 -> Eltwise6 (in-place)
I0117 22:13:17.351881  7680 net.cpp:122] Setting up ReLU13
I0117 22:13:17.351892  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.351897  7680 net.cpp:137] Memory required for data: 254504000
I0117 22:13:17.351902  7680 layer_factory.hpp:77] Creating layer Eltwise6_ReLU13_0_split
I0117 22:13:17.351909  7680 net.cpp:84] Creating Layer Eltwise6_ReLU13_0_split
I0117 22:13:17.351914  7680 net.cpp:406] Eltwise6_ReLU13_0_split <- Eltwise6
I0117 22:13:17.351922  7680 net.cpp:380] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_0
I0117 22:13:17.351929  7680 net.cpp:380] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_1
I0117 22:13:17.351965  7680 net.cpp:122] Setting up Eltwise6_ReLU13_0_split
I0117 22:13:17.351974  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.351979  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.351984  7680 net.cpp:137] Memory required for data: 258830400
I0117 22:13:17.351989  7680 layer_factory.hpp:77] Creating layer Convolution15
I0117 22:13:17.351999  7680 net.cpp:84] Creating Layer Convolution15
I0117 22:13:17.352003  7680 net.cpp:406] Convolution15 <- Eltwise6_ReLU13_0_split_0
I0117 22:13:17.352011  7680 net.cpp:380] Convolution15 -> Convolution15
I0117 22:13:17.353121  7680 net.cpp:122] Setting up Convolution15
I0117 22:13:17.353134  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.353139  7680 net.cpp:137] Memory required for data: 260993600
I0117 22:13:17.353147  7680 layer_factory.hpp:77] Creating layer BatchNorm15
I0117 22:13:17.353155  7680 net.cpp:84] Creating Layer BatchNorm15
I0117 22:13:17.353160  7680 net.cpp:406] BatchNorm15 <- Convolution15
I0117 22:13:17.353168  7680 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I0117 22:13:17.353328  7680 net.cpp:122] Setting up BatchNorm15
I0117 22:13:17.353338  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.353343  7680 net.cpp:137] Memory required for data: 263156800
I0117 22:13:17.353350  7680 layer_factory.hpp:77] Creating layer Scale15
I0117 22:13:17.353358  7680 net.cpp:84] Creating Layer Scale15
I0117 22:13:17.353363  7680 net.cpp:406] Scale15 <- Convolution15
I0117 22:13:17.353368  7680 net.cpp:367] Scale15 -> Convolution15 (in-place)
I0117 22:13:17.353404  7680 layer_factory.hpp:77] Creating layer Scale15
I0117 22:13:17.353502  7680 net.cpp:122] Setting up Scale15
I0117 22:13:17.353512  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.353516  7680 net.cpp:137] Memory required for data: 265320000
I0117 22:13:17.353523  7680 layer_factory.hpp:77] Creating layer ReLU14
I0117 22:13:17.353530  7680 net.cpp:84] Creating Layer ReLU14
I0117 22:13:17.353535  7680 net.cpp:406] ReLU14 <- Convolution15
I0117 22:13:17.353541  7680 net.cpp:367] ReLU14 -> Convolution15 (in-place)
I0117 22:13:17.354074  7680 net.cpp:122] Setting up ReLU14
I0117 22:13:17.354084  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.354089  7680 net.cpp:137] Memory required for data: 267483200
I0117 22:13:17.354094  7680 layer_factory.hpp:77] Creating layer Convolution16
I0117 22:13:17.354104  7680 net.cpp:84] Creating Layer Convolution16
I0117 22:13:17.354110  7680 net.cpp:406] Convolution16 <- Convolution15
I0117 22:13:17.354117  7680 net.cpp:380] Convolution16 -> Convolution16
I0117 22:13:17.355633  7680 net.cpp:122] Setting up Convolution16
I0117 22:13:17.355648  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.355653  7680 net.cpp:137] Memory required for data: 269646400
I0117 22:13:17.355660  7680 layer_factory.hpp:77] Creating layer BatchNorm16
I0117 22:13:17.355669  7680 net.cpp:84] Creating Layer BatchNorm16
I0117 22:13:17.355674  7680 net.cpp:406] BatchNorm16 <- Convolution16
I0117 22:13:17.355685  7680 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I0117 22:13:17.355856  7680 net.cpp:122] Setting up BatchNorm16
I0117 22:13:17.355865  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.355870  7680 net.cpp:137] Memory required for data: 271809600
I0117 22:13:17.355880  7680 layer_factory.hpp:77] Creating layer Scale16
I0117 22:13:17.355886  7680 net.cpp:84] Creating Layer Scale16
I0117 22:13:17.355891  7680 net.cpp:406] Scale16 <- Convolution16
I0117 22:13:17.355897  7680 net.cpp:367] Scale16 -> Convolution16 (in-place)
I0117 22:13:17.355934  7680 layer_factory.hpp:77] Creating layer Scale16
I0117 22:13:17.356034  7680 net.cpp:122] Setting up Scale16
I0117 22:13:17.356042  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.356047  7680 net.cpp:137] Memory required for data: 273972800
I0117 22:13:17.356055  7680 layer_factory.hpp:77] Creating layer Eltwise7
I0117 22:13:17.356061  7680 net.cpp:84] Creating Layer Eltwise7
I0117 22:13:17.356067  7680 net.cpp:406] Eltwise7 <- Eltwise6_ReLU13_0_split_1
I0117 22:13:17.356072  7680 net.cpp:406] Eltwise7 <- Convolution16
I0117 22:13:17.356079  7680 net.cpp:380] Eltwise7 -> Eltwise7
I0117 22:13:17.356103  7680 net.cpp:122] Setting up Eltwise7
I0117 22:13:17.356112  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.356117  7680 net.cpp:137] Memory required for data: 276136000
I0117 22:13:17.356120  7680 layer_factory.hpp:77] Creating layer ReLU15
I0117 22:13:17.356127  7680 net.cpp:84] Creating Layer ReLU15
I0117 22:13:17.356132  7680 net.cpp:406] ReLU15 <- Eltwise7
I0117 22:13:17.356138  7680 net.cpp:367] ReLU15 -> Eltwise7 (in-place)
I0117 22:13:17.356276  7680 net.cpp:122] Setting up ReLU15
I0117 22:13:17.356287  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.356292  7680 net.cpp:137] Memory required for data: 278299200
I0117 22:13:17.356297  7680 layer_factory.hpp:77] Creating layer Eltwise7_ReLU15_0_split
I0117 22:13:17.356303  7680 net.cpp:84] Creating Layer Eltwise7_ReLU15_0_split
I0117 22:13:17.356308  7680 net.cpp:406] Eltwise7_ReLU15_0_split <- Eltwise7
I0117 22:13:17.356314  7680 net.cpp:380] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_0
I0117 22:13:17.356323  7680 net.cpp:380] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_1
I0117 22:13:17.356359  7680 net.cpp:122] Setting up Eltwise7_ReLU15_0_split
I0117 22:13:17.356366  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.356372  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.356377  7680 net.cpp:137] Memory required for data: 282625600
I0117 22:13:17.356381  7680 layer_factory.hpp:77] Creating layer Convolution17
I0117 22:13:17.356391  7680 net.cpp:84] Creating Layer Convolution17
I0117 22:13:17.356396  7680 net.cpp:406] Convolution17 <- Eltwise7_ReLU15_0_split_0
I0117 22:13:17.356405  7680 net.cpp:380] Convolution17 -> Convolution17
I0117 22:13:17.358686  7680 net.cpp:122] Setting up Convolution17
I0117 22:13:17.358700  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.358705  7680 net.cpp:137] Memory required for data: 284788800
I0117 22:13:17.358712  7680 layer_factory.hpp:77] Creating layer BatchNorm17
I0117 22:13:17.358721  7680 net.cpp:84] Creating Layer BatchNorm17
I0117 22:13:17.358726  7680 net.cpp:406] BatchNorm17 <- Convolution17
I0117 22:13:17.358732  7680 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I0117 22:13:17.358899  7680 net.cpp:122] Setting up BatchNorm17
I0117 22:13:17.358909  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.358913  7680 net.cpp:137] Memory required for data: 286952000
I0117 22:13:17.358922  7680 layer_factory.hpp:77] Creating layer Scale17
I0117 22:13:17.358929  7680 net.cpp:84] Creating Layer Scale17
I0117 22:13:17.358934  7680 net.cpp:406] Scale17 <- Convolution17
I0117 22:13:17.358940  7680 net.cpp:367] Scale17 -> Convolution17 (in-place)
I0117 22:13:17.358978  7680 layer_factory.hpp:77] Creating layer Scale17
I0117 22:13:17.359093  7680 net.cpp:122] Setting up Scale17
I0117 22:13:17.359107  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.359117  7680 net.cpp:137] Memory required for data: 289115200
I0117 22:13:17.359124  7680 layer_factory.hpp:77] Creating layer ReLU16
I0117 22:13:17.359130  7680 net.cpp:84] Creating Layer ReLU16
I0117 22:13:17.359136  7680 net.cpp:406] ReLU16 <- Convolution17
I0117 22:13:17.359143  7680 net.cpp:367] ReLU16 -> Convolution17 (in-place)
I0117 22:13:17.359710  7680 net.cpp:122] Setting up ReLU16
I0117 22:13:17.359722  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.359727  7680 net.cpp:137] Memory required for data: 291278400
I0117 22:13:17.359733  7680 layer_factory.hpp:77] Creating layer Convolution18
I0117 22:13:17.359743  7680 net.cpp:84] Creating Layer Convolution18
I0117 22:13:17.359748  7680 net.cpp:406] Convolution18 <- Convolution17
I0117 22:13:17.359756  7680 net.cpp:380] Convolution18 -> Convolution18
I0117 22:13:17.360865  7680 net.cpp:122] Setting up Convolution18
I0117 22:13:17.360877  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.360882  7680 net.cpp:137] Memory required for data: 293441600
I0117 22:13:17.360890  7680 layer_factory.hpp:77] Creating layer BatchNorm18
I0117 22:13:17.360898  7680 net.cpp:84] Creating Layer BatchNorm18
I0117 22:13:17.360903  7680 net.cpp:406] BatchNorm18 <- Convolution18
I0117 22:13:17.360909  7680 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I0117 22:13:17.361078  7680 net.cpp:122] Setting up BatchNorm18
I0117 22:13:17.361088  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.361093  7680 net.cpp:137] Memory required for data: 295604800
I0117 22:13:17.361101  7680 layer_factory.hpp:77] Creating layer Scale18
I0117 22:13:17.361109  7680 net.cpp:84] Creating Layer Scale18
I0117 22:13:17.361114  7680 net.cpp:406] Scale18 <- Convolution18
I0117 22:13:17.361119  7680 net.cpp:367] Scale18 -> Convolution18 (in-place)
I0117 22:13:17.361156  7680 layer_factory.hpp:77] Creating layer Scale18
I0117 22:13:17.361256  7680 net.cpp:122] Setting up Scale18
I0117 22:13:17.361265  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.361270  7680 net.cpp:137] Memory required for data: 297768000
I0117 22:13:17.361277  7680 layer_factory.hpp:77] Creating layer Eltwise8
I0117 22:13:17.361285  7680 net.cpp:84] Creating Layer Eltwise8
I0117 22:13:17.361290  7680 net.cpp:406] Eltwise8 <- Eltwise7_ReLU15_0_split_1
I0117 22:13:17.361296  7680 net.cpp:406] Eltwise8 <- Convolution18
I0117 22:13:17.361302  7680 net.cpp:380] Eltwise8 -> Eltwise8
I0117 22:13:17.361326  7680 net.cpp:122] Setting up Eltwise8
I0117 22:13:17.361335  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.361340  7680 net.cpp:137] Memory required for data: 299931200
I0117 22:13:17.361344  7680 layer_factory.hpp:77] Creating layer ReLU17
I0117 22:13:17.361351  7680 net.cpp:84] Creating Layer ReLU17
I0117 22:13:17.361356  7680 net.cpp:406] ReLU17 <- Eltwise8
I0117 22:13:17.361362  7680 net.cpp:367] ReLU17 -> Eltwise8 (in-place)
I0117 22:13:17.361901  7680 net.cpp:122] Setting up ReLU17
I0117 22:13:17.361912  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.361917  7680 net.cpp:137] Memory required for data: 302094400
I0117 22:13:17.361922  7680 layer_factory.hpp:77] Creating layer Eltwise8_ReLU17_0_split
I0117 22:13:17.361929  7680 net.cpp:84] Creating Layer Eltwise8_ReLU17_0_split
I0117 22:13:17.361934  7680 net.cpp:406] Eltwise8_ReLU17_0_split <- Eltwise8
I0117 22:13:17.361941  7680 net.cpp:380] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_0
I0117 22:13:17.361950  7680 net.cpp:380] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_1
I0117 22:13:17.361958  7680 net.cpp:380] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_2
I0117 22:13:17.362006  7680 net.cpp:122] Setting up Eltwise8_ReLU17_0_split
I0117 22:13:17.362015  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.362020  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.362026  7680 net.cpp:129] Top shape: 100 32 13 13 (540800)
I0117 22:13:17.362031  7680 net.cpp:137] Memory required for data: 308584000
I0117 22:13:17.362045  7680 layer_factory.hpp:77] Creating layer Convolution19
I0117 22:13:17.362054  7680 net.cpp:84] Creating Layer Convolution19
I0117 22:13:17.362059  7680 net.cpp:406] Convolution19 <- Eltwise8_ReLU17_0_split_0
I0117 22:13:17.362067  7680 net.cpp:380] Convolution19 -> Convolution19
I0117 22:13:17.363574  7680 net.cpp:122] Setting up Convolution19
I0117 22:13:17.363587  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.363592  7680 net.cpp:137] Memory required for data: 309838400
I0117 22:13:17.363600  7680 layer_factory.hpp:77] Creating layer BatchNorm19
I0117 22:13:17.363610  7680 net.cpp:84] Creating Layer BatchNorm19
I0117 22:13:17.363615  7680 net.cpp:406] BatchNorm19 <- Convolution19
I0117 22:13:17.363622  7680 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I0117 22:13:17.363798  7680 net.cpp:122] Setting up BatchNorm19
I0117 22:13:17.363807  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.363812  7680 net.cpp:137] Memory required for data: 311092800
I0117 22:13:17.363832  7680 layer_factory.hpp:77] Creating layer Scale19
I0117 22:13:17.363840  7680 net.cpp:84] Creating Layer Scale19
I0117 22:13:17.363845  7680 net.cpp:406] Scale19 <- Convolution19
I0117 22:13:17.363852  7680 net.cpp:367] Scale19 -> Convolution19 (in-place)
I0117 22:13:17.363893  7680 layer_factory.hpp:77] Creating layer Scale19
I0117 22:13:17.364015  7680 net.cpp:122] Setting up Scale19
I0117 22:13:17.364024  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.364029  7680 net.cpp:137] Memory required for data: 312347200
I0117 22:13:17.364045  7680 layer_factory.hpp:77] Creating layer Convolution20
I0117 22:13:17.364056  7680 net.cpp:84] Creating Layer Convolution20
I0117 22:13:17.364063  7680 net.cpp:406] Convolution20 <- Eltwise8_ReLU17_0_split_1
I0117 22:13:17.364079  7680 net.cpp:380] Convolution20 -> Convolution20
I0117 22:13:17.366047  7680 net.cpp:122] Setting up Convolution20
I0117 22:13:17.366060  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.366066  7680 net.cpp:137] Memory required for data: 313601600
I0117 22:13:17.366073  7680 layer_factory.hpp:77] Creating layer BatchNorm20
I0117 22:13:17.366082  7680 net.cpp:84] Creating Layer BatchNorm20
I0117 22:13:17.366088  7680 net.cpp:406] BatchNorm20 <- Convolution20
I0117 22:13:17.366096  7680 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I0117 22:13:17.366276  7680 net.cpp:122] Setting up BatchNorm20
I0117 22:13:17.366286  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.366291  7680 net.cpp:137] Memory required for data: 314856000
I0117 22:13:17.366299  7680 layer_factory.hpp:77] Creating layer Scale20
I0117 22:13:17.366307  7680 net.cpp:84] Creating Layer Scale20
I0117 22:13:17.366312  7680 net.cpp:406] Scale20 <- Convolution20
I0117 22:13:17.366318  7680 net.cpp:367] Scale20 -> Convolution20 (in-place)
I0117 22:13:17.366358  7680 layer_factory.hpp:77] Creating layer Scale20
I0117 22:13:17.366467  7680 net.cpp:122] Setting up Scale20
I0117 22:13:17.366478  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.366483  7680 net.cpp:137] Memory required for data: 316110400
I0117 22:13:17.366490  7680 layer_factory.hpp:77] Creating layer ReLU18
I0117 22:13:17.366497  7680 net.cpp:84] Creating Layer ReLU18
I0117 22:13:17.366503  7680 net.cpp:406] ReLU18 <- Convolution20
I0117 22:13:17.366508  7680 net.cpp:367] ReLU18 -> Convolution20 (in-place)
I0117 22:13:17.366657  7680 net.cpp:122] Setting up ReLU18
I0117 22:13:17.366668  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.366673  7680 net.cpp:137] Memory required for data: 317364800
I0117 22:13:17.366678  7680 layer_factory.hpp:77] Creating layer Convolution21
I0117 22:13:17.366688  7680 net.cpp:84] Creating Layer Convolution21
I0117 22:13:17.366694  7680 net.cpp:406] Convolution21 <- Convolution20
I0117 22:13:17.366701  7680 net.cpp:380] Convolution21 -> Convolution21
I0117 22:13:17.368918  7680 net.cpp:122] Setting up Convolution21
I0117 22:13:17.368932  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.368947  7680 net.cpp:137] Memory required for data: 318619200
I0117 22:13:17.368957  7680 layer_factory.hpp:77] Creating layer BatchNorm21
I0117 22:13:17.368963  7680 net.cpp:84] Creating Layer BatchNorm21
I0117 22:13:17.368968  7680 net.cpp:406] BatchNorm21 <- Convolution21
I0117 22:13:17.368976  7680 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I0117 22:13:17.369159  7680 net.cpp:122] Setting up BatchNorm21
I0117 22:13:17.369168  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.369174  7680 net.cpp:137] Memory required for data: 319873600
I0117 22:13:17.369181  7680 layer_factory.hpp:77] Creating layer Scale21
I0117 22:13:17.369189  7680 net.cpp:84] Creating Layer Scale21
I0117 22:13:17.369194  7680 net.cpp:406] Scale21 <- Convolution21
I0117 22:13:17.369200  7680 net.cpp:367] Scale21 -> Convolution21 (in-place)
I0117 22:13:17.369240  7680 layer_factory.hpp:77] Creating layer Scale21
I0117 22:13:17.369348  7680 net.cpp:122] Setting up Scale21
I0117 22:13:17.369359  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.369364  7680 net.cpp:137] Memory required for data: 321128000
I0117 22:13:17.369370  7680 layer_factory.hpp:77] Creating layer Eltwise9
I0117 22:13:17.369379  7680 net.cpp:84] Creating Layer Eltwise9
I0117 22:13:17.369384  7680 net.cpp:406] Eltwise9 <- Convolution19
I0117 22:13:17.369388  7680 net.cpp:406] Eltwise9 <- Convolution21
I0117 22:13:17.369395  7680 net.cpp:380] Eltwise9 -> Eltwise9
I0117 22:13:17.369421  7680 net.cpp:122] Setting up Eltwise9
I0117 22:13:17.369431  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.369436  7680 net.cpp:137] Memory required for data: 322382400
I0117 22:13:17.369439  7680 layer_factory.hpp:77] Creating layer ReLU19
I0117 22:13:17.369447  7680 net.cpp:84] Creating Layer ReLU19
I0117 22:13:17.369452  7680 net.cpp:406] ReLU19 <- Eltwise9
I0117 22:13:17.369458  7680 net.cpp:367] ReLU19 -> Eltwise9 (in-place)
I0117 22:13:17.369616  7680 net.cpp:122] Setting up ReLU19
I0117 22:13:17.369626  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.369632  7680 net.cpp:137] Memory required for data: 323636800
I0117 22:13:17.369637  7680 layer_factory.hpp:77] Creating layer Eltwise9_ReLU19_0_split
I0117 22:13:17.369643  7680 net.cpp:84] Creating Layer Eltwise9_ReLU19_0_split
I0117 22:13:17.369648  7680 net.cpp:406] Eltwise9_ReLU19_0_split <- Eltwise9
I0117 22:13:17.369655  7680 net.cpp:380] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_0
I0117 22:13:17.369665  7680 net.cpp:380] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_1
I0117 22:13:17.369704  7680 net.cpp:122] Setting up Eltwise9_ReLU19_0_split
I0117 22:13:17.369714  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.369719  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.369724  7680 net.cpp:137] Memory required for data: 326145600
I0117 22:13:17.369729  7680 layer_factory.hpp:77] Creating layer Convolution22
I0117 22:13:17.369740  7680 net.cpp:84] Creating Layer Convolution22
I0117 22:13:17.369745  7680 net.cpp:406] Convolution22 <- Eltwise9_ReLU19_0_split_0
I0117 22:13:17.369753  7680 net.cpp:380] Convolution22 -> Convolution22
I0117 22:13:17.371970  7680 net.cpp:122] Setting up Convolution22
I0117 22:13:17.371984  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.371989  7680 net.cpp:137] Memory required for data: 327400000
I0117 22:13:17.371996  7680 layer_factory.hpp:77] Creating layer BatchNorm22
I0117 22:13:17.372005  7680 net.cpp:84] Creating Layer BatchNorm22
I0117 22:13:17.372011  7680 net.cpp:406] BatchNorm22 <- Convolution22
I0117 22:13:17.372017  7680 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I0117 22:13:17.372201  7680 net.cpp:122] Setting up BatchNorm22
I0117 22:13:17.372211  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.372215  7680 net.cpp:137] Memory required for data: 328654400
I0117 22:13:17.372225  7680 layer_factory.hpp:77] Creating layer Scale22
I0117 22:13:17.372233  7680 net.cpp:84] Creating Layer Scale22
I0117 22:13:17.372242  7680 net.cpp:406] Scale22 <- Convolution22
I0117 22:13:17.372254  7680 net.cpp:367] Scale22 -> Convolution22 (in-place)
I0117 22:13:17.372294  7680 layer_factory.hpp:77] Creating layer Scale22
I0117 22:13:17.372404  7680 net.cpp:122] Setting up Scale22
I0117 22:13:17.372414  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.372418  7680 net.cpp:137] Memory required for data: 329908800
I0117 22:13:17.372426  7680 layer_factory.hpp:77] Creating layer ReLU20
I0117 22:13:17.372434  7680 net.cpp:84] Creating Layer ReLU20
I0117 22:13:17.372439  7680 net.cpp:406] ReLU20 <- Convolution22
I0117 22:13:17.372445  7680 net.cpp:367] ReLU20 -> Convolution22 (in-place)
I0117 22:13:17.373016  7680 net.cpp:122] Setting up ReLU20
I0117 22:13:17.373037  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.373042  7680 net.cpp:137] Memory required for data: 331163200
I0117 22:13:17.373047  7680 layer_factory.hpp:77] Creating layer Convolution23
I0117 22:13:17.373059  7680 net.cpp:84] Creating Layer Convolution23
I0117 22:13:17.373065  7680 net.cpp:406] Convolution23 <- Convolution22
I0117 22:13:17.373082  7680 net.cpp:380] Convolution23 -> Convolution23
I0117 22:13:17.375509  7680 net.cpp:122] Setting up Convolution23
I0117 22:13:17.375545  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.375552  7680 net.cpp:137] Memory required for data: 332417600
I0117 22:13:17.375563  7680 layer_factory.hpp:77] Creating layer BatchNorm23
I0117 22:13:17.375574  7680 net.cpp:84] Creating Layer BatchNorm23
I0117 22:13:17.375581  7680 net.cpp:406] BatchNorm23 <- Convolution23
I0117 22:13:17.375589  7680 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I0117 22:13:17.375800  7680 net.cpp:122] Setting up BatchNorm23
I0117 22:13:17.375813  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.375818  7680 net.cpp:137] Memory required for data: 333672000
I0117 22:13:17.375828  7680 layer_factory.hpp:77] Creating layer Scale23
I0117 22:13:17.375838  7680 net.cpp:84] Creating Layer Scale23
I0117 22:13:17.375844  7680 net.cpp:406] Scale23 <- Convolution23
I0117 22:13:17.375851  7680 net.cpp:367] Scale23 -> Convolution23 (in-place)
I0117 22:13:17.375901  7680 layer_factory.hpp:77] Creating layer Scale23
I0117 22:13:17.376030  7680 net.cpp:122] Setting up Scale23
I0117 22:13:17.376042  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.376047  7680 net.cpp:137] Memory required for data: 334926400
I0117 22:13:17.376055  7680 layer_factory.hpp:77] Creating layer Eltwise10
I0117 22:13:17.376065  7680 net.cpp:84] Creating Layer Eltwise10
I0117 22:13:17.376070  7680 net.cpp:406] Eltwise10 <- Eltwise9_ReLU19_0_split_1
I0117 22:13:17.376078  7680 net.cpp:406] Eltwise10 <- Convolution23
I0117 22:13:17.376086  7680 net.cpp:380] Eltwise10 -> Eltwise10
I0117 22:13:17.376128  7680 net.cpp:122] Setting up Eltwise10
I0117 22:13:17.376139  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.376144  7680 net.cpp:137] Memory required for data: 336180800
I0117 22:13:17.376149  7680 layer_factory.hpp:77] Creating layer ReLU21
I0117 22:13:17.376157  7680 net.cpp:84] Creating Layer ReLU21
I0117 22:13:17.376163  7680 net.cpp:406] ReLU21 <- Eltwise10
I0117 22:13:17.376169  7680 net.cpp:367] ReLU21 -> Eltwise10 (in-place)
I0117 22:13:17.376355  7680 net.cpp:122] Setting up ReLU21
I0117 22:13:17.376368  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.376372  7680 net.cpp:137] Memory required for data: 337435200
I0117 22:13:17.376377  7680 layer_factory.hpp:77] Creating layer Eltwise10_ReLU21_0_split
I0117 22:13:17.376385  7680 net.cpp:84] Creating Layer Eltwise10_ReLU21_0_split
I0117 22:13:17.376390  7680 net.cpp:406] Eltwise10_ReLU21_0_split <- Eltwise10
I0117 22:13:17.376399  7680 net.cpp:380] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_0
I0117 22:13:17.376408  7680 net.cpp:380] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_1
I0117 22:13:17.376452  7680 net.cpp:122] Setting up Eltwise10_ReLU21_0_split
I0117 22:13:17.376461  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.376476  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.376487  7680 net.cpp:137] Memory required for data: 339944000
I0117 22:13:17.376493  7680 layer_factory.hpp:77] Creating layer Convolution24
I0117 22:13:17.376507  7680 net.cpp:84] Creating Layer Convolution24
I0117 22:13:17.376513  7680 net.cpp:406] Convolution24 <- Eltwise10_ReLU21_0_split_0
I0117 22:13:17.376523  7680 net.cpp:380] Convolution24 -> Convolution24
I0117 22:13:17.379057  7680 net.cpp:122] Setting up Convolution24
I0117 22:13:17.379097  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.379106  7680 net.cpp:137] Memory required for data: 341198400
I0117 22:13:17.379118  7680 layer_factory.hpp:77] Creating layer BatchNorm24
I0117 22:13:17.379132  7680 net.cpp:84] Creating Layer BatchNorm24
I0117 22:13:17.379138  7680 net.cpp:406] BatchNorm24 <- Convolution24
I0117 22:13:17.379148  7680 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I0117 22:13:17.379380  7680 net.cpp:122] Setting up BatchNorm24
I0117 22:13:17.379403  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.379410  7680 net.cpp:137] Memory required for data: 342452800
I0117 22:13:17.379428  7680 layer_factory.hpp:77] Creating layer Scale24
I0117 22:13:17.379437  7680 net.cpp:84] Creating Layer Scale24
I0117 22:13:17.379443  7680 net.cpp:406] Scale24 <- Convolution24
I0117 22:13:17.379453  7680 net.cpp:367] Scale24 -> Convolution24 (in-place)
I0117 22:13:17.379504  7680 layer_factory.hpp:77] Creating layer Scale24
I0117 22:13:17.379637  7680 net.cpp:122] Setting up Scale24
I0117 22:13:17.379648  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.379653  7680 net.cpp:137] Memory required for data: 343707200
I0117 22:13:17.379662  7680 layer_factory.hpp:77] Creating layer ReLU22
I0117 22:13:17.379670  7680 net.cpp:84] Creating Layer ReLU22
I0117 22:13:17.379675  7680 net.cpp:406] ReLU22 <- Convolution24
I0117 22:13:17.379683  7680 net.cpp:367] ReLU22 -> Convolution24 (in-place)
I0117 22:13:17.379876  7680 net.cpp:122] Setting up ReLU22
I0117 22:13:17.379887  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.379892  7680 net.cpp:137] Memory required for data: 344961600
I0117 22:13:17.379899  7680 layer_factory.hpp:77] Creating layer Convolution25
I0117 22:13:17.379912  7680 net.cpp:84] Creating Layer Convolution25
I0117 22:13:17.379918  7680 net.cpp:406] Convolution25 <- Convolution24
I0117 22:13:17.379928  7680 net.cpp:380] Convolution25 -> Convolution25
I0117 22:13:17.382905  7680 net.cpp:122] Setting up Convolution25
I0117 22:13:17.382942  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.382949  7680 net.cpp:137] Memory required for data: 346216000
I0117 22:13:17.382962  7680 layer_factory.hpp:77] Creating layer BatchNorm25
I0117 22:13:17.382977  7680 net.cpp:84] Creating Layer BatchNorm25
I0117 22:13:17.382984  7680 net.cpp:406] BatchNorm25 <- Convolution25
I0117 22:13:17.382993  7680 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I0117 22:13:17.383226  7680 net.cpp:122] Setting up BatchNorm25
I0117 22:13:17.383239  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.383244  7680 net.cpp:137] Memory required for data: 347470400
I0117 22:13:17.383253  7680 layer_factory.hpp:77] Creating layer Scale25
I0117 22:13:17.383263  7680 net.cpp:84] Creating Layer Scale25
I0117 22:13:17.383270  7680 net.cpp:406] Scale25 <- Convolution25
I0117 22:13:17.383276  7680 net.cpp:367] Scale25 -> Convolution25 (in-place)
I0117 22:13:17.383323  7680 layer_factory.hpp:77] Creating layer Scale25
I0117 22:13:17.383455  7680 net.cpp:122] Setting up Scale25
I0117 22:13:17.383466  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.383471  7680 net.cpp:137] Memory required for data: 348724800
I0117 22:13:17.383477  7680 layer_factory.hpp:77] Creating layer Eltwise11
I0117 22:13:17.383491  7680 net.cpp:84] Creating Layer Eltwise11
I0117 22:13:17.383497  7680 net.cpp:406] Eltwise11 <- Eltwise10_ReLU21_0_split_1
I0117 22:13:17.383503  7680 net.cpp:406] Eltwise11 <- Convolution25
I0117 22:13:17.383518  7680 net.cpp:380] Eltwise11 -> Eltwise11
I0117 22:13:17.383563  7680 net.cpp:122] Setting up Eltwise11
I0117 22:13:17.383572  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.383577  7680 net.cpp:137] Memory required for data: 349979200
I0117 22:13:17.383581  7680 layer_factory.hpp:77] Creating layer ReLU23
I0117 22:13:17.383589  7680 net.cpp:84] Creating Layer ReLU23
I0117 22:13:17.383594  7680 net.cpp:406] ReLU23 <- Eltwise11
I0117 22:13:17.383610  7680 net.cpp:367] ReLU23 -> Eltwise11 (in-place)
I0117 22:13:17.384250  7680 net.cpp:122] Setting up ReLU23
I0117 22:13:17.384266  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.384272  7680 net.cpp:137] Memory required for data: 351233600
I0117 22:13:17.384277  7680 layer_factory.hpp:77] Creating layer Eltwise11_ReLU23_0_split
I0117 22:13:17.384286  7680 net.cpp:84] Creating Layer Eltwise11_ReLU23_0_split
I0117 22:13:17.384291  7680 net.cpp:406] Eltwise11_ReLU23_0_split <- Eltwise11
I0117 22:13:17.384300  7680 net.cpp:380] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_0
I0117 22:13:17.384310  7680 net.cpp:380] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_1
I0117 22:13:17.384358  7680 net.cpp:122] Setting up Eltwise11_ReLU23_0_split
I0117 22:13:17.384368  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.384374  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.384379  7680 net.cpp:137] Memory required for data: 353742400
I0117 22:13:17.384384  7680 layer_factory.hpp:77] Creating layer Convolution26
I0117 22:13:17.384398  7680 net.cpp:84] Creating Layer Convolution26
I0117 22:13:17.384413  7680 net.cpp:406] Convolution26 <- Eltwise11_ReLU23_0_split_0
I0117 22:13:17.384423  7680 net.cpp:380] Convolution26 -> Convolution26
I0117 22:13:17.386962  7680 net.cpp:122] Setting up Convolution26
I0117 22:13:17.387002  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.387010  7680 net.cpp:137] Memory required for data: 354996800
I0117 22:13:17.387022  7680 layer_factory.hpp:77] Creating layer BatchNorm26
I0117 22:13:17.387035  7680 net.cpp:84] Creating Layer BatchNorm26
I0117 22:13:17.387043  7680 net.cpp:406] BatchNorm26 <- Convolution26
I0117 22:13:17.387053  7680 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I0117 22:13:17.387280  7680 net.cpp:122] Setting up BatchNorm26
I0117 22:13:17.387293  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.387298  7680 net.cpp:137] Memory required for data: 356251200
I0117 22:13:17.387310  7680 layer_factory.hpp:77] Creating layer Scale26
I0117 22:13:17.387320  7680 net.cpp:84] Creating Layer Scale26
I0117 22:13:17.387326  7680 net.cpp:406] Scale26 <- Convolution26
I0117 22:13:17.387332  7680 net.cpp:367] Scale26 -> Convolution26 (in-place)
I0117 22:13:17.387384  7680 layer_factory.hpp:77] Creating layer Scale26
I0117 22:13:17.387531  7680 net.cpp:122] Setting up Scale26
I0117 22:13:17.387543  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.387548  7680 net.cpp:137] Memory required for data: 357505600
I0117 22:13:17.387557  7680 layer_factory.hpp:77] Creating layer ReLU24
I0117 22:13:17.387565  7680 net.cpp:84] Creating Layer ReLU24
I0117 22:13:17.387570  7680 net.cpp:406] ReLU24 <- Convolution26
I0117 22:13:17.387578  7680 net.cpp:367] ReLU24 -> Convolution26 (in-place)
I0117 22:13:17.387781  7680 net.cpp:122] Setting up ReLU24
I0117 22:13:17.387794  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.387799  7680 net.cpp:137] Memory required for data: 358760000
I0117 22:13:17.387804  7680 layer_factory.hpp:77] Creating layer Convolution27
I0117 22:13:17.387817  7680 net.cpp:84] Creating Layer Convolution27
I0117 22:13:17.387823  7680 net.cpp:406] Convolution27 <- Convolution26
I0117 22:13:17.387831  7680 net.cpp:380] Convolution27 -> Convolution27
I0117 22:13:17.390751  7680 net.cpp:122] Setting up Convolution27
I0117 22:13:17.390789  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.390794  7680 net.cpp:137] Memory required for data: 360014400
I0117 22:13:17.390813  7680 layer_factory.hpp:77] Creating layer BatchNorm27
I0117 22:13:17.390832  7680 net.cpp:84] Creating Layer BatchNorm27
I0117 22:13:17.390839  7680 net.cpp:406] BatchNorm27 <- Convolution27
I0117 22:13:17.390849  7680 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I0117 22:13:17.391082  7680 net.cpp:122] Setting up BatchNorm27
I0117 22:13:17.391110  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.391115  7680 net.cpp:137] Memory required for data: 361268800
I0117 22:13:17.391125  7680 layer_factory.hpp:77] Creating layer Scale27
I0117 22:13:17.391147  7680 net.cpp:84] Creating Layer Scale27
I0117 22:13:17.391153  7680 net.cpp:406] Scale27 <- Convolution27
I0117 22:13:17.391160  7680 net.cpp:367] Scale27 -> Convolution27 (in-place)
I0117 22:13:17.391217  7680 layer_factory.hpp:77] Creating layer Scale27
I0117 22:13:17.391346  7680 net.cpp:122] Setting up Scale27
I0117 22:13:17.391357  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.391361  7680 net.cpp:137] Memory required for data: 362523200
I0117 22:13:17.391371  7680 layer_factory.hpp:77] Creating layer Eltwise12
I0117 22:13:17.391378  7680 net.cpp:84] Creating Layer Eltwise12
I0117 22:13:17.391384  7680 net.cpp:406] Eltwise12 <- Eltwise11_ReLU23_0_split_1
I0117 22:13:17.391400  7680 net.cpp:406] Eltwise12 <- Convolution27
I0117 22:13:17.391409  7680 net.cpp:380] Eltwise12 -> Eltwise12
I0117 22:13:17.391440  7680 net.cpp:122] Setting up Eltwise12
I0117 22:13:17.391451  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.391456  7680 net.cpp:137] Memory required for data: 363777600
I0117 22:13:17.391460  7680 layer_factory.hpp:77] Creating layer Convolution_eltwise4
I0117 22:13:17.391474  7680 net.cpp:84] Creating Layer Convolution_eltwise4
I0117 22:13:17.391480  7680 net.cpp:406] Convolution_eltwise4 <- Eltwise4_ReLU9_0_split_2
I0117 22:13:17.391489  7680 net.cpp:380] Convolution_eltwise4 -> Convolution_eltwise4
I0117 22:13:17.393400  7680 net.cpp:122] Setting up Convolution_eltwise4
I0117 22:13:17.393435  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.393440  7680 net.cpp:137] Memory required for data: 365032000
I0117 22:13:17.393451  7680 layer_factory.hpp:77] Creating layer BatchNorm_Convolution_eltwise4
I0117 22:13:17.393463  7680 net.cpp:84] Creating Layer BatchNorm_Convolution_eltwise4
I0117 22:13:17.393471  7680 net.cpp:406] BatchNorm_Convolution_eltwise4 <- Convolution_eltwise4
I0117 22:13:17.393479  7680 net.cpp:367] BatchNorm_Convolution_eltwise4 -> Convolution_eltwise4 (in-place)
I0117 22:13:17.393694  7680 net.cpp:122] Setting up BatchNorm_Convolution_eltwise4
I0117 22:13:17.393707  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.393712  7680 net.cpp:137] Memory required for data: 366286400
I0117 22:13:17.393720  7680 layer_factory.hpp:77] Creating layer Scale_Convolution_eltwise4
I0117 22:13:17.393731  7680 net.cpp:84] Creating Layer Scale_Convolution_eltwise4
I0117 22:13:17.393736  7680 net.cpp:406] Scale_Convolution_eltwise4 <- Convolution_eltwise4
I0117 22:13:17.393743  7680 net.cpp:367] Scale_Convolution_eltwise4 -> Convolution_eltwise4 (in-place)
I0117 22:13:17.393792  7680 layer_factory.hpp:77] Creating layer Scale_Convolution_eltwise4
I0117 22:13:17.393923  7680 net.cpp:122] Setting up Scale_Convolution_eltwise4
I0117 22:13:17.393932  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.393937  7680 net.cpp:137] Memory required for data: 367540800
I0117 22:13:17.393945  7680 layer_factory.hpp:77] Creating layer Convolution_eltwise8
I0117 22:13:17.393959  7680 net.cpp:84] Creating Layer Convolution_eltwise8
I0117 22:13:17.393965  7680 net.cpp:406] Convolution_eltwise8 <- Eltwise8_ReLU17_0_split_2
I0117 22:13:17.393973  7680 net.cpp:380] Convolution_eltwise8 -> Convolution_eltwise8
I0117 22:13:17.395923  7680 net.cpp:122] Setting up Convolution_eltwise8
I0117 22:13:17.395959  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.395965  7680 net.cpp:137] Memory required for data: 368795200
I0117 22:13:17.395977  7680 layer_factory.hpp:77] Creating layer BatchNorm_Convolution_eltwise8
I0117 22:13:17.396003  7680 net.cpp:84] Creating Layer BatchNorm_Convolution_eltwise8
I0117 22:13:17.396009  7680 net.cpp:406] BatchNorm_Convolution_eltwise8 <- Convolution_eltwise8
I0117 22:13:17.396018  7680 net.cpp:367] BatchNorm_Convolution_eltwise8 -> Convolution_eltwise8 (in-place)
I0117 22:13:17.396232  7680 net.cpp:122] Setting up BatchNorm_Convolution_eltwise8
I0117 22:13:17.396244  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.396248  7680 net.cpp:137] Memory required for data: 370049600
I0117 22:13:17.396258  7680 layer_factory.hpp:77] Creating layer Scale_Convolution_eltwise8
I0117 22:13:17.396268  7680 net.cpp:84] Creating Layer Scale_Convolution_eltwise8
I0117 22:13:17.396275  7680 net.cpp:406] Scale_Convolution_eltwise8 <- Convolution_eltwise8
I0117 22:13:17.396281  7680 net.cpp:367] Scale_Convolution_eltwise8 -> Convolution_eltwise8 (in-place)
I0117 22:13:17.396330  7680 layer_factory.hpp:77] Creating layer Scale_Convolution_eltwise8
I0117 22:13:17.396476  7680 net.cpp:122] Setting up Scale_Convolution_eltwise8
I0117 22:13:17.396486  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.396490  7680 net.cpp:137] Memory required for data: 371304000
I0117 22:13:17.396497  7680 layer_factory.hpp:77] Creating layer fuse1
I0117 22:13:17.396507  7680 net.cpp:84] Creating Layer fuse1
I0117 22:13:17.396512  7680 net.cpp:406] fuse1 <- Convolution_eltwise4
I0117 22:13:17.396518  7680 net.cpp:406] fuse1 <- Convolution_eltwise8
I0117 22:13:17.396525  7680 net.cpp:380] fuse1 -> fuse1
I0117 22:13:17.396558  7680 net.cpp:122] Setting up fuse1
I0117 22:13:17.396566  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.396571  7680 net.cpp:137] Memory required for data: 372558400
I0117 22:13:17.396576  7680 layer_factory.hpp:77] Creating layer fuse2
I0117 22:13:17.396584  7680 net.cpp:84] Creating Layer fuse2
I0117 22:13:17.396589  7680 net.cpp:406] fuse2 <- fuse1
I0117 22:13:17.396595  7680 net.cpp:406] fuse2 <- Eltwise12
I0117 22:13:17.396602  7680 net.cpp:380] fuse2 -> fuse2
I0117 22:13:17.396628  7680 net.cpp:122] Setting up fuse2
I0117 22:13:17.396637  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.396642  7680 net.cpp:137] Memory required for data: 373812800
I0117 22:13:17.396647  7680 layer_factory.hpp:77] Creating layer ReLU25
I0117 22:13:17.396653  7680 net.cpp:84] Creating Layer ReLU25
I0117 22:13:17.396658  7680 net.cpp:406] ReLU25 <- fuse2
I0117 22:13:17.396664  7680 net.cpp:367] ReLU25 -> fuse2 (in-place)
I0117 22:13:17.396834  7680 net.cpp:122] Setting up ReLU25
I0117 22:13:17.396845  7680 net.cpp:129] Top shape: 100 64 7 7 (313600)
I0117 22:13:17.396850  7680 net.cpp:137] Memory required for data: 375067200
I0117 22:13:17.396855  7680 layer_factory.hpp:77] Creating layer Pooling1
I0117 22:13:17.396863  7680 net.cpp:84] Creating Layer Pooling1
I0117 22:13:17.396868  7680 net.cpp:406] Pooling1 <- fuse2
I0117 22:13:17.396877  7680 net.cpp:380] Pooling1 -> Pooling1
I0117 22:13:17.397562  7680 net.cpp:122] Setting up Pooling1
I0117 22:13:17.397579  7680 net.cpp:129] Top shape: 100 64 1 1 (6400)
I0117 22:13:17.397584  7680 net.cpp:137] Memory required for data: 375092800
I0117 22:13:17.397589  7680 layer_factory.hpp:77] Creating layer InnerProduct1
I0117 22:13:17.397599  7680 net.cpp:84] Creating Layer InnerProduct1
I0117 22:13:17.397605  7680 net.cpp:406] InnerProduct1 <- Pooling1
I0117 22:13:17.397614  7680 net.cpp:380] InnerProduct1 -> InnerProduct1
I0117 22:13:17.397773  7680 net.cpp:122] Setting up InnerProduct1
I0117 22:13:17.397783  7680 net.cpp:129] Top shape: 100 16 (1600)
I0117 22:13:17.397789  7680 net.cpp:137] Memory required for data: 375099200
I0117 22:13:17.397796  7680 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0117 22:13:17.397804  7680 net.cpp:84] Creating Layer SoftmaxWithLoss1
I0117 22:13:17.397810  7680 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I0117 22:13:17.397815  7680 net.cpp:406] SoftmaxWithLoss1 <- label
I0117 22:13:17.397826  7680 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0117 22:13:17.397846  7680 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0117 22:13:17.398164  7680 net.cpp:122] Setting up SoftmaxWithLoss1
I0117 22:13:17.398175  7680 net.cpp:129] Top shape: (1)
I0117 22:13:17.398180  7680 net.cpp:132]     with loss weight 1
I0117 22:13:17.398207  7680 net.cpp:137] Memory required for data: 375099204
I0117 22:13:17.398213  7680 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I0117 22:13:17.398221  7680 net.cpp:198] InnerProduct1 needs backward computation.
I0117 22:13:17.398227  7680 net.cpp:198] Pooling1 needs backward computation.
I0117 22:13:17.398232  7680 net.cpp:198] ReLU25 needs backward computation.
I0117 22:13:17.398237  7680 net.cpp:198] fuse2 needs backward computation.
I0117 22:13:17.398242  7680 net.cpp:198] fuse1 needs backward computation.
I0117 22:13:17.398248  7680 net.cpp:198] Scale_Convolution_eltwise8 needs backward computation.
I0117 22:13:17.398253  7680 net.cpp:198] BatchNorm_Convolution_eltwise8 needs backward computation.
I0117 22:13:17.398257  7680 net.cpp:198] Convolution_eltwise8 needs backward computation.
I0117 22:13:17.398263  7680 net.cpp:198] Scale_Convolution_eltwise4 needs backward computation.
I0117 22:13:17.398268  7680 net.cpp:198] BatchNorm_Convolution_eltwise4 needs backward computation.
I0117 22:13:17.398273  7680 net.cpp:198] Convolution_eltwise4 needs backward computation.
I0117 22:13:17.398278  7680 net.cpp:198] Eltwise12 needs backward computation.
I0117 22:13:17.398283  7680 net.cpp:198] Scale27 needs backward computation.
I0117 22:13:17.398288  7680 net.cpp:198] BatchNorm27 needs backward computation.
I0117 22:13:17.398293  7680 net.cpp:198] Convolution27 needs backward computation.
I0117 22:13:17.398298  7680 net.cpp:198] ReLU24 needs backward computation.
I0117 22:13:17.398303  7680 net.cpp:198] Scale26 needs backward computation.
I0117 22:13:17.398308  7680 net.cpp:198] BatchNorm26 needs backward computation.
I0117 22:13:17.398313  7680 net.cpp:198] Convolution26 needs backward computation.
I0117 22:13:17.398317  7680 net.cpp:198] Eltwise11_ReLU23_0_split needs backward computation.
I0117 22:13:17.398322  7680 net.cpp:198] ReLU23 needs backward computation.
I0117 22:13:17.398327  7680 net.cpp:198] Eltwise11 needs backward computation.
I0117 22:13:17.398332  7680 net.cpp:198] Scale25 needs backward computation.
I0117 22:13:17.398337  7680 net.cpp:198] BatchNorm25 needs backward computation.
I0117 22:13:17.398342  7680 net.cpp:198] Convolution25 needs backward computation.
I0117 22:13:17.398346  7680 net.cpp:198] ReLU22 needs backward computation.
I0117 22:13:17.398351  7680 net.cpp:198] Scale24 needs backward computation.
I0117 22:13:17.398356  7680 net.cpp:198] BatchNorm24 needs backward computation.
I0117 22:13:17.398361  7680 net.cpp:198] Convolution24 needs backward computation.
I0117 22:13:17.398366  7680 net.cpp:198] Eltwise10_ReLU21_0_split needs backward computation.
I0117 22:13:17.398373  7680 net.cpp:198] ReLU21 needs backward computation.
I0117 22:13:17.398378  7680 net.cpp:198] Eltwise10 needs backward computation.
I0117 22:13:17.398385  7680 net.cpp:198] Scale23 needs backward computation.
I0117 22:13:17.398389  7680 net.cpp:198] BatchNorm23 needs backward computation.
I0117 22:13:17.398393  7680 net.cpp:198] Convolution23 needs backward computation.
I0117 22:13:17.398398  7680 net.cpp:198] ReLU20 needs backward computation.
I0117 22:13:17.398403  7680 net.cpp:198] Scale22 needs backward computation.
I0117 22:13:17.398408  7680 net.cpp:198] BatchNorm22 needs backward computation.
I0117 22:13:17.398413  7680 net.cpp:198] Convolution22 needs backward computation.
I0117 22:13:17.398418  7680 net.cpp:198] Eltwise9_ReLU19_0_split needs backward computation.
I0117 22:13:17.398423  7680 net.cpp:198] ReLU19 needs backward computation.
I0117 22:13:17.398428  7680 net.cpp:198] Eltwise9 needs backward computation.
I0117 22:13:17.398433  7680 net.cpp:198] Scale21 needs backward computation.
I0117 22:13:17.398438  7680 net.cpp:198] BatchNorm21 needs backward computation.
I0117 22:13:17.398442  7680 net.cpp:198] Convolution21 needs backward computation.
I0117 22:13:17.398458  7680 net.cpp:198] ReLU18 needs backward computation.
I0117 22:13:17.398463  7680 net.cpp:198] Scale20 needs backward computation.
I0117 22:13:17.398476  7680 net.cpp:198] BatchNorm20 needs backward computation.
I0117 22:13:17.398481  7680 net.cpp:198] Convolution20 needs backward computation.
I0117 22:13:17.398486  7680 net.cpp:198] Scale19 needs backward computation.
I0117 22:13:17.398491  7680 net.cpp:198] BatchNorm19 needs backward computation.
I0117 22:13:17.398496  7680 net.cpp:198] Convolution19 needs backward computation.
I0117 22:13:17.398501  7680 net.cpp:198] Eltwise8_ReLU17_0_split needs backward computation.
I0117 22:13:17.398506  7680 net.cpp:198] ReLU17 needs backward computation.
I0117 22:13:17.398511  7680 net.cpp:198] Eltwise8 needs backward computation.
I0117 22:13:17.398516  7680 net.cpp:198] Scale18 needs backward computation.
I0117 22:13:17.398530  7680 net.cpp:198] BatchNorm18 needs backward computation.
I0117 22:13:17.398535  7680 net.cpp:198] Convolution18 needs backward computation.
I0117 22:13:17.398540  7680 net.cpp:198] ReLU16 needs backward computation.
I0117 22:13:17.398545  7680 net.cpp:198] Scale17 needs backward computation.
I0117 22:13:17.398548  7680 net.cpp:198] BatchNorm17 needs backward computation.
I0117 22:13:17.398553  7680 net.cpp:198] Convolution17 needs backward computation.
I0117 22:13:17.398558  7680 net.cpp:198] Eltwise7_ReLU15_0_split needs backward computation.
I0117 22:13:17.398563  7680 net.cpp:198] ReLU15 needs backward computation.
I0117 22:13:17.398568  7680 net.cpp:198] Eltwise7 needs backward computation.
I0117 22:13:17.398573  7680 net.cpp:198] Scale16 needs backward computation.
I0117 22:13:17.398577  7680 net.cpp:198] BatchNorm16 needs backward computation.
I0117 22:13:17.398582  7680 net.cpp:198] Convolution16 needs backward computation.
I0117 22:13:17.398586  7680 net.cpp:198] ReLU14 needs backward computation.
I0117 22:13:17.398591  7680 net.cpp:198] Scale15 needs backward computation.
I0117 22:13:17.398597  7680 net.cpp:198] BatchNorm15 needs backward computation.
I0117 22:13:17.398600  7680 net.cpp:198] Convolution15 needs backward computation.
I0117 22:13:17.398605  7680 net.cpp:198] Eltwise6_ReLU13_0_split needs backward computation.
I0117 22:13:17.398610  7680 net.cpp:198] ReLU13 needs backward computation.
I0117 22:13:17.398615  7680 net.cpp:198] Eltwise6 needs backward computation.
I0117 22:13:17.398622  7680 net.cpp:198] Scale14 needs backward computation.
I0117 22:13:17.398627  7680 net.cpp:198] BatchNorm14 needs backward computation.
I0117 22:13:17.398632  7680 net.cpp:198] Convolution14 needs backward computation.
I0117 22:13:17.398636  7680 net.cpp:198] ReLU12 needs backward computation.
I0117 22:13:17.398640  7680 net.cpp:198] Scale13 needs backward computation.
I0117 22:13:17.398645  7680 net.cpp:198] BatchNorm13 needs backward computation.
I0117 22:13:17.398649  7680 net.cpp:198] Convolution13 needs backward computation.
I0117 22:13:17.398655  7680 net.cpp:198] Eltwise5_ReLU11_0_split needs backward computation.
I0117 22:13:17.398659  7680 net.cpp:198] ReLU11 needs backward computation.
I0117 22:13:17.398664  7680 net.cpp:198] Eltwise5 needs backward computation.
I0117 22:13:17.398669  7680 net.cpp:198] Scale12 needs backward computation.
I0117 22:13:17.398674  7680 net.cpp:198] BatchNorm12 needs backward computation.
I0117 22:13:17.398679  7680 net.cpp:198] Convolution12 needs backward computation.
I0117 22:13:17.398684  7680 net.cpp:198] ReLU10 needs backward computation.
I0117 22:13:17.398689  7680 net.cpp:198] Scale11 needs backward computation.
I0117 22:13:17.398694  7680 net.cpp:198] BatchNorm11 needs backward computation.
I0117 22:13:17.398699  7680 net.cpp:198] Convolution11 needs backward computation.
I0117 22:13:17.398705  7680 net.cpp:198] Scale10 needs backward computation.
I0117 22:13:17.398708  7680 net.cpp:198] BatchNorm10 needs backward computation.
I0117 22:13:17.398713  7680 net.cpp:198] Convolution10 needs backward computation.
I0117 22:13:17.398718  7680 net.cpp:198] Eltwise4_ReLU9_0_split needs backward computation.
I0117 22:13:17.398731  7680 net.cpp:198] ReLU9 needs backward computation.
I0117 22:13:17.398737  7680 net.cpp:198] Eltwise4 needs backward computation.
I0117 22:13:17.398742  7680 net.cpp:198] Scale9 needs backward computation.
I0117 22:13:17.398747  7680 net.cpp:198] BatchNorm9 needs backward computation.
I0117 22:13:17.398752  7680 net.cpp:198] Convolution9 needs backward computation.
I0117 22:13:17.398757  7680 net.cpp:198] ReLU8 needs backward computation.
I0117 22:13:17.398761  7680 net.cpp:198] Scale8 needs backward computation.
I0117 22:13:17.398766  7680 net.cpp:198] BatchNorm8 needs backward computation.
I0117 22:13:17.398772  7680 net.cpp:198] Convolution8 needs backward computation.
I0117 22:13:17.398777  7680 net.cpp:198] Eltwise3_ReLU7_0_split needs backward computation.
I0117 22:13:17.398782  7680 net.cpp:198] ReLU7 needs backward computation.
I0117 22:13:17.398785  7680 net.cpp:198] Eltwise3 needs backward computation.
I0117 22:13:17.398790  7680 net.cpp:198] Scale7 needs backward computation.
I0117 22:13:17.398795  7680 net.cpp:198] BatchNorm7 needs backward computation.
I0117 22:13:17.398800  7680 net.cpp:198] Convolution7 needs backward computation.
I0117 22:13:17.398805  7680 net.cpp:198] ReLU6 needs backward computation.
I0117 22:13:17.398810  7680 net.cpp:198] Scale6 needs backward computation.
I0117 22:13:17.398814  7680 net.cpp:198] BatchNorm6 needs backward computation.
I0117 22:13:17.398819  7680 net.cpp:198] Convolution6 needs backward computation.
I0117 22:13:17.398824  7680 net.cpp:198] Eltwise2_ReLU5_0_split needs backward computation.
I0117 22:13:17.398830  7680 net.cpp:198] ReLU5 needs backward computation.
I0117 22:13:17.398835  7680 net.cpp:198] Eltwise2 needs backward computation.
I0117 22:13:17.398841  7680 net.cpp:198] Scale5 needs backward computation.
I0117 22:13:17.398846  7680 net.cpp:198] BatchNorm5 needs backward computation.
I0117 22:13:17.398850  7680 net.cpp:198] Convolution5 needs backward computation.
I0117 22:13:17.398855  7680 net.cpp:198] ReLU4 needs backward computation.
I0117 22:13:17.398860  7680 net.cpp:198] Scale4 needs backward computation.
I0117 22:13:17.398864  7680 net.cpp:198] BatchNorm4 needs backward computation.
I0117 22:13:17.398869  7680 net.cpp:198] Convolution4 needs backward computation.
I0117 22:13:17.398874  7680 net.cpp:198] Eltwise1_ReLU3_0_split needs backward computation.
I0117 22:13:17.398880  7680 net.cpp:198] ReLU3 needs backward computation.
I0117 22:13:17.398885  7680 net.cpp:198] Eltwise1 needs backward computation.
I0117 22:13:17.398890  7680 net.cpp:198] Scale3 needs backward computation.
I0117 22:13:17.398895  7680 net.cpp:198] BatchNorm3 needs backward computation.
I0117 22:13:17.398898  7680 net.cpp:198] Convolution3 needs backward computation.
I0117 22:13:17.398903  7680 net.cpp:198] ReLU2 needs backward computation.
I0117 22:13:17.398908  7680 net.cpp:198] Scale2 needs backward computation.
I0117 22:13:17.398913  7680 net.cpp:198] BatchNorm2 needs backward computation.
I0117 22:13:17.398917  7680 net.cpp:198] Convolution2 needs backward computation.
I0117 22:13:17.398922  7680 net.cpp:198] Convolution1_ReLU1_0_split needs backward computation.
I0117 22:13:17.398927  7680 net.cpp:198] ReLU1 needs backward computation.
I0117 22:13:17.398932  7680 net.cpp:198] Scale1 needs backward computation.
I0117 22:13:17.398937  7680 net.cpp:198] BatchNorm1 needs backward computation.
I0117 22:13:17.398941  7680 net.cpp:198] Convolution1 needs backward computation.
I0117 22:13:17.398947  7680 net.cpp:200] indian does not need backward computation.
I0117 22:13:17.398952  7680 net.cpp:242] This network produces output SoftmaxWithLoss1
I0117 22:13:17.399018  7680 net.cpp:255] Network initialization done.
I0117 22:13:17.400061  7680 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: ./prototxt_files/train_indian_pines.prototxt
I0117 22:13:17.400084  7680 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0117 22:13:17.400096  7680 solver.cpp:172] Creating test net (#0) specified by net file: ./prototxt_files/train_indian_pines.prototxt
I0117 22:13:17.400204  7680 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer indian
I0117 22:13:17.400862  7680 net.cpp:51] Initializing net from parameters: 
name: "DFFN"
state {
  phase: TEST
}
layer {
  name: "indian"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "caffe-master/data/indian_pines/test.txt"
    batch_size: 20
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "data"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution11"
  top: "Convolution11"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Convolution11"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Convolution10"
  bottom: "Convolution12"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "Convolution13"
  top: "Convolution13"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Convolution15"
  top: "Convolution15"
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Convolution15"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution16"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution17"
  top: "Convolution17"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Convolution17"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution18"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution20"
  top: "Convolution20"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Convolution19"
  bottom: "Convolution21"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU20"
  type: "ReLU"
  bottom: "Convolution22"
  top: "Convolution22"
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Convolution22"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Eltwise9"
  bottom: "Convolution23"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "Convolution24"
  top: "Convolution24"
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Convolution24"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution25"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "Eltwise11"
  top: "Eltwise11"
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU24"
  type: "ReLU"
  bottom: "Convolution26"
  top: "Convolution26"
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Convolution26"
  top: "Convolution27"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Eltwise11"
  bottom: "Convolution27"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution_eltwise4"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution_eltwise4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm_Convolution_eltwise4"
  type: "BatchNorm"
  bottom: "Convolution_eltwise4"
  top: "Convolution_eltwise4"
}
layer {
  name: "Scale_Convolution_eltwise4"
  type: "Scale"
  bottom: "Convolution_eltwise4"
  top: "Convolution_eltwise4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution_eltwise8"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution_eltwise8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm_Convolution_eltwise8"
  type: "BatchNorm"
  bottom: "Convolution_eltwise8"
  top: "Convolution_eltwise8"
}
layer {
  name: "Scale_Convolution_eltwise8"
  type: "Scale"
  bottom: "Convolution_eltwise8"
  top: "Convolution_eltwise8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "fuse1"
  type: "Eltwise"
  bottom: "Convolution_eltwise4"
  bottom: "Convolution_eltwise8"
  top: "fuse1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "fuse2"
  type: "Eltwise"
  bottom: "fuse1"
  bottom: "Eltwise12"
  top: "fuse2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "fuse2"
  top: "fuse2"
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "fuse2"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "InnerProduct1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 16
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "label"
  top: "SoftmaxWithLoss1"
}
layer {
  name: "Accuracy1"
  type: "Accuracy"
  bottom: "InnerProduct1"
  bottom: "label"
  top: "Accuracy1"
  include {
    phase: TEST
  }
}
I0117 22:13:17.401248  7680 layer_factory.hpp:77] Creating layer indian
I0117 22:13:17.401263  7680 net.cpp:84] Creating Layer indian
I0117 22:13:17.401269  7680 net.cpp:380] indian -> data
I0117 22:13:17.401281  7680 net.cpp:380] indian -> label
I0117 22:13:17.401289  7680 hdf5_data_layer.cpp:80] Loading list of HDF5 filenames from: caffe-master/data/indian_pines/test.txt
I0117 22:13:17.418963  7680 hdf5_data_layer.cpp:94] Number of HDF5 files: 5
I0117 22:13:17.429636  7680 net.cpp:122] Setting up indian
I0117 22:13:17.429683  7680 net.cpp:129] Top shape: 20 3 25 25 (37500)
I0117 22:13:17.429693  7680 net.cpp:129] Top shape: 20 1 (20)
I0117 22:13:17.429699  7680 net.cpp:137] Memory required for data: 150080
I0117 22:13:17.429708  7680 layer_factory.hpp:77] Creating layer label_indian_1_split
I0117 22:13:17.429720  7680 net.cpp:84] Creating Layer label_indian_1_split
I0117 22:13:17.429728  7680 net.cpp:406] label_indian_1_split <- label
I0117 22:13:17.429736  7680 net.cpp:380] label_indian_1_split -> label_indian_1_split_0
I0117 22:13:17.429749  7680 net.cpp:380] label_indian_1_split -> label_indian_1_split_1
I0117 22:13:17.429822  7680 net.cpp:122] Setting up label_indian_1_split
I0117 22:13:17.429834  7680 net.cpp:129] Top shape: 20 1 (20)
I0117 22:13:17.429841  7680 net.cpp:129] Top shape: 20 1 (20)
I0117 22:13:17.429844  7680 net.cpp:137] Memory required for data: 150240
I0117 22:13:17.429850  7680 layer_factory.hpp:77] Creating layer Convolution1
I0117 22:13:17.429873  7680 net.cpp:84] Creating Layer Convolution1
I0117 22:13:17.429879  7680 net.cpp:406] Convolution1 <- data
I0117 22:13:17.429888  7680 net.cpp:380] Convolution1 -> Convolution1
I0117 22:13:17.432072  7680 net.cpp:122] Setting up Convolution1
I0117 22:13:17.432116  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.432123  7680 net.cpp:137] Memory required for data: 950240
I0117 22:13:17.432143  7680 layer_factory.hpp:77] Creating layer BatchNorm1
I0117 22:13:17.432157  7680 net.cpp:84] Creating Layer BatchNorm1
I0117 22:13:17.432171  7680 net.cpp:406] BatchNorm1 <- Convolution1
I0117 22:13:17.432179  7680 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I0117 22:13:17.432418  7680 net.cpp:122] Setting up BatchNorm1
I0117 22:13:17.432430  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.432435  7680 net.cpp:137] Memory required for data: 1750240
I0117 22:13:17.432457  7680 layer_factory.hpp:77] Creating layer Scale1
I0117 22:13:17.432468  7680 net.cpp:84] Creating Layer Scale1
I0117 22:13:17.432474  7680 net.cpp:406] Scale1 <- Convolution1
I0117 22:13:17.432489  7680 net.cpp:367] Scale1 -> Convolution1 (in-place)
I0117 22:13:17.432539  7680 layer_factory.hpp:77] Creating layer Scale1
I0117 22:13:17.432668  7680 net.cpp:122] Setting up Scale1
I0117 22:13:17.432678  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.432683  7680 net.cpp:137] Memory required for data: 2550240
I0117 22:13:17.432690  7680 layer_factory.hpp:77] Creating layer ReLU1
I0117 22:13:17.432698  7680 net.cpp:84] Creating Layer ReLU1
I0117 22:13:17.432703  7680 net.cpp:406] ReLU1 <- Convolution1
I0117 22:13:17.432709  7680 net.cpp:367] ReLU1 -> Convolution1 (in-place)
I0117 22:13:17.432888  7680 net.cpp:122] Setting up ReLU1
I0117 22:13:17.432900  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.432905  7680 net.cpp:137] Memory required for data: 3350240
I0117 22:13:17.432910  7680 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I0117 22:13:17.432919  7680 net.cpp:84] Creating Layer Convolution1_ReLU1_0_split
I0117 22:13:17.432924  7680 net.cpp:406] Convolution1_ReLU1_0_split <- Convolution1
I0117 22:13:17.432930  7680 net.cpp:380] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I0117 22:13:17.432940  7680 net.cpp:380] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I0117 22:13:17.432986  7680 net.cpp:122] Setting up Convolution1_ReLU1_0_split
I0117 22:13:17.432996  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.433002  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.433007  7680 net.cpp:137] Memory required for data: 4950240
I0117 22:13:17.433012  7680 layer_factory.hpp:77] Creating layer Convolution2
I0117 22:13:17.433024  7680 net.cpp:84] Creating Layer Convolution2
I0117 22:13:17.433029  7680 net.cpp:406] Convolution2 <- Convolution1_ReLU1_0_split_0
I0117 22:13:17.433037  7680 net.cpp:380] Convolution2 -> Convolution2
I0117 22:13:17.434890  7680 net.cpp:122] Setting up Convolution2
I0117 22:13:17.434936  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.434942  7680 net.cpp:137] Memory required for data: 5750240
I0117 22:13:17.434957  7680 layer_factory.hpp:77] Creating layer BatchNorm2
I0117 22:13:17.434969  7680 net.cpp:84] Creating Layer BatchNorm2
I0117 22:13:17.434975  7680 net.cpp:406] BatchNorm2 <- Convolution2
I0117 22:13:17.434983  7680 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I0117 22:13:17.435200  7680 net.cpp:122] Setting up BatchNorm2
I0117 22:13:17.435212  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.435217  7680 net.cpp:137] Memory required for data: 6550240
I0117 22:13:17.435228  7680 layer_factory.hpp:77] Creating layer Scale2
I0117 22:13:17.435237  7680 net.cpp:84] Creating Layer Scale2
I0117 22:13:17.435242  7680 net.cpp:406] Scale2 <- Convolution2
I0117 22:13:17.435250  7680 net.cpp:367] Scale2 -> Convolution2 (in-place)
I0117 22:13:17.435297  7680 layer_factory.hpp:77] Creating layer Scale2
I0117 22:13:17.435441  7680 net.cpp:122] Setting up Scale2
I0117 22:13:17.435451  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.435457  7680 net.cpp:137] Memory required for data: 7350240
I0117 22:13:17.435465  7680 layer_factory.hpp:77] Creating layer ReLU2
I0117 22:13:17.435472  7680 net.cpp:84] Creating Layer ReLU2
I0117 22:13:17.435477  7680 net.cpp:406] ReLU2 <- Convolution2
I0117 22:13:17.435483  7680 net.cpp:367] ReLU2 -> Convolution2 (in-place)
I0117 22:13:17.436137  7680 net.cpp:122] Setting up ReLU2
I0117 22:13:17.436154  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.436159  7680 net.cpp:137] Memory required for data: 8150240
I0117 22:13:17.436166  7680 layer_factory.hpp:77] Creating layer Convolution3
I0117 22:13:17.436179  7680 net.cpp:84] Creating Layer Convolution3
I0117 22:13:17.436184  7680 net.cpp:406] Convolution3 <- Convolution2
I0117 22:13:17.436193  7680 net.cpp:380] Convolution3 -> Convolution3
I0117 22:13:17.437980  7680 net.cpp:122] Setting up Convolution3
I0117 22:13:17.438010  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.438016  7680 net.cpp:137] Memory required for data: 8950240
I0117 22:13:17.438037  7680 layer_factory.hpp:77] Creating layer BatchNorm3
I0117 22:13:17.438048  7680 net.cpp:84] Creating Layer BatchNorm3
I0117 22:13:17.438055  7680 net.cpp:406] BatchNorm3 <- Convolution3
I0117 22:13:17.438063  7680 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I0117 22:13:17.438307  7680 net.cpp:122] Setting up BatchNorm3
I0117 22:13:17.438318  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.438323  7680 net.cpp:137] Memory required for data: 9750240
I0117 22:13:17.438338  7680 layer_factory.hpp:77] Creating layer Scale3
I0117 22:13:17.438347  7680 net.cpp:84] Creating Layer Scale3
I0117 22:13:17.438352  7680 net.cpp:406] Scale3 <- Convolution3
I0117 22:13:17.438359  7680 net.cpp:367] Scale3 -> Convolution3 (in-place)
I0117 22:13:17.438410  7680 layer_factory.hpp:77] Creating layer Scale3
I0117 22:13:17.438544  7680 net.cpp:122] Setting up Scale3
I0117 22:13:17.438555  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.438560  7680 net.cpp:137] Memory required for data: 10550240
I0117 22:13:17.438567  7680 layer_factory.hpp:77] Creating layer Eltwise1
I0117 22:13:17.438577  7680 net.cpp:84] Creating Layer Eltwise1
I0117 22:13:17.438582  7680 net.cpp:406] Eltwise1 <- Convolution1_ReLU1_0_split_1
I0117 22:13:17.438588  7680 net.cpp:406] Eltwise1 <- Convolution3
I0117 22:13:17.438596  7680 net.cpp:380] Eltwise1 -> Eltwise1
I0117 22:13:17.438627  7680 net.cpp:122] Setting up Eltwise1
I0117 22:13:17.438635  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.438640  7680 net.cpp:137] Memory required for data: 11350240
I0117 22:13:17.438645  7680 layer_factory.hpp:77] Creating layer ReLU3
I0117 22:13:17.438652  7680 net.cpp:84] Creating Layer ReLU3
I0117 22:13:17.438657  7680 net.cpp:406] ReLU3 <- Eltwise1
I0117 22:13:17.438664  7680 net.cpp:367] ReLU3 -> Eltwise1 (in-place)
I0117 22:13:17.438861  7680 net.cpp:122] Setting up ReLU3
I0117 22:13:17.438882  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.438887  7680 net.cpp:137] Memory required for data: 12150240
I0117 22:13:17.438892  7680 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I0117 22:13:17.438904  7680 net.cpp:84] Creating Layer Eltwise1_ReLU3_0_split
I0117 22:13:17.438908  7680 net.cpp:406] Eltwise1_ReLU3_0_split <- Eltwise1
I0117 22:13:17.438916  7680 net.cpp:380] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I0117 22:13:17.438925  7680 net.cpp:380] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I0117 22:13:17.438969  7680 net.cpp:122] Setting up Eltwise1_ReLU3_0_split
I0117 22:13:17.438979  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.438984  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.438989  7680 net.cpp:137] Memory required for data: 13750240
I0117 22:13:17.438994  7680 layer_factory.hpp:77] Creating layer Convolution4
I0117 22:13:17.439007  7680 net.cpp:84] Creating Layer Convolution4
I0117 22:13:17.439013  7680 net.cpp:406] Convolution4 <- Eltwise1_ReLU3_0_split_0
I0117 22:13:17.439020  7680 net.cpp:380] Convolution4 -> Convolution4
I0117 22:13:17.441588  7680 net.cpp:122] Setting up Convolution4
I0117 22:13:17.441639  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.441649  7680 net.cpp:137] Memory required for data: 14550240
I0117 22:13:17.441664  7680 layer_factory.hpp:77] Creating layer BatchNorm4
I0117 22:13:17.441679  7680 net.cpp:84] Creating Layer BatchNorm4
I0117 22:13:17.441687  7680 net.cpp:406] BatchNorm4 <- Convolution4
I0117 22:13:17.441697  7680 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I0117 22:13:17.441956  7680 net.cpp:122] Setting up BatchNorm4
I0117 22:13:17.441969  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.441974  7680 net.cpp:137] Memory required for data: 15350240
I0117 22:13:17.441995  7680 layer_factory.hpp:77] Creating layer Scale4
I0117 22:13:17.442006  7680 net.cpp:84] Creating Layer Scale4
I0117 22:13:17.442013  7680 net.cpp:406] Scale4 <- Convolution4
I0117 22:13:17.442019  7680 net.cpp:367] Scale4 -> Convolution4 (in-place)
I0117 22:13:17.442086  7680 layer_factory.hpp:77] Creating layer Scale4
I0117 22:13:17.442237  7680 net.cpp:122] Setting up Scale4
I0117 22:13:17.442248  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.442255  7680 net.cpp:137] Memory required for data: 16150240
I0117 22:13:17.442262  7680 layer_factory.hpp:77] Creating layer ReLU4
I0117 22:13:17.442271  7680 net.cpp:84] Creating Layer ReLU4
I0117 22:13:17.442276  7680 net.cpp:406] ReLU4 <- Convolution4
I0117 22:13:17.442283  7680 net.cpp:367] ReLU4 -> Convolution4 (in-place)
I0117 22:13:17.442489  7680 net.cpp:122] Setting up ReLU4
I0117 22:13:17.442502  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.442507  7680 net.cpp:137] Memory required for data: 16950240
I0117 22:13:17.442513  7680 layer_factory.hpp:77] Creating layer Convolution5
I0117 22:13:17.442528  7680 net.cpp:84] Creating Layer Convolution5
I0117 22:13:17.442533  7680 net.cpp:406] Convolution5 <- Convolution4
I0117 22:13:17.442543  7680 net.cpp:380] Convolution5 -> Convolution5
I0117 22:13:17.444483  7680 net.cpp:122] Setting up Convolution5
I0117 22:13:17.444520  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.444528  7680 net.cpp:137] Memory required for data: 17750240
I0117 22:13:17.444540  7680 layer_factory.hpp:77] Creating layer BatchNorm5
I0117 22:13:17.444552  7680 net.cpp:84] Creating Layer BatchNorm5
I0117 22:13:17.444559  7680 net.cpp:406] BatchNorm5 <- Convolution5
I0117 22:13:17.444568  7680 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I0117 22:13:17.444798  7680 net.cpp:122] Setting up BatchNorm5
I0117 22:13:17.444810  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.444816  7680 net.cpp:137] Memory required for data: 18550240
I0117 22:13:17.444833  7680 layer_factory.hpp:77] Creating layer Scale5
I0117 22:13:17.444842  7680 net.cpp:84] Creating Layer Scale5
I0117 22:13:17.444866  7680 net.cpp:406] Scale5 <- Convolution5
I0117 22:13:17.444875  7680 net.cpp:367] Scale5 -> Convolution5 (in-place)
I0117 22:13:17.444928  7680 layer_factory.hpp:77] Creating layer Scale5
I0117 22:13:17.445070  7680 net.cpp:122] Setting up Scale5
I0117 22:13:17.445081  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.445086  7680 net.cpp:137] Memory required for data: 19350240
I0117 22:13:17.445096  7680 layer_factory.hpp:77] Creating layer Eltwise2
I0117 22:13:17.445104  7680 net.cpp:84] Creating Layer Eltwise2
I0117 22:13:17.445111  7680 net.cpp:406] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I0117 22:13:17.445116  7680 net.cpp:406] Eltwise2 <- Convolution5
I0117 22:13:17.445123  7680 net.cpp:380] Eltwise2 -> Eltwise2
I0117 22:13:17.445155  7680 net.cpp:122] Setting up Eltwise2
I0117 22:13:17.445166  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.445170  7680 net.cpp:137] Memory required for data: 20150240
I0117 22:13:17.445176  7680 layer_factory.hpp:77] Creating layer ReLU5
I0117 22:13:17.445183  7680 net.cpp:84] Creating Layer ReLU5
I0117 22:13:17.445188  7680 net.cpp:406] ReLU5 <- Eltwise2
I0117 22:13:17.445195  7680 net.cpp:367] ReLU5 -> Eltwise2 (in-place)
I0117 22:13:17.445874  7680 net.cpp:122] Setting up ReLU5
I0117 22:13:17.445893  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.445897  7680 net.cpp:137] Memory required for data: 20950240
I0117 22:13:17.445904  7680 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I0117 22:13:17.445912  7680 net.cpp:84] Creating Layer Eltwise2_ReLU5_0_split
I0117 22:13:17.445917  7680 net.cpp:406] Eltwise2_ReLU5_0_split <- Eltwise2
I0117 22:13:17.445925  7680 net.cpp:380] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I0117 22:13:17.445935  7680 net.cpp:380] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I0117 22:13:17.445986  7680 net.cpp:122] Setting up Eltwise2_ReLU5_0_split
I0117 22:13:17.445996  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.446003  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.446008  7680 net.cpp:137] Memory required for data: 22550240
I0117 22:13:17.446022  7680 layer_factory.hpp:77] Creating layer Convolution6
I0117 22:13:17.446035  7680 net.cpp:84] Creating Layer Convolution6
I0117 22:13:17.446040  7680 net.cpp:406] Convolution6 <- Eltwise2_ReLU5_0_split_0
I0117 22:13:17.446049  7680 net.cpp:380] Convolution6 -> Convolution6
I0117 22:13:17.447845  7680 net.cpp:122] Setting up Convolution6
I0117 22:13:17.447880  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.447887  7680 net.cpp:137] Memory required for data: 23350240
I0117 22:13:17.447899  7680 layer_factory.hpp:77] Creating layer BatchNorm6
I0117 22:13:17.447911  7680 net.cpp:84] Creating Layer BatchNorm6
I0117 22:13:17.447917  7680 net.cpp:406] BatchNorm6 <- Convolution6
I0117 22:13:17.447926  7680 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I0117 22:13:17.448163  7680 net.cpp:122] Setting up BatchNorm6
I0117 22:13:17.448174  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.448179  7680 net.cpp:137] Memory required for data: 24150240
I0117 22:13:17.448191  7680 layer_factory.hpp:77] Creating layer Scale6
I0117 22:13:17.448200  7680 net.cpp:84] Creating Layer Scale6
I0117 22:13:17.448206  7680 net.cpp:406] Scale6 <- Convolution6
I0117 22:13:17.448213  7680 net.cpp:367] Scale6 -> Convolution6 (in-place)
I0117 22:13:17.448264  7680 layer_factory.hpp:77] Creating layer Scale6
I0117 22:13:17.448416  7680 net.cpp:122] Setting up Scale6
I0117 22:13:17.448427  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.448432  7680 net.cpp:137] Memory required for data: 24950240
I0117 22:13:17.448441  7680 layer_factory.hpp:77] Creating layer ReLU6
I0117 22:13:17.448448  7680 net.cpp:84] Creating Layer ReLU6
I0117 22:13:17.448453  7680 net.cpp:406] ReLU6 <- Convolution6
I0117 22:13:17.448459  7680 net.cpp:367] ReLU6 -> Convolution6 (in-place)
I0117 22:13:17.448632  7680 net.cpp:122] Setting up ReLU6
I0117 22:13:17.448652  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.448664  7680 net.cpp:137] Memory required for data: 25750240
I0117 22:13:17.448670  7680 layer_factory.hpp:77] Creating layer Convolution7
I0117 22:13:17.448683  7680 net.cpp:84] Creating Layer Convolution7
I0117 22:13:17.448688  7680 net.cpp:406] Convolution7 <- Convolution6
I0117 22:13:17.448695  7680 net.cpp:380] Convolution7 -> Convolution7
I0117 22:13:17.450448  7680 net.cpp:122] Setting up Convolution7
I0117 22:13:17.450489  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.450495  7680 net.cpp:137] Memory required for data: 26550240
I0117 22:13:17.450506  7680 layer_factory.hpp:77] Creating layer BatchNorm7
I0117 22:13:17.450531  7680 net.cpp:84] Creating Layer BatchNorm7
I0117 22:13:17.450537  7680 net.cpp:406] BatchNorm7 <- Convolution7
I0117 22:13:17.450546  7680 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I0117 22:13:17.450770  7680 net.cpp:122] Setting up BatchNorm7
I0117 22:13:17.450783  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.450788  7680 net.cpp:137] Memory required for data: 27350240
I0117 22:13:17.450798  7680 layer_factory.hpp:77] Creating layer Scale7
I0117 22:13:17.450808  7680 net.cpp:84] Creating Layer Scale7
I0117 22:13:17.450814  7680 net.cpp:406] Scale7 <- Convolution7
I0117 22:13:17.450820  7680 net.cpp:367] Scale7 -> Convolution7 (in-place)
I0117 22:13:17.450868  7680 layer_factory.hpp:77] Creating layer Scale7
I0117 22:13:17.451004  7680 net.cpp:122] Setting up Scale7
I0117 22:13:17.451014  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.451020  7680 net.cpp:137] Memory required for data: 28150240
I0117 22:13:17.451027  7680 layer_factory.hpp:77] Creating layer Eltwise3
I0117 22:13:17.451036  7680 net.cpp:84] Creating Layer Eltwise3
I0117 22:13:17.451042  7680 net.cpp:406] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I0117 22:13:17.451048  7680 net.cpp:406] Eltwise3 <- Convolution7
I0117 22:13:17.451056  7680 net.cpp:380] Eltwise3 -> Eltwise3
I0117 22:13:17.451086  7680 net.cpp:122] Setting up Eltwise3
I0117 22:13:17.451095  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.451100  7680 net.cpp:137] Memory required for data: 28950240
I0117 22:13:17.451105  7680 layer_factory.hpp:77] Creating layer ReLU7
I0117 22:13:17.451112  7680 net.cpp:84] Creating Layer ReLU7
I0117 22:13:17.451117  7680 net.cpp:406] ReLU7 <- Eltwise3
I0117 22:13:17.451123  7680 net.cpp:367] ReLU7 -> Eltwise3 (in-place)
I0117 22:13:17.451287  7680 net.cpp:122] Setting up ReLU7
I0117 22:13:17.451298  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.451303  7680 net.cpp:137] Memory required for data: 29750240
I0117 22:13:17.451308  7680 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I0117 22:13:17.451316  7680 net.cpp:84] Creating Layer Eltwise3_ReLU7_0_split
I0117 22:13:17.451323  7680 net.cpp:406] Eltwise3_ReLU7_0_split <- Eltwise3
I0117 22:13:17.451329  7680 net.cpp:380] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I0117 22:13:17.451337  7680 net.cpp:380] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I0117 22:13:17.451402  7680 net.cpp:122] Setting up Eltwise3_ReLU7_0_split
I0117 22:13:17.451414  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.451428  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.451433  7680 net.cpp:137] Memory required for data: 31350240
I0117 22:13:17.451437  7680 layer_factory.hpp:77] Creating layer Convolution8
I0117 22:13:17.451449  7680 net.cpp:84] Creating Layer Convolution8
I0117 22:13:17.451455  7680 net.cpp:406] Convolution8 <- Eltwise3_ReLU7_0_split_0
I0117 22:13:17.451462  7680 net.cpp:380] Convolution8 -> Convolution8
I0117 22:13:17.453657  7680 net.cpp:122] Setting up Convolution8
I0117 22:13:17.453693  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.453708  7680 net.cpp:137] Memory required for data: 32150240
I0117 22:13:17.453721  7680 layer_factory.hpp:77] Creating layer BatchNorm8
I0117 22:13:17.453730  7680 net.cpp:84] Creating Layer BatchNorm8
I0117 22:13:17.453747  7680 net.cpp:406] BatchNorm8 <- Convolution8
I0117 22:13:17.453763  7680 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I0117 22:13:17.454007  7680 net.cpp:122] Setting up BatchNorm8
I0117 22:13:17.454027  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.454032  7680 net.cpp:137] Memory required for data: 32950240
I0117 22:13:17.454043  7680 layer_factory.hpp:77] Creating layer Scale8
I0117 22:13:17.454053  7680 net.cpp:84] Creating Layer Scale8
I0117 22:13:17.454059  7680 net.cpp:406] Scale8 <- Convolution8
I0117 22:13:17.454066  7680 net.cpp:367] Scale8 -> Convolution8 (in-place)
I0117 22:13:17.454128  7680 layer_factory.hpp:77] Creating layer Scale8
I0117 22:13:17.454269  7680 net.cpp:122] Setting up Scale8
I0117 22:13:17.454279  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.454284  7680 net.cpp:137] Memory required for data: 33750240
I0117 22:13:17.454291  7680 layer_factory.hpp:77] Creating layer ReLU8
I0117 22:13:17.454299  7680 net.cpp:84] Creating Layer ReLU8
I0117 22:13:17.454304  7680 net.cpp:406] ReLU8 <- Convolution8
I0117 22:13:17.454310  7680 net.cpp:367] ReLU8 -> Convolution8 (in-place)
I0117 22:13:17.454917  7680 net.cpp:122] Setting up ReLU8
I0117 22:13:17.454931  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.454934  7680 net.cpp:137] Memory required for data: 34550240
I0117 22:13:17.454941  7680 layer_factory.hpp:77] Creating layer Convolution9
I0117 22:13:17.454952  7680 net.cpp:84] Creating Layer Convolution9
I0117 22:13:17.454957  7680 net.cpp:406] Convolution9 <- Convolution8
I0117 22:13:17.454965  7680 net.cpp:380] Convolution9 -> Convolution9
I0117 22:13:17.456710  7680 net.cpp:122] Setting up Convolution9
I0117 22:13:17.456727  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.456732  7680 net.cpp:137] Memory required for data: 35350240
I0117 22:13:17.456740  7680 layer_factory.hpp:77] Creating layer BatchNorm9
I0117 22:13:17.456748  7680 net.cpp:84] Creating Layer BatchNorm9
I0117 22:13:17.456754  7680 net.cpp:406] BatchNorm9 <- Convolution9
I0117 22:13:17.456768  7680 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I0117 22:13:17.457007  7680 net.cpp:122] Setting up BatchNorm9
I0117 22:13:17.457017  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.457023  7680 net.cpp:137] Memory required for data: 36150240
I0117 22:13:17.457032  7680 layer_factory.hpp:77] Creating layer Scale9
I0117 22:13:17.457041  7680 net.cpp:84] Creating Layer Scale9
I0117 22:13:17.457046  7680 net.cpp:406] Scale9 <- Convolution9
I0117 22:13:17.457052  7680 net.cpp:367] Scale9 -> Convolution9 (in-place)
I0117 22:13:17.457099  7680 layer_factory.hpp:77] Creating layer Scale9
I0117 22:13:17.457260  7680 net.cpp:122] Setting up Scale9
I0117 22:13:17.457270  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.457275  7680 net.cpp:137] Memory required for data: 36950240
I0117 22:13:17.457283  7680 layer_factory.hpp:77] Creating layer Eltwise4
I0117 22:13:17.457291  7680 net.cpp:84] Creating Layer Eltwise4
I0117 22:13:17.457296  7680 net.cpp:406] Eltwise4 <- Eltwise3_ReLU7_0_split_1
I0117 22:13:17.457303  7680 net.cpp:406] Eltwise4 <- Convolution9
I0117 22:13:17.457311  7680 net.cpp:380] Eltwise4 -> Eltwise4
I0117 22:13:17.457341  7680 net.cpp:122] Setting up Eltwise4
I0117 22:13:17.457352  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.457357  7680 net.cpp:137] Memory required for data: 37750240
I0117 22:13:17.457362  7680 layer_factory.hpp:77] Creating layer ReLU9
I0117 22:13:17.457370  7680 net.cpp:84] Creating Layer ReLU9
I0117 22:13:17.457375  7680 net.cpp:406] ReLU9 <- Eltwise4
I0117 22:13:17.457381  7680 net.cpp:367] ReLU9 -> Eltwise4 (in-place)
I0117 22:13:17.457545  7680 net.cpp:122] Setting up ReLU9
I0117 22:13:17.457557  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.457562  7680 net.cpp:137] Memory required for data: 38550240
I0117 22:13:17.457567  7680 layer_factory.hpp:77] Creating layer Eltwise4_ReLU9_0_split
I0117 22:13:17.457576  7680 net.cpp:84] Creating Layer Eltwise4_ReLU9_0_split
I0117 22:13:17.457592  7680 net.cpp:406] Eltwise4_ReLU9_0_split <- Eltwise4
I0117 22:13:17.457600  7680 net.cpp:380] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_0
I0117 22:13:17.457610  7680 net.cpp:380] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_1
I0117 22:13:17.457619  7680 net.cpp:380] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_2
I0117 22:13:17.457676  7680 net.cpp:122] Setting up Eltwise4_ReLU9_0_split
I0117 22:13:17.457687  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.457693  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.457700  7680 net.cpp:129] Top shape: 20 16 25 25 (200000)
I0117 22:13:17.457703  7680 net.cpp:137] Memory required for data: 40950240
I0117 22:13:17.457708  7680 layer_factory.hpp:77] Creating layer Convolution10
I0117 22:13:17.457720  7680 net.cpp:84] Creating Layer Convolution10
I0117 22:13:17.457726  7680 net.cpp:406] Convolution10 <- Eltwise4_ReLU9_0_split_0
I0117 22:13:17.457733  7680 net.cpp:380] Convolution10 -> Convolution10
I0117 22:13:17.459506  7680 net.cpp:122] Setting up Convolution10
I0117 22:13:17.459528  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.459534  7680 net.cpp:137] Memory required for data: 41382880
I0117 22:13:17.459553  7680 layer_factory.hpp:77] Creating layer BatchNorm10
I0117 22:13:17.459563  7680 net.cpp:84] Creating Layer BatchNorm10
I0117 22:13:17.459569  7680 net.cpp:406] BatchNorm10 <- Convolution10
I0117 22:13:17.459576  7680 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I0117 22:13:17.459810  7680 net.cpp:122] Setting up BatchNorm10
I0117 22:13:17.459820  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.459825  7680 net.cpp:137] Memory required for data: 41815520
I0117 22:13:17.459833  7680 layer_factory.hpp:77] Creating layer Scale10
I0117 22:13:17.459841  7680 net.cpp:84] Creating Layer Scale10
I0117 22:13:17.459846  7680 net.cpp:406] Scale10 <- Convolution10
I0117 22:13:17.459852  7680 net.cpp:367] Scale10 -> Convolution10 (in-place)
I0117 22:13:17.459903  7680 layer_factory.hpp:77] Creating layer Scale10
I0117 22:13:17.460034  7680 net.cpp:122] Setting up Scale10
I0117 22:13:17.460044  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.460049  7680 net.cpp:137] Memory required for data: 42248160
I0117 22:13:17.460057  7680 layer_factory.hpp:77] Creating layer Convolution11
I0117 22:13:17.460068  7680 net.cpp:84] Creating Layer Convolution11
I0117 22:13:17.460074  7680 net.cpp:406] Convolution11 <- Eltwise4_ReLU9_0_split_1
I0117 22:13:17.460083  7680 net.cpp:380] Convolution11 -> Convolution11
I0117 22:13:17.461755  7680 net.cpp:122] Setting up Convolution11
I0117 22:13:17.461768  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.461773  7680 net.cpp:137] Memory required for data: 42680800
I0117 22:13:17.461781  7680 layer_factory.hpp:77] Creating layer BatchNorm11
I0117 22:13:17.461791  7680 net.cpp:84] Creating Layer BatchNorm11
I0117 22:13:17.461797  7680 net.cpp:406] BatchNorm11 <- Convolution11
I0117 22:13:17.461807  7680 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I0117 22:13:17.462023  7680 net.cpp:122] Setting up BatchNorm11
I0117 22:13:17.462033  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.462038  7680 net.cpp:137] Memory required for data: 43113440
I0117 22:13:17.462045  7680 layer_factory.hpp:77] Creating layer Scale11
I0117 22:13:17.462054  7680 net.cpp:84] Creating Layer Scale11
I0117 22:13:17.462060  7680 net.cpp:406] Scale11 <- Convolution11
I0117 22:13:17.462067  7680 net.cpp:367] Scale11 -> Convolution11 (in-place)
I0117 22:13:17.462113  7680 layer_factory.hpp:77] Creating layer Scale11
I0117 22:13:17.462245  7680 net.cpp:122] Setting up Scale11
I0117 22:13:17.462255  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.462260  7680 net.cpp:137] Memory required for data: 43546080
I0117 22:13:17.462267  7680 layer_factory.hpp:77] Creating layer ReLU10
I0117 22:13:17.462275  7680 net.cpp:84] Creating Layer ReLU10
I0117 22:13:17.462281  7680 net.cpp:406] ReLU10 <- Convolution11
I0117 22:13:17.462298  7680 net.cpp:367] ReLU10 -> Convolution11 (in-place)
I0117 22:13:17.462460  7680 net.cpp:122] Setting up ReLU10
I0117 22:13:17.462471  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.462476  7680 net.cpp:137] Memory required for data: 43978720
I0117 22:13:17.462481  7680 layer_factory.hpp:77] Creating layer Convolution12
I0117 22:13:17.462492  7680 net.cpp:84] Creating Layer Convolution12
I0117 22:13:17.462498  7680 net.cpp:406] Convolution12 <- Convolution11
I0117 22:13:17.462507  7680 net.cpp:380] Convolution12 -> Convolution12
I0117 22:13:17.464608  7680 net.cpp:122] Setting up Convolution12
I0117 22:13:17.464623  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.464628  7680 net.cpp:137] Memory required for data: 44411360
I0117 22:13:17.464637  7680 layer_factory.hpp:77] Creating layer BatchNorm12
I0117 22:13:17.464645  7680 net.cpp:84] Creating Layer BatchNorm12
I0117 22:13:17.464650  7680 net.cpp:406] BatchNorm12 <- Convolution12
I0117 22:13:17.464658  7680 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I0117 22:13:17.464871  7680 net.cpp:122] Setting up BatchNorm12
I0117 22:13:17.464881  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.464886  7680 net.cpp:137] Memory required for data: 44844000
I0117 22:13:17.464895  7680 layer_factory.hpp:77] Creating layer Scale12
I0117 22:13:17.464901  7680 net.cpp:84] Creating Layer Scale12
I0117 22:13:17.464906  7680 net.cpp:406] Scale12 <- Convolution12
I0117 22:13:17.464915  7680 net.cpp:367] Scale12 -> Convolution12 (in-place)
I0117 22:13:17.464958  7680 layer_factory.hpp:77] Creating layer Scale12
I0117 22:13:17.465087  7680 net.cpp:122] Setting up Scale12
I0117 22:13:17.465096  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.465101  7680 net.cpp:137] Memory required for data: 45276640
I0117 22:13:17.465108  7680 layer_factory.hpp:77] Creating layer Eltwise5
I0117 22:13:17.465116  7680 net.cpp:84] Creating Layer Eltwise5
I0117 22:13:17.465121  7680 net.cpp:406] Eltwise5 <- Convolution10
I0117 22:13:17.465126  7680 net.cpp:406] Eltwise5 <- Convolution12
I0117 22:13:17.465134  7680 net.cpp:380] Eltwise5 -> Eltwise5
I0117 22:13:17.465164  7680 net.cpp:122] Setting up Eltwise5
I0117 22:13:17.465173  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.465178  7680 net.cpp:137] Memory required for data: 45709280
I0117 22:13:17.465183  7680 layer_factory.hpp:77] Creating layer ReLU11
I0117 22:13:17.465189  7680 net.cpp:84] Creating Layer ReLU11
I0117 22:13:17.465194  7680 net.cpp:406] ReLU11 <- Eltwise5
I0117 22:13:17.465200  7680 net.cpp:367] ReLU11 -> Eltwise5 (in-place)
I0117 22:13:17.465767  7680 net.cpp:122] Setting up ReLU11
I0117 22:13:17.465778  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.465783  7680 net.cpp:137] Memory required for data: 46141920
I0117 22:13:17.465788  7680 layer_factory.hpp:77] Creating layer Eltwise5_ReLU11_0_split
I0117 22:13:17.465796  7680 net.cpp:84] Creating Layer Eltwise5_ReLU11_0_split
I0117 22:13:17.465802  7680 net.cpp:406] Eltwise5_ReLU11_0_split <- Eltwise5
I0117 22:13:17.465811  7680 net.cpp:380] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_0
I0117 22:13:17.465823  7680 net.cpp:380] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_1
I0117 22:13:17.465872  7680 net.cpp:122] Setting up Eltwise5_ReLU11_0_split
I0117 22:13:17.465881  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.465888  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.465891  7680 net.cpp:137] Memory required for data: 47007200
I0117 22:13:17.465896  7680 layer_factory.hpp:77] Creating layer Convolution13
I0117 22:13:17.465909  7680 net.cpp:84] Creating Layer Convolution13
I0117 22:13:17.465914  7680 net.cpp:406] Convolution13 <- Eltwise5_ReLU11_0_split_0
I0117 22:13:17.465921  7680 net.cpp:380] Convolution13 -> Convolution13
I0117 22:13:17.467159  7680 net.cpp:122] Setting up Convolution13
I0117 22:13:17.467172  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.467181  7680 net.cpp:137] Memory required for data: 47439840
I0117 22:13:17.467195  7680 layer_factory.hpp:77] Creating layer BatchNorm13
I0117 22:13:17.467206  7680 net.cpp:84] Creating Layer BatchNorm13
I0117 22:13:17.467211  7680 net.cpp:406] BatchNorm13 <- Convolution13
I0117 22:13:17.467218  7680 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I0117 22:13:17.467465  7680 net.cpp:122] Setting up BatchNorm13
I0117 22:13:17.467475  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.467480  7680 net.cpp:137] Memory required for data: 47872480
I0117 22:13:17.467489  7680 layer_factory.hpp:77] Creating layer Scale13
I0117 22:13:17.467497  7680 net.cpp:84] Creating Layer Scale13
I0117 22:13:17.467504  7680 net.cpp:406] Scale13 <- Convolution13
I0117 22:13:17.467509  7680 net.cpp:367] Scale13 -> Convolution13 (in-place)
I0117 22:13:17.467555  7680 layer_factory.hpp:77] Creating layer Scale13
I0117 22:13:17.467684  7680 net.cpp:122] Setting up Scale13
I0117 22:13:17.467694  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.467700  7680 net.cpp:137] Memory required for data: 48305120
I0117 22:13:17.467706  7680 layer_factory.hpp:77] Creating layer ReLU12
I0117 22:13:17.467715  7680 net.cpp:84] Creating Layer ReLU12
I0117 22:13:17.467720  7680 net.cpp:406] ReLU12 <- Convolution13
I0117 22:13:17.467725  7680 net.cpp:367] ReLU12 -> Convolution13 (in-place)
I0117 22:13:17.468284  7680 net.cpp:122] Setting up ReLU12
I0117 22:13:17.468297  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.468302  7680 net.cpp:137] Memory required for data: 48737760
I0117 22:13:17.468307  7680 layer_factory.hpp:77] Creating layer Convolution14
I0117 22:13:17.468324  7680 net.cpp:84] Creating Layer Convolution14
I0117 22:13:17.468330  7680 net.cpp:406] Convolution14 <- Convolution13
I0117 22:13:17.468338  7680 net.cpp:380] Convolution14 -> Convolution14
I0117 22:13:17.470003  7680 net.cpp:122] Setting up Convolution14
I0117 22:13:17.470016  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.470022  7680 net.cpp:137] Memory required for data: 49170400
I0117 22:13:17.470031  7680 layer_factory.hpp:77] Creating layer BatchNorm14
I0117 22:13:17.470039  7680 net.cpp:84] Creating Layer BatchNorm14
I0117 22:13:17.470044  7680 net.cpp:406] BatchNorm14 <- Convolution14
I0117 22:13:17.470052  7680 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I0117 22:13:17.470268  7680 net.cpp:122] Setting up BatchNorm14
I0117 22:13:17.470276  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.470281  7680 net.cpp:137] Memory required for data: 49603040
I0117 22:13:17.470289  7680 layer_factory.hpp:77] Creating layer Scale14
I0117 22:13:17.470297  7680 net.cpp:84] Creating Layer Scale14
I0117 22:13:17.470302  7680 net.cpp:406] Scale14 <- Convolution14
I0117 22:13:17.470309  7680 net.cpp:367] Scale14 -> Convolution14 (in-place)
I0117 22:13:17.470353  7680 layer_factory.hpp:77] Creating layer Scale14
I0117 22:13:17.470484  7680 net.cpp:122] Setting up Scale14
I0117 22:13:17.470492  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.470497  7680 net.cpp:137] Memory required for data: 50035680
I0117 22:13:17.470504  7680 layer_factory.hpp:77] Creating layer Eltwise6
I0117 22:13:17.470512  7680 net.cpp:84] Creating Layer Eltwise6
I0117 22:13:17.470517  7680 net.cpp:406] Eltwise6 <- Eltwise5_ReLU11_0_split_1
I0117 22:13:17.470523  7680 net.cpp:406] Eltwise6 <- Convolution14
I0117 22:13:17.470532  7680 net.cpp:380] Eltwise6 -> Eltwise6
I0117 22:13:17.470563  7680 net.cpp:122] Setting up Eltwise6
I0117 22:13:17.470572  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.470577  7680 net.cpp:137] Memory required for data: 50468320
I0117 22:13:17.470582  7680 layer_factory.hpp:77] Creating layer ReLU13
I0117 22:13:17.470589  7680 net.cpp:84] Creating Layer ReLU13
I0117 22:13:17.470594  7680 net.cpp:406] ReLU13 <- Eltwise6
I0117 22:13:17.470600  7680 net.cpp:367] ReLU13 -> Eltwise6 (in-place)
I0117 22:13:17.470757  7680 net.cpp:122] Setting up ReLU13
I0117 22:13:17.470772  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.470782  7680 net.cpp:137] Memory required for data: 50900960
I0117 22:13:17.470788  7680 layer_factory.hpp:77] Creating layer Eltwise6_ReLU13_0_split
I0117 22:13:17.470794  7680 net.cpp:84] Creating Layer Eltwise6_ReLU13_0_split
I0117 22:13:17.470799  7680 net.cpp:406] Eltwise6_ReLU13_0_split <- Eltwise6
I0117 22:13:17.470808  7680 net.cpp:380] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_0
I0117 22:13:17.470816  7680 net.cpp:380] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_1
I0117 22:13:17.470862  7680 net.cpp:122] Setting up Eltwise6_ReLU13_0_split
I0117 22:13:17.470871  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.470877  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.470882  7680 net.cpp:137] Memory required for data: 51766240
I0117 22:13:17.470886  7680 layer_factory.hpp:77] Creating layer Convolution15
I0117 22:13:17.470897  7680 net.cpp:84] Creating Layer Convolution15
I0117 22:13:17.470902  7680 net.cpp:406] Convolution15 <- Eltwise6_ReLU13_0_split_0
I0117 22:13:17.470911  7680 net.cpp:380] Convolution15 -> Convolution15
I0117 22:13:17.472574  7680 net.cpp:122] Setting up Convolution15
I0117 22:13:17.472589  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.472594  7680 net.cpp:137] Memory required for data: 52198880
I0117 22:13:17.472601  7680 layer_factory.hpp:77] Creating layer BatchNorm15
I0117 22:13:17.472610  7680 net.cpp:84] Creating Layer BatchNorm15
I0117 22:13:17.472616  7680 net.cpp:406] BatchNorm15 <- Convolution15
I0117 22:13:17.472623  7680 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I0117 22:13:17.472842  7680 net.cpp:122] Setting up BatchNorm15
I0117 22:13:17.472851  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.472856  7680 net.cpp:137] Memory required for data: 52631520
I0117 22:13:17.472865  7680 layer_factory.hpp:77] Creating layer Scale15
I0117 22:13:17.472872  7680 net.cpp:84] Creating Layer Scale15
I0117 22:13:17.472877  7680 net.cpp:406] Scale15 <- Convolution15
I0117 22:13:17.472883  7680 net.cpp:367] Scale15 -> Convolution15 (in-place)
I0117 22:13:17.472930  7680 layer_factory.hpp:77] Creating layer Scale15
I0117 22:13:17.473062  7680 net.cpp:122] Setting up Scale15
I0117 22:13:17.473071  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.473076  7680 net.cpp:137] Memory required for data: 53064160
I0117 22:13:17.473084  7680 layer_factory.hpp:77] Creating layer ReLU14
I0117 22:13:17.473090  7680 net.cpp:84] Creating Layer ReLU14
I0117 22:13:17.473104  7680 net.cpp:406] ReLU14 <- Convolution15
I0117 22:13:17.473110  7680 net.cpp:367] ReLU14 -> Convolution15 (in-place)
I0117 22:13:17.473858  7680 net.cpp:122] Setting up ReLU14
I0117 22:13:17.473877  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.473883  7680 net.cpp:137] Memory required for data: 53496800
I0117 22:13:17.473889  7680 layer_factory.hpp:77] Creating layer Convolution16
I0117 22:13:17.473902  7680 net.cpp:84] Creating Layer Convolution16
I0117 22:13:17.473908  7680 net.cpp:406] Convolution16 <- Convolution15
I0117 22:13:17.473917  7680 net.cpp:380] Convolution16 -> Convolution16
I0117 22:13:17.475817  7680 net.cpp:122] Setting up Convolution16
I0117 22:13:17.475839  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.475845  7680 net.cpp:137] Memory required for data: 53929440
I0117 22:13:17.475854  7680 layer_factory.hpp:77] Creating layer BatchNorm16
I0117 22:13:17.475862  7680 net.cpp:84] Creating Layer BatchNorm16
I0117 22:13:17.475868  7680 net.cpp:406] BatchNorm16 <- Convolution16
I0117 22:13:17.475877  7680 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I0117 22:13:17.476106  7680 net.cpp:122] Setting up BatchNorm16
I0117 22:13:17.476116  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.476121  7680 net.cpp:137] Memory required for data: 54362080
I0117 22:13:17.476130  7680 layer_factory.hpp:77] Creating layer Scale16
I0117 22:13:17.476137  7680 net.cpp:84] Creating Layer Scale16
I0117 22:13:17.476148  7680 net.cpp:406] Scale16 <- Convolution16
I0117 22:13:17.476161  7680 net.cpp:367] Scale16 -> Convolution16 (in-place)
I0117 22:13:17.476210  7680 layer_factory.hpp:77] Creating layer Scale16
I0117 22:13:17.476348  7680 net.cpp:122] Setting up Scale16
I0117 22:13:17.476357  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.476362  7680 net.cpp:137] Memory required for data: 54794720
I0117 22:13:17.476371  7680 layer_factory.hpp:77] Creating layer Eltwise7
I0117 22:13:17.476377  7680 net.cpp:84] Creating Layer Eltwise7
I0117 22:13:17.476383  7680 net.cpp:406] Eltwise7 <- Eltwise6_ReLU13_0_split_1
I0117 22:13:17.476388  7680 net.cpp:406] Eltwise7 <- Convolution16
I0117 22:13:17.476395  7680 net.cpp:380] Eltwise7 -> Eltwise7
I0117 22:13:17.476426  7680 net.cpp:122] Setting up Eltwise7
I0117 22:13:17.476438  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.476442  7680 net.cpp:137] Memory required for data: 55227360
I0117 22:13:17.476447  7680 layer_factory.hpp:77] Creating layer ReLU15
I0117 22:13:17.476454  7680 net.cpp:84] Creating Layer ReLU15
I0117 22:13:17.476459  7680 net.cpp:406] ReLU15 <- Eltwise7
I0117 22:13:17.476465  7680 net.cpp:367] ReLU15 -> Eltwise7 (in-place)
I0117 22:13:17.477092  7680 net.cpp:122] Setting up ReLU15
I0117 22:13:17.477110  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.477115  7680 net.cpp:137] Memory required for data: 55660000
I0117 22:13:17.477121  7680 layer_factory.hpp:77] Creating layer Eltwise7_ReLU15_0_split
I0117 22:13:17.477130  7680 net.cpp:84] Creating Layer Eltwise7_ReLU15_0_split
I0117 22:13:17.477136  7680 net.cpp:406] Eltwise7_ReLU15_0_split <- Eltwise7
I0117 22:13:17.477144  7680 net.cpp:380] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_0
I0117 22:13:17.477154  7680 net.cpp:380] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_1
I0117 22:13:17.477208  7680 net.cpp:122] Setting up Eltwise7_ReLU15_0_split
I0117 22:13:17.477218  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.477224  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.477229  7680 net.cpp:137] Memory required for data: 56525280
I0117 22:13:17.477234  7680 layer_factory.hpp:77] Creating layer Convolution17
I0117 22:13:17.477247  7680 net.cpp:84] Creating Layer Convolution17
I0117 22:13:17.477253  7680 net.cpp:406] Convolution17 <- Eltwise7_ReLU15_0_split_0
I0117 22:13:17.477263  7680 net.cpp:380] Convolution17 -> Convolution17
I0117 22:13:17.479176  7680 net.cpp:122] Setting up Convolution17
I0117 22:13:17.479205  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.479212  7680 net.cpp:137] Memory required for data: 56957920
I0117 22:13:17.479223  7680 layer_factory.hpp:77] Creating layer BatchNorm17
I0117 22:13:17.479234  7680 net.cpp:84] Creating Layer BatchNorm17
I0117 22:13:17.479240  7680 net.cpp:406] BatchNorm17 <- Convolution17
I0117 22:13:17.479249  7680 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I0117 22:13:17.479528  7680 net.cpp:122] Setting up BatchNorm17
I0117 22:13:17.479542  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.479547  7680 net.cpp:137] Memory required for data: 57390560
I0117 22:13:17.479557  7680 layer_factory.hpp:77] Creating layer Scale17
I0117 22:13:17.479566  7680 net.cpp:84] Creating Layer Scale17
I0117 22:13:17.479573  7680 net.cpp:406] Scale17 <- Convolution17
I0117 22:13:17.479581  7680 net.cpp:367] Scale17 -> Convolution17 (in-place)
I0117 22:13:17.479640  7680 layer_factory.hpp:77] Creating layer Scale17
I0117 22:13:17.479794  7680 net.cpp:122] Setting up Scale17
I0117 22:13:17.479805  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.479810  7680 net.cpp:137] Memory required for data: 57823200
I0117 22:13:17.479818  7680 layer_factory.hpp:77] Creating layer ReLU16
I0117 22:13:17.479826  7680 net.cpp:84] Creating Layer ReLU16
I0117 22:13:17.479831  7680 net.cpp:406] ReLU16 <- Convolution17
I0117 22:13:17.479840  7680 net.cpp:367] ReLU16 -> Convolution17 (in-place)
I0117 22:13:17.480023  7680 net.cpp:122] Setting up ReLU16
I0117 22:13:17.480042  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.480057  7680 net.cpp:137] Memory required for data: 58255840
I0117 22:13:17.480062  7680 layer_factory.hpp:77] Creating layer Convolution18
I0117 22:13:17.480077  7680 net.cpp:84] Creating Layer Convolution18
I0117 22:13:17.480082  7680 net.cpp:406] Convolution18 <- Convolution17
I0117 22:13:17.480092  7680 net.cpp:380] Convolution18 -> Convolution18
I0117 22:13:17.482005  7680 net.cpp:122] Setting up Convolution18
I0117 22:13:17.482039  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.482045  7680 net.cpp:137] Memory required for data: 58688480
I0117 22:13:17.482056  7680 layer_factory.hpp:77] Creating layer BatchNorm18
I0117 22:13:17.482069  7680 net.cpp:84] Creating Layer BatchNorm18
I0117 22:13:17.482076  7680 net.cpp:406] BatchNorm18 <- Convolution18
I0117 22:13:17.482085  7680 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I0117 22:13:17.482363  7680 net.cpp:122] Setting up BatchNorm18
I0117 22:13:17.482375  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.482380  7680 net.cpp:137] Memory required for data: 59121120
I0117 22:13:17.482390  7680 layer_factory.hpp:77] Creating layer Scale18
I0117 22:13:17.482399  7680 net.cpp:84] Creating Layer Scale18
I0117 22:13:17.482405  7680 net.cpp:406] Scale18 <- Convolution18
I0117 22:13:17.482411  7680 net.cpp:367] Scale18 -> Convolution18 (in-place)
I0117 22:13:17.482823  7680 layer_factory.hpp:77] Creating layer Scale18
I0117 22:13:17.482946  7680 net.cpp:122] Setting up Scale18
I0117 22:13:17.482957  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.482962  7680 net.cpp:137] Memory required for data: 59553760
I0117 22:13:17.482971  7680 layer_factory.hpp:77] Creating layer Eltwise8
I0117 22:13:17.482980  7680 net.cpp:84] Creating Layer Eltwise8
I0117 22:13:17.482986  7680 net.cpp:406] Eltwise8 <- Eltwise7_ReLU15_0_split_1
I0117 22:13:17.482992  7680 net.cpp:406] Eltwise8 <- Convolution18
I0117 22:13:17.483006  7680 net.cpp:380] Eltwise8 -> Eltwise8
I0117 22:13:17.483036  7680 net.cpp:122] Setting up Eltwise8
I0117 22:13:17.483044  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.483049  7680 net.cpp:137] Memory required for data: 59986400
I0117 22:13:17.483054  7680 layer_factory.hpp:77] Creating layer ReLU17
I0117 22:13:17.483062  7680 net.cpp:84] Creating Layer ReLU17
I0117 22:13:17.483067  7680 net.cpp:406] ReLU17 <- Eltwise8
I0117 22:13:17.483072  7680 net.cpp:367] ReLU17 -> Eltwise8 (in-place)
I0117 22:13:17.483762  7680 net.cpp:122] Setting up ReLU17
I0117 22:13:17.483780  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.483785  7680 net.cpp:137] Memory required for data: 60419040
I0117 22:13:17.483790  7680 layer_factory.hpp:77] Creating layer Eltwise8_ReLU17_0_split
I0117 22:13:17.483800  7680 net.cpp:84] Creating Layer Eltwise8_ReLU17_0_split
I0117 22:13:17.483805  7680 net.cpp:406] Eltwise8_ReLU17_0_split <- Eltwise8
I0117 22:13:17.483814  7680 net.cpp:380] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_0
I0117 22:13:17.483824  7680 net.cpp:380] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_1
I0117 22:13:17.483832  7680 net.cpp:380] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_2
I0117 22:13:17.483885  7680 net.cpp:122] Setting up Eltwise8_ReLU17_0_split
I0117 22:13:17.483894  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.483901  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.483906  7680 net.cpp:129] Top shape: 20 32 13 13 (108160)
I0117 22:13:17.483909  7680 net.cpp:137] Memory required for data: 61716960
I0117 22:13:17.483914  7680 layer_factory.hpp:77] Creating layer Convolution19
I0117 22:13:17.483928  7680 net.cpp:84] Creating Layer Convolution19
I0117 22:13:17.483934  7680 net.cpp:406] Convolution19 <- Eltwise8_ReLU17_0_split_0
I0117 22:13:17.483942  7680 net.cpp:380] Convolution19 -> Convolution19
I0117 22:13:17.485221  7680 net.cpp:122] Setting up Convolution19
I0117 22:13:17.485242  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.485257  7680 net.cpp:137] Memory required for data: 61967840
I0117 22:13:17.485275  7680 layer_factory.hpp:77] Creating layer BatchNorm19
I0117 22:13:17.485285  7680 net.cpp:84] Creating Layer BatchNorm19
I0117 22:13:17.485291  7680 net.cpp:406] BatchNorm19 <- Convolution19
I0117 22:13:17.485299  7680 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I0117 22:13:17.485499  7680 net.cpp:122] Setting up BatchNorm19
I0117 22:13:17.485509  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.485514  7680 net.cpp:137] Memory required for data: 62218720
I0117 22:13:17.485543  7680 layer_factory.hpp:77] Creating layer Scale19
I0117 22:13:17.485553  7680 net.cpp:84] Creating Layer Scale19
I0117 22:13:17.485558  7680 net.cpp:406] Scale19 <- Convolution19
I0117 22:13:17.485566  7680 net.cpp:367] Scale19 -> Convolution19 (in-place)
I0117 22:13:17.485610  7680 layer_factory.hpp:77] Creating layer Scale19
I0117 22:13:17.485723  7680 net.cpp:122] Setting up Scale19
I0117 22:13:17.485733  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.485738  7680 net.cpp:137] Memory required for data: 62469600
I0117 22:13:17.485746  7680 layer_factory.hpp:77] Creating layer Convolution20
I0117 22:13:17.485759  7680 net.cpp:84] Creating Layer Convolution20
I0117 22:13:17.485764  7680 net.cpp:406] Convolution20 <- Eltwise8_ReLU17_0_split_1
I0117 22:13:17.485774  7680 net.cpp:380] Convolution20 -> Convolution20
I0117 22:13:17.487843  7680 net.cpp:122] Setting up Convolution20
I0117 22:13:17.487876  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.487884  7680 net.cpp:137] Memory required for data: 62720480
I0117 22:13:17.487895  7680 layer_factory.hpp:77] Creating layer BatchNorm20
I0117 22:13:17.487906  7680 net.cpp:84] Creating Layer BatchNorm20
I0117 22:13:17.487913  7680 net.cpp:406] BatchNorm20 <- Convolution20
I0117 22:13:17.487923  7680 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I0117 22:13:17.488101  7680 net.cpp:122] Setting up BatchNorm20
I0117 22:13:17.488111  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.488116  7680 net.cpp:137] Memory required for data: 62971360
I0117 22:13:17.488126  7680 layer_factory.hpp:77] Creating layer Scale20
I0117 22:13:17.488137  7680 net.cpp:84] Creating Layer Scale20
I0117 22:13:17.488142  7680 net.cpp:406] Scale20 <- Convolution20
I0117 22:13:17.488148  7680 net.cpp:367] Scale20 -> Convolution20 (in-place)
I0117 22:13:17.488200  7680 layer_factory.hpp:77] Creating layer Scale20
I0117 22:13:17.488323  7680 net.cpp:122] Setting up Scale20
I0117 22:13:17.488333  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.488338  7680 net.cpp:137] Memory required for data: 63222240
I0117 22:13:17.488346  7680 layer_factory.hpp:77] Creating layer ReLU18
I0117 22:13:17.488355  7680 net.cpp:84] Creating Layer ReLU18
I0117 22:13:17.488360  7680 net.cpp:406] ReLU18 <- Convolution20
I0117 22:13:17.488368  7680 net.cpp:367] ReLU18 -> Convolution20 (in-place)
I0117 22:13:17.489619  7680 net.cpp:122] Setting up ReLU18
I0117 22:13:17.489640  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.489645  7680 net.cpp:137] Memory required for data: 63473120
I0117 22:13:17.489651  7680 layer_factory.hpp:77] Creating layer Convolution21
I0117 22:13:17.489676  7680 net.cpp:84] Creating Layer Convolution21
I0117 22:13:17.489682  7680 net.cpp:406] Convolution21 <- Convolution20
I0117 22:13:17.489692  7680 net.cpp:380] Convolution21 -> Convolution21
I0117 22:13:17.492233  7680 net.cpp:122] Setting up Convolution21
I0117 22:13:17.492250  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.492256  7680 net.cpp:137] Memory required for data: 63724000
I0117 22:13:17.492265  7680 layer_factory.hpp:77] Creating layer BatchNorm21
I0117 22:13:17.492275  7680 net.cpp:84] Creating Layer BatchNorm21
I0117 22:13:17.492281  7680 net.cpp:406] BatchNorm21 <- Convolution21
I0117 22:13:17.492290  7680 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I0117 22:13:17.492462  7680 net.cpp:122] Setting up BatchNorm21
I0117 22:13:17.492472  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.492486  7680 net.cpp:137] Memory required for data: 63974880
I0117 22:13:17.492501  7680 layer_factory.hpp:77] Creating layer Scale21
I0117 22:13:17.492512  7680 net.cpp:84] Creating Layer Scale21
I0117 22:13:17.492517  7680 net.cpp:406] Scale21 <- Convolution21
I0117 22:13:17.492524  7680 net.cpp:367] Scale21 -> Convolution21 (in-place)
I0117 22:13:17.492565  7680 layer_factory.hpp:77] Creating layer Scale21
I0117 22:13:17.492667  7680 net.cpp:122] Setting up Scale21
I0117 22:13:17.492677  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.492682  7680 net.cpp:137] Memory required for data: 64225760
I0117 22:13:17.492689  7680 layer_factory.hpp:77] Creating layer Eltwise9
I0117 22:13:17.492698  7680 net.cpp:84] Creating Layer Eltwise9
I0117 22:13:17.492704  7680 net.cpp:406] Eltwise9 <- Convolution19
I0117 22:13:17.492710  7680 net.cpp:406] Eltwise9 <- Convolution21
I0117 22:13:17.492718  7680 net.cpp:380] Eltwise9 -> Eltwise9
I0117 22:13:17.492743  7680 net.cpp:122] Setting up Eltwise9
I0117 22:13:17.492751  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.492756  7680 net.cpp:137] Memory required for data: 64476640
I0117 22:13:17.492761  7680 layer_factory.hpp:77] Creating layer ReLU19
I0117 22:13:17.492769  7680 net.cpp:84] Creating Layer ReLU19
I0117 22:13:17.492775  7680 net.cpp:406] ReLU19 <- Eltwise9
I0117 22:13:17.492781  7680 net.cpp:367] ReLU19 -> Eltwise9 (in-place)
I0117 22:13:17.492956  7680 net.cpp:122] Setting up ReLU19
I0117 22:13:17.492967  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.492972  7680 net.cpp:137] Memory required for data: 64727520
I0117 22:13:17.492977  7680 layer_factory.hpp:77] Creating layer Eltwise9_ReLU19_0_split
I0117 22:13:17.492986  7680 net.cpp:84] Creating Layer Eltwise9_ReLU19_0_split
I0117 22:13:17.492992  7680 net.cpp:406] Eltwise9_ReLU19_0_split <- Eltwise9
I0117 22:13:17.493000  7680 net.cpp:380] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_0
I0117 22:13:17.493010  7680 net.cpp:380] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_1
I0117 22:13:17.493046  7680 net.cpp:122] Setting up Eltwise9_ReLU19_0_split
I0117 22:13:17.493054  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.493060  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.493065  7680 net.cpp:137] Memory required for data: 65229280
I0117 22:13:17.493069  7680 layer_factory.hpp:77] Creating layer Convolution22
I0117 22:13:17.493080  7680 net.cpp:84] Creating Layer Convolution22
I0117 22:13:17.493086  7680 net.cpp:406] Convolution22 <- Eltwise9_ReLU19_0_split_0
I0117 22:13:17.493095  7680 net.cpp:380] Convolution22 -> Convolution22
I0117 22:13:17.495429  7680 net.cpp:122] Setting up Convolution22
I0117 22:13:17.495443  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.495448  7680 net.cpp:137] Memory required for data: 65480160
I0117 22:13:17.495457  7680 layer_factory.hpp:77] Creating layer BatchNorm22
I0117 22:13:17.495466  7680 net.cpp:84] Creating Layer BatchNorm22
I0117 22:13:17.495471  7680 net.cpp:406] BatchNorm22 <- Convolution22
I0117 22:13:17.495478  7680 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I0117 22:13:17.495640  7680 net.cpp:122] Setting up BatchNorm22
I0117 22:13:17.495649  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.495654  7680 net.cpp:137] Memory required for data: 65731040
I0117 22:13:17.495662  7680 layer_factory.hpp:77] Creating layer Scale22
I0117 22:13:17.495671  7680 net.cpp:84] Creating Layer Scale22
I0117 22:13:17.495676  7680 net.cpp:406] Scale22 <- Convolution22
I0117 22:13:17.495682  7680 net.cpp:367] Scale22 -> Convolution22 (in-place)
I0117 22:13:17.495720  7680 layer_factory.hpp:77] Creating layer Scale22
I0117 22:13:17.495820  7680 net.cpp:122] Setting up Scale22
I0117 22:13:17.495831  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.495836  7680 net.cpp:137] Memory required for data: 65981920
I0117 22:13:17.495842  7680 layer_factory.hpp:77] Creating layer ReLU20
I0117 22:13:17.495849  7680 net.cpp:84] Creating Layer ReLU20
I0117 22:13:17.495858  7680 net.cpp:406] ReLU20 <- Convolution22
I0117 22:13:17.495870  7680 net.cpp:367] ReLU20 -> Convolution22 (in-place)
I0117 22:13:17.496042  7680 net.cpp:122] Setting up ReLU20
I0117 22:13:17.496054  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.496059  7680 net.cpp:137] Memory required for data: 66232800
I0117 22:13:17.496064  7680 layer_factory.hpp:77] Creating layer Convolution23
I0117 22:13:17.496075  7680 net.cpp:84] Creating Layer Convolution23
I0117 22:13:17.496080  7680 net.cpp:406] Convolution23 <- Convolution22
I0117 22:13:17.496088  7680 net.cpp:380] Convolution23 -> Convolution23
I0117 22:13:17.498351  7680 net.cpp:122] Setting up Convolution23
I0117 22:13:17.498364  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.498369  7680 net.cpp:137] Memory required for data: 66483680
I0117 22:13:17.498376  7680 layer_factory.hpp:77] Creating layer BatchNorm23
I0117 22:13:17.498386  7680 net.cpp:84] Creating Layer BatchNorm23
I0117 22:13:17.498391  7680 net.cpp:406] BatchNorm23 <- Convolution23
I0117 22:13:17.498399  7680 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I0117 22:13:17.498560  7680 net.cpp:122] Setting up BatchNorm23
I0117 22:13:17.498569  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.498574  7680 net.cpp:137] Memory required for data: 66734560
I0117 22:13:17.498582  7680 layer_factory.hpp:77] Creating layer Scale23
I0117 22:13:17.498589  7680 net.cpp:84] Creating Layer Scale23
I0117 22:13:17.498594  7680 net.cpp:406] Scale23 <- Convolution23
I0117 22:13:17.498600  7680 net.cpp:367] Scale23 -> Convolution23 (in-place)
I0117 22:13:17.498638  7680 layer_factory.hpp:77] Creating layer Scale23
I0117 22:13:17.498738  7680 net.cpp:122] Setting up Scale23
I0117 22:13:17.498746  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.498751  7680 net.cpp:137] Memory required for data: 66985440
I0117 22:13:17.498759  7680 layer_factory.hpp:77] Creating layer Eltwise10
I0117 22:13:17.498767  7680 net.cpp:84] Creating Layer Eltwise10
I0117 22:13:17.498772  7680 net.cpp:406] Eltwise10 <- Eltwise9_ReLU19_0_split_1
I0117 22:13:17.498778  7680 net.cpp:406] Eltwise10 <- Convolution23
I0117 22:13:17.498785  7680 net.cpp:380] Eltwise10 -> Eltwise10
I0117 22:13:17.498809  7680 net.cpp:122] Setting up Eltwise10
I0117 22:13:17.498817  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.498822  7680 net.cpp:137] Memory required for data: 67236320
I0117 22:13:17.498826  7680 layer_factory.hpp:77] Creating layer ReLU21
I0117 22:13:17.498833  7680 net.cpp:84] Creating Layer ReLU21
I0117 22:13:17.498838  7680 net.cpp:406] ReLU21 <- Eltwise10
I0117 22:13:17.498845  7680 net.cpp:367] ReLU21 -> Eltwise10 (in-place)
I0117 22:13:17.499430  7680 net.cpp:122] Setting up ReLU21
I0117 22:13:17.499444  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.499449  7680 net.cpp:137] Memory required for data: 67487200
I0117 22:13:17.499454  7680 layer_factory.hpp:77] Creating layer Eltwise10_ReLU21_0_split
I0117 22:13:17.499460  7680 net.cpp:84] Creating Layer Eltwise10_ReLU21_0_split
I0117 22:13:17.499465  7680 net.cpp:406] Eltwise10_ReLU21_0_split <- Eltwise10
I0117 22:13:17.499474  7680 net.cpp:380] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_0
I0117 22:13:17.499482  7680 net.cpp:380] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_1
I0117 22:13:17.499521  7680 net.cpp:122] Setting up Eltwise10_ReLU21_0_split
I0117 22:13:17.499529  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.499536  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.499539  7680 net.cpp:137] Memory required for data: 67988960
I0117 22:13:17.499544  7680 layer_factory.hpp:77] Creating layer Convolution24
I0117 22:13:17.499555  7680 net.cpp:84] Creating Layer Convolution24
I0117 22:13:17.499562  7680 net.cpp:406] Convolution24 <- Eltwise10_ReLU21_0_split_0
I0117 22:13:17.499568  7680 net.cpp:380] Convolution24 -> Convolution24
I0117 22:13:17.501822  7680 net.cpp:122] Setting up Convolution24
I0117 22:13:17.501837  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.501850  7680 net.cpp:137] Memory required for data: 68239840
I0117 22:13:17.501859  7680 layer_factory.hpp:77] Creating layer BatchNorm24
I0117 22:13:17.501866  7680 net.cpp:84] Creating Layer BatchNorm24
I0117 22:13:17.501873  7680 net.cpp:406] BatchNorm24 <- Convolution24
I0117 22:13:17.501880  7680 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I0117 22:13:17.502064  7680 net.cpp:122] Setting up BatchNorm24
I0117 22:13:17.502074  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.502079  7680 net.cpp:137] Memory required for data: 68490720
I0117 22:13:17.502087  7680 layer_factory.hpp:77] Creating layer Scale24
I0117 22:13:17.502095  7680 net.cpp:84] Creating Layer Scale24
I0117 22:13:17.502101  7680 net.cpp:406] Scale24 <- Convolution24
I0117 22:13:17.502107  7680 net.cpp:367] Scale24 -> Convolution24 (in-place)
I0117 22:13:17.502144  7680 layer_factory.hpp:77] Creating layer Scale24
I0117 22:13:17.502246  7680 net.cpp:122] Setting up Scale24
I0117 22:13:17.502255  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.502260  7680 net.cpp:137] Memory required for data: 68741600
I0117 22:13:17.502267  7680 layer_factory.hpp:77] Creating layer ReLU22
I0117 22:13:17.502274  7680 net.cpp:84] Creating Layer ReLU22
I0117 22:13:17.502279  7680 net.cpp:406] ReLU22 <- Convolution24
I0117 22:13:17.502285  7680 net.cpp:367] ReLU22 -> Convolution24 (in-place)
I0117 22:13:17.502456  7680 net.cpp:122] Setting up ReLU22
I0117 22:13:17.502466  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.502471  7680 net.cpp:137] Memory required for data: 68992480
I0117 22:13:17.502476  7680 layer_factory.hpp:77] Creating layer Convolution25
I0117 22:13:17.502487  7680 net.cpp:84] Creating Layer Convolution25
I0117 22:13:17.502492  7680 net.cpp:406] Convolution25 <- Convolution24
I0117 22:13:17.502501  7680 net.cpp:380] Convolution25 -> Convolution25
I0117 22:13:17.504777  7680 net.cpp:122] Setting up Convolution25
I0117 22:13:17.504793  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.504798  7680 net.cpp:137] Memory required for data: 69243360
I0117 22:13:17.504806  7680 layer_factory.hpp:77] Creating layer BatchNorm25
I0117 22:13:17.504815  7680 net.cpp:84] Creating Layer BatchNorm25
I0117 22:13:17.504820  7680 net.cpp:406] BatchNorm25 <- Convolution25
I0117 22:13:17.504827  7680 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I0117 22:13:17.504995  7680 net.cpp:122] Setting up BatchNorm25
I0117 22:13:17.505005  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.505009  7680 net.cpp:137] Memory required for data: 69494240
I0117 22:13:17.505018  7680 layer_factory.hpp:77] Creating layer Scale25
I0117 22:13:17.505025  7680 net.cpp:84] Creating Layer Scale25
I0117 22:13:17.505030  7680 net.cpp:406] Scale25 <- Convolution25
I0117 22:13:17.505036  7680 net.cpp:367] Scale25 -> Convolution25 (in-place)
I0117 22:13:17.505072  7680 layer_factory.hpp:77] Creating layer Scale25
I0117 22:13:17.505173  7680 net.cpp:122] Setting up Scale25
I0117 22:13:17.505182  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.505187  7680 net.cpp:137] Memory required for data: 69745120
I0117 22:13:17.505194  7680 layer_factory.hpp:77] Creating layer Eltwise11
I0117 22:13:17.505201  7680 net.cpp:84] Creating Layer Eltwise11
I0117 22:13:17.505206  7680 net.cpp:406] Eltwise11 <- Eltwise10_ReLU21_0_split_1
I0117 22:13:17.505213  7680 net.cpp:406] Eltwise11 <- Convolution25
I0117 22:13:17.505220  7680 net.cpp:380] Eltwise11 -> Eltwise11
I0117 22:13:17.505244  7680 net.cpp:122] Setting up Eltwise11
I0117 22:13:17.505251  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.505256  7680 net.cpp:137] Memory required for data: 69996000
I0117 22:13:17.505261  7680 layer_factory.hpp:77] Creating layer ReLU23
I0117 22:13:17.505270  7680 net.cpp:84] Creating Layer ReLU23
I0117 22:13:17.505275  7680 net.cpp:406] ReLU23 <- Eltwise11
I0117 22:13:17.505280  7680 net.cpp:367] ReLU23 -> Eltwise11 (in-place)
I0117 22:13:17.505451  7680 net.cpp:122] Setting up ReLU23
I0117 22:13:17.505465  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.505475  7680 net.cpp:137] Memory required for data: 70246880
I0117 22:13:17.505481  7680 layer_factory.hpp:77] Creating layer Eltwise11_ReLU23_0_split
I0117 22:13:17.505487  7680 net.cpp:84] Creating Layer Eltwise11_ReLU23_0_split
I0117 22:13:17.505492  7680 net.cpp:406] Eltwise11_ReLU23_0_split <- Eltwise11
I0117 22:13:17.505501  7680 net.cpp:380] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_0
I0117 22:13:17.505518  7680 net.cpp:380] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_1
I0117 22:13:17.505554  7680 net.cpp:122] Setting up Eltwise11_ReLU23_0_split
I0117 22:13:17.505566  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.505573  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.505576  7680 net.cpp:137] Memory required for data: 70748640
I0117 22:13:17.505581  7680 layer_factory.hpp:77] Creating layer Convolution26
I0117 22:13:17.505590  7680 net.cpp:84] Creating Layer Convolution26
I0117 22:13:17.505596  7680 net.cpp:406] Convolution26 <- Eltwise11_ReLU23_0_split_0
I0117 22:13:17.505605  7680 net.cpp:380] Convolution26 -> Convolution26
I0117 22:13:17.508395  7680 net.cpp:122] Setting up Convolution26
I0117 22:13:17.508415  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.508420  7680 net.cpp:137] Memory required for data: 70999520
I0117 22:13:17.508430  7680 layer_factory.hpp:77] Creating layer BatchNorm26
I0117 22:13:17.508440  7680 net.cpp:84] Creating Layer BatchNorm26
I0117 22:13:17.508445  7680 net.cpp:406] BatchNorm26 <- Convolution26
I0117 22:13:17.508452  7680 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I0117 22:13:17.508635  7680 net.cpp:122] Setting up BatchNorm26
I0117 22:13:17.508646  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.508651  7680 net.cpp:137] Memory required for data: 71250400
I0117 22:13:17.508659  7680 layer_factory.hpp:77] Creating layer Scale26
I0117 22:13:17.508666  7680 net.cpp:84] Creating Layer Scale26
I0117 22:13:17.508672  7680 net.cpp:406] Scale26 <- Convolution26
I0117 22:13:17.508679  7680 net.cpp:367] Scale26 -> Convolution26 (in-place)
I0117 22:13:17.508718  7680 layer_factory.hpp:77] Creating layer Scale26
I0117 22:13:17.508828  7680 net.cpp:122] Setting up Scale26
I0117 22:13:17.508838  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.508843  7680 net.cpp:137] Memory required for data: 71501280
I0117 22:13:17.508850  7680 layer_factory.hpp:77] Creating layer ReLU24
I0117 22:13:17.508857  7680 net.cpp:84] Creating Layer ReLU24
I0117 22:13:17.508863  7680 net.cpp:406] ReLU24 <- Convolution26
I0117 22:13:17.508870  7680 net.cpp:367] ReLU24 -> Convolution26 (in-place)
I0117 22:13:17.509464  7680 net.cpp:122] Setting up ReLU24
I0117 22:13:17.509476  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.509481  7680 net.cpp:137] Memory required for data: 71752160
I0117 22:13:17.509486  7680 layer_factory.hpp:77] Creating layer Convolution27
I0117 22:13:17.509498  7680 net.cpp:84] Creating Layer Convolution27
I0117 22:13:17.509505  7680 net.cpp:406] Convolution27 <- Convolution26
I0117 22:13:17.509513  7680 net.cpp:380] Convolution27 -> Convolution27
I0117 22:13:17.511833  7680 net.cpp:122] Setting up Convolution27
I0117 22:13:17.511847  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.511852  7680 net.cpp:137] Memory required for data: 72003040
I0117 22:13:17.511860  7680 layer_factory.hpp:77] Creating layer BatchNorm27
I0117 22:13:17.511883  7680 net.cpp:84] Creating Layer BatchNorm27
I0117 22:13:17.511888  7680 net.cpp:406] BatchNorm27 <- Convolution27
I0117 22:13:17.511895  7680 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I0117 22:13:17.512068  7680 net.cpp:122] Setting up BatchNorm27
I0117 22:13:17.512078  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.512082  7680 net.cpp:137] Memory required for data: 72253920
I0117 22:13:17.512091  7680 layer_factory.hpp:77] Creating layer Scale27
I0117 22:13:17.512099  7680 net.cpp:84] Creating Layer Scale27
I0117 22:13:17.512109  7680 net.cpp:406] Scale27 <- Convolution27
I0117 22:13:17.512123  7680 net.cpp:367] Scale27 -> Convolution27 (in-place)
I0117 22:13:17.512163  7680 layer_factory.hpp:77] Creating layer Scale27
I0117 22:13:17.512267  7680 net.cpp:122] Setting up Scale27
I0117 22:13:17.512276  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.512281  7680 net.cpp:137] Memory required for data: 72504800
I0117 22:13:17.512289  7680 layer_factory.hpp:77] Creating layer Eltwise12
I0117 22:13:17.512297  7680 net.cpp:84] Creating Layer Eltwise12
I0117 22:13:17.512303  7680 net.cpp:406] Eltwise12 <- Eltwise11_ReLU23_0_split_1
I0117 22:13:17.512310  7680 net.cpp:406] Eltwise12 <- Convolution27
I0117 22:13:17.512316  7680 net.cpp:380] Eltwise12 -> Eltwise12
I0117 22:13:17.512341  7680 net.cpp:122] Setting up Eltwise12
I0117 22:13:17.512349  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.512354  7680 net.cpp:137] Memory required for data: 72755680
I0117 22:13:17.512359  7680 layer_factory.hpp:77] Creating layer Convolution_eltwise4
I0117 22:13:17.512370  7680 net.cpp:84] Creating Layer Convolution_eltwise4
I0117 22:13:17.512377  7680 net.cpp:406] Convolution_eltwise4 <- Eltwise4_ReLU9_0_split_2
I0117 22:13:17.512384  7680 net.cpp:380] Convolution_eltwise4 -> Convolution_eltwise4
I0117 22:13:17.513643  7680 net.cpp:122] Setting up Convolution_eltwise4
I0117 22:13:17.513656  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.513661  7680 net.cpp:137] Memory required for data: 73006560
I0117 22:13:17.513669  7680 layer_factory.hpp:77] Creating layer BatchNorm_Convolution_eltwise4
I0117 22:13:17.513676  7680 net.cpp:84] Creating Layer BatchNorm_Convolution_eltwise4
I0117 22:13:17.513682  7680 net.cpp:406] BatchNorm_Convolution_eltwise4 <- Convolution_eltwise4
I0117 22:13:17.513690  7680 net.cpp:367] BatchNorm_Convolution_eltwise4 -> Convolution_eltwise4 (in-place)
I0117 22:13:17.513864  7680 net.cpp:122] Setting up BatchNorm_Convolution_eltwise4
I0117 22:13:17.513873  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.513878  7680 net.cpp:137] Memory required for data: 73257440
I0117 22:13:17.513886  7680 layer_factory.hpp:77] Creating layer Scale_Convolution_eltwise4
I0117 22:13:17.513893  7680 net.cpp:84] Creating Layer Scale_Convolution_eltwise4
I0117 22:13:17.513900  7680 net.cpp:406] Scale_Convolution_eltwise4 <- Convolution_eltwise4
I0117 22:13:17.513906  7680 net.cpp:367] Scale_Convolution_eltwise4 -> Convolution_eltwise4 (in-place)
I0117 22:13:17.513945  7680 layer_factory.hpp:77] Creating layer Scale_Convolution_eltwise4
I0117 22:13:17.514051  7680 net.cpp:122] Setting up Scale_Convolution_eltwise4
I0117 22:13:17.514060  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.514065  7680 net.cpp:137] Memory required for data: 73508320
I0117 22:13:17.514072  7680 layer_factory.hpp:77] Creating layer Convolution_eltwise8
I0117 22:13:17.514084  7680 net.cpp:84] Creating Layer Convolution_eltwise8
I0117 22:13:17.514091  7680 net.cpp:406] Convolution_eltwise8 <- Eltwise8_ReLU17_0_split_2
I0117 22:13:17.514097  7680 net.cpp:380] Convolution_eltwise8 -> Convolution_eltwise8
I0117 22:13:17.516237  7680 net.cpp:122] Setting up Convolution_eltwise8
I0117 22:13:17.516252  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.516258  7680 net.cpp:137] Memory required for data: 73759200
I0117 22:13:17.516265  7680 layer_factory.hpp:77] Creating layer BatchNorm_Convolution_eltwise8
I0117 22:13:17.516274  7680 net.cpp:84] Creating Layer BatchNorm_Convolution_eltwise8
I0117 22:13:17.516280  7680 net.cpp:406] BatchNorm_Convolution_eltwise8 <- Convolution_eltwise8
I0117 22:13:17.516286  7680 net.cpp:367] BatchNorm_Convolution_eltwise8 -> Convolution_eltwise8 (in-place)
I0117 22:13:17.516458  7680 net.cpp:122] Setting up BatchNorm_Convolution_eltwise8
I0117 22:13:17.516468  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.516472  7680 net.cpp:137] Memory required for data: 74010080
I0117 22:13:17.516480  7680 layer_factory.hpp:77] Creating layer Scale_Convolution_eltwise8
I0117 22:13:17.516492  7680 net.cpp:84] Creating Layer Scale_Convolution_eltwise8
I0117 22:13:17.516504  7680 net.cpp:406] Scale_Convolution_eltwise8 <- Convolution_eltwise8
I0117 22:13:17.516510  7680 net.cpp:367] Scale_Convolution_eltwise8 -> Convolution_eltwise8 (in-place)
I0117 22:13:17.516549  7680 layer_factory.hpp:77] Creating layer Scale_Convolution_eltwise8
I0117 22:13:17.516656  7680 net.cpp:122] Setting up Scale_Convolution_eltwise8
I0117 22:13:17.516665  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.516670  7680 net.cpp:137] Memory required for data: 74260960
I0117 22:13:17.516677  7680 layer_factory.hpp:77] Creating layer fuse1
I0117 22:13:17.516686  7680 net.cpp:84] Creating Layer fuse1
I0117 22:13:17.516692  7680 net.cpp:406] fuse1 <- Convolution_eltwise4
I0117 22:13:17.516697  7680 net.cpp:406] fuse1 <- Convolution_eltwise8
I0117 22:13:17.516705  7680 net.cpp:380] fuse1 -> fuse1
I0117 22:13:17.516729  7680 net.cpp:122] Setting up fuse1
I0117 22:13:17.516737  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.516742  7680 net.cpp:137] Memory required for data: 74511840
I0117 22:13:17.516747  7680 layer_factory.hpp:77] Creating layer fuse2
I0117 22:13:17.516754  7680 net.cpp:84] Creating Layer fuse2
I0117 22:13:17.516760  7680 net.cpp:406] fuse2 <- fuse1
I0117 22:13:17.516767  7680 net.cpp:406] fuse2 <- Eltwise12
I0117 22:13:17.516772  7680 net.cpp:380] fuse2 -> fuse2
I0117 22:13:17.516794  7680 net.cpp:122] Setting up fuse2
I0117 22:13:17.516803  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.516808  7680 net.cpp:137] Memory required for data: 74762720
I0117 22:13:17.516813  7680 layer_factory.hpp:77] Creating layer ReLU25
I0117 22:13:17.516819  7680 net.cpp:84] Creating Layer ReLU25
I0117 22:13:17.516824  7680 net.cpp:406] ReLU25 <- fuse2
I0117 22:13:17.516831  7680 net.cpp:367] ReLU25 -> fuse2 (in-place)
I0117 22:13:17.517411  7680 net.cpp:122] Setting up ReLU25
I0117 22:13:17.517422  7680 net.cpp:129] Top shape: 20 64 7 7 (62720)
I0117 22:13:17.517427  7680 net.cpp:137] Memory required for data: 75013600
I0117 22:13:17.517432  7680 layer_factory.hpp:77] Creating layer Pooling1
I0117 22:13:17.517441  7680 net.cpp:84] Creating Layer Pooling1
I0117 22:13:17.517446  7680 net.cpp:406] Pooling1 <- fuse2
I0117 22:13:17.517453  7680 net.cpp:380] Pooling1 -> Pooling1
I0117 22:13:17.517635  7680 net.cpp:122] Setting up Pooling1
I0117 22:13:17.517647  7680 net.cpp:129] Top shape: 20 64 1 1 (1280)
I0117 22:13:17.517652  7680 net.cpp:137] Memory required for data: 75018720
I0117 22:13:17.517657  7680 layer_factory.hpp:77] Creating layer InnerProduct1
I0117 22:13:17.517666  7680 net.cpp:84] Creating Layer InnerProduct1
I0117 22:13:17.517671  7680 net.cpp:406] InnerProduct1 <- Pooling1
I0117 22:13:17.517679  7680 net.cpp:380] InnerProduct1 -> InnerProduct1
I0117 22:13:17.517808  7680 net.cpp:122] Setting up InnerProduct1
I0117 22:13:17.517817  7680 net.cpp:129] Top shape: 20 16 (320)
I0117 22:13:17.517822  7680 net.cpp:137] Memory required for data: 75020000
I0117 22:13:17.517829  7680 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I0117 22:13:17.517838  7680 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I0117 22:13:17.517843  7680 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I0117 22:13:17.517850  7680 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I0117 22:13:17.517858  7680 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I0117 22:13:17.517896  7680 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I0117 22:13:17.517904  7680 net.cpp:129] Top shape: 20 16 (320)
I0117 22:13:17.517910  7680 net.cpp:129] Top shape: 20 16 (320)
I0117 22:13:17.517915  7680 net.cpp:137] Memory required for data: 75022560
I0117 22:13:17.517918  7680 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0117 22:13:17.517925  7680 net.cpp:84] Creating Layer SoftmaxWithLoss1
I0117 22:13:17.517930  7680 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I0117 22:13:17.517944  7680 net.cpp:406] SoftmaxWithLoss1 <- label_indian_1_split_0
I0117 22:13:17.517961  7680 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0117 22:13:17.517971  7680 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0117 22:13:17.518661  7680 net.cpp:122] Setting up SoftmaxWithLoss1
I0117 22:13:17.518673  7680 net.cpp:129] Top shape: (1)
I0117 22:13:17.518678  7680 net.cpp:132]     with loss weight 1
I0117 22:13:17.518689  7680 net.cpp:137] Memory required for data: 75022564
I0117 22:13:17.518694  7680 layer_factory.hpp:77] Creating layer Accuracy1
I0117 22:13:17.518702  7680 net.cpp:84] Creating Layer Accuracy1
I0117 22:13:17.518708  7680 net.cpp:406] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I0117 22:13:17.518714  7680 net.cpp:406] Accuracy1 <- label_indian_1_split_1
I0117 22:13:17.518723  7680 net.cpp:380] Accuracy1 -> Accuracy1
I0117 22:13:17.518734  7680 net.cpp:122] Setting up Accuracy1
I0117 22:13:17.518740  7680 net.cpp:129] Top shape: (1)
I0117 22:13:17.518745  7680 net.cpp:137] Memory required for data: 75022568
I0117 22:13:17.518749  7680 net.cpp:200] Accuracy1 does not need backward computation.
I0117 22:13:17.518755  7680 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I0117 22:13:17.518761  7680 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I0117 22:13:17.518766  7680 net.cpp:198] InnerProduct1 needs backward computation.
I0117 22:13:17.518771  7680 net.cpp:198] Pooling1 needs backward computation.
I0117 22:13:17.518775  7680 net.cpp:198] ReLU25 needs backward computation.
I0117 22:13:17.518780  7680 net.cpp:198] fuse2 needs backward computation.
I0117 22:13:17.518785  7680 net.cpp:198] fuse1 needs backward computation.
I0117 22:13:17.518790  7680 net.cpp:198] Scale_Convolution_eltwise8 needs backward computation.
I0117 22:13:17.518795  7680 net.cpp:198] BatchNorm_Convolution_eltwise8 needs backward computation.
I0117 22:13:17.518800  7680 net.cpp:198] Convolution_eltwise8 needs backward computation.
I0117 22:13:17.518805  7680 net.cpp:198] Scale_Convolution_eltwise4 needs backward computation.
I0117 22:13:17.518810  7680 net.cpp:198] BatchNorm_Convolution_eltwise4 needs backward computation.
I0117 22:13:17.518815  7680 net.cpp:198] Convolution_eltwise4 needs backward computation.
I0117 22:13:17.518820  7680 net.cpp:198] Eltwise12 needs backward computation.
I0117 22:13:17.518824  7680 net.cpp:198] Scale27 needs backward computation.
I0117 22:13:17.518829  7680 net.cpp:198] BatchNorm27 needs backward computation.
I0117 22:13:17.518833  7680 net.cpp:198] Convolution27 needs backward computation.
I0117 22:13:17.518838  7680 net.cpp:198] ReLU24 needs backward computation.
I0117 22:13:17.518843  7680 net.cpp:198] Scale26 needs backward computation.
I0117 22:13:17.518847  7680 net.cpp:198] BatchNorm26 needs backward computation.
I0117 22:13:17.518852  7680 net.cpp:198] Convolution26 needs backward computation.
I0117 22:13:17.518857  7680 net.cpp:198] Eltwise11_ReLU23_0_split needs backward computation.
I0117 22:13:17.518862  7680 net.cpp:198] ReLU23 needs backward computation.
I0117 22:13:17.518867  7680 net.cpp:198] Eltwise11 needs backward computation.
I0117 22:13:17.518872  7680 net.cpp:198] Scale25 needs backward computation.
I0117 22:13:17.518877  7680 net.cpp:198] BatchNorm25 needs backward computation.
I0117 22:13:17.518882  7680 net.cpp:198] Convolution25 needs backward computation.
I0117 22:13:17.518887  7680 net.cpp:198] ReLU22 needs backward computation.
I0117 22:13:17.518890  7680 net.cpp:198] Scale24 needs backward computation.
I0117 22:13:17.518895  7680 net.cpp:198] BatchNorm24 needs backward computation.
I0117 22:13:17.518899  7680 net.cpp:198] Convolution24 needs backward computation.
I0117 22:13:17.518906  7680 net.cpp:198] Eltwise10_ReLU21_0_split needs backward computation.
I0117 22:13:17.518911  7680 net.cpp:198] ReLU21 needs backward computation.
I0117 22:13:17.518916  7680 net.cpp:198] Eltwise10 needs backward computation.
I0117 22:13:17.518921  7680 net.cpp:198] Scale23 needs backward computation.
I0117 22:13:17.518929  7680 net.cpp:198] BatchNorm23 needs backward computation.
I0117 22:13:17.518939  7680 net.cpp:198] Convolution23 needs backward computation.
I0117 22:13:17.518944  7680 net.cpp:198] ReLU20 needs backward computation.
I0117 22:13:17.518949  7680 net.cpp:198] Scale22 needs backward computation.
I0117 22:13:17.518954  7680 net.cpp:198] BatchNorm22 needs backward computation.
I0117 22:13:17.518957  7680 net.cpp:198] Convolution22 needs backward computation.
I0117 22:13:17.518962  7680 net.cpp:198] Eltwise9_ReLU19_0_split needs backward computation.
I0117 22:13:17.518967  7680 net.cpp:198] ReLU19 needs backward computation.
I0117 22:13:17.518972  7680 net.cpp:198] Eltwise9 needs backward computation.
I0117 22:13:17.518978  7680 net.cpp:198] Scale21 needs backward computation.
I0117 22:13:17.518982  7680 net.cpp:198] BatchNorm21 needs backward computation.
I0117 22:13:17.518987  7680 net.cpp:198] Convolution21 needs backward computation.
I0117 22:13:17.519001  7680 net.cpp:198] ReLU18 needs backward computation.
I0117 22:13:17.519004  7680 net.cpp:198] Scale20 needs backward computation.
I0117 22:13:17.519009  7680 net.cpp:198] BatchNorm20 needs backward computation.
I0117 22:13:17.519014  7680 net.cpp:198] Convolution20 needs backward computation.
I0117 22:13:17.519019  7680 net.cpp:198] Scale19 needs backward computation.
I0117 22:13:17.519024  7680 net.cpp:198] BatchNorm19 needs backward computation.
I0117 22:13:17.519028  7680 net.cpp:198] Convolution19 needs backward computation.
I0117 22:13:17.519034  7680 net.cpp:198] Eltwise8_ReLU17_0_split needs backward computation.
I0117 22:13:17.519039  7680 net.cpp:198] ReLU17 needs backward computation.
I0117 22:13:17.519044  7680 net.cpp:198] Eltwise8 needs backward computation.
I0117 22:13:17.519049  7680 net.cpp:198] Scale18 needs backward computation.
I0117 22:13:17.519054  7680 net.cpp:198] BatchNorm18 needs backward computation.
I0117 22:13:17.519068  7680 net.cpp:198] Convolution18 needs backward computation.
I0117 22:13:17.519073  7680 net.cpp:198] ReLU16 needs backward computation.
I0117 22:13:17.519076  7680 net.cpp:198] Scale17 needs backward computation.
I0117 22:13:17.519081  7680 net.cpp:198] BatchNorm17 needs backward computation.
I0117 22:13:17.519086  7680 net.cpp:198] Convolution17 needs backward computation.
I0117 22:13:17.519091  7680 net.cpp:198] Eltwise7_ReLU15_0_split needs backward computation.
I0117 22:13:17.519096  7680 net.cpp:198] ReLU15 needs backward computation.
I0117 22:13:17.519100  7680 net.cpp:198] Eltwise7 needs backward computation.
I0117 22:13:17.519107  7680 net.cpp:198] Scale16 needs backward computation.
I0117 22:13:17.519112  7680 net.cpp:198] BatchNorm16 needs backward computation.
I0117 22:13:17.519117  7680 net.cpp:198] Convolution16 needs backward computation.
I0117 22:13:17.519122  7680 net.cpp:198] ReLU14 needs backward computation.
I0117 22:13:17.519127  7680 net.cpp:198] Scale15 needs backward computation.
I0117 22:13:17.519131  7680 net.cpp:198] BatchNorm15 needs backward computation.
I0117 22:13:17.519136  7680 net.cpp:198] Convolution15 needs backward computation.
I0117 22:13:17.519141  7680 net.cpp:198] Eltwise6_ReLU13_0_split needs backward computation.
I0117 22:13:17.519146  7680 net.cpp:198] ReLU13 needs backward computation.
I0117 22:13:17.519151  7680 net.cpp:198] Eltwise6 needs backward computation.
I0117 22:13:17.519156  7680 net.cpp:198] Scale14 needs backward computation.
I0117 22:13:17.519161  7680 net.cpp:198] BatchNorm14 needs backward computation.
I0117 22:13:17.519165  7680 net.cpp:198] Convolution14 needs backward computation.
I0117 22:13:17.519170  7680 net.cpp:198] ReLU12 needs backward computation.
I0117 22:13:17.519176  7680 net.cpp:198] Scale13 needs backward computation.
I0117 22:13:17.519179  7680 net.cpp:198] BatchNorm13 needs backward computation.
I0117 22:13:17.519184  7680 net.cpp:198] Convolution13 needs backward computation.
I0117 22:13:17.519188  7680 net.cpp:198] Eltwise5_ReLU11_0_split needs backward computation.
I0117 22:13:17.519193  7680 net.cpp:198] ReLU11 needs backward computation.
I0117 22:13:17.519206  7680 net.cpp:198] Eltwise5 needs backward computation.
I0117 22:13:17.519210  7680 net.cpp:198] Scale12 needs backward computation.
I0117 22:13:17.519215  7680 net.cpp:198] BatchNorm12 needs backward computation.
I0117 22:13:17.519219  7680 net.cpp:198] Convolution12 needs backward computation.
I0117 22:13:17.519224  7680 net.cpp:198] ReLU10 needs backward computation.
I0117 22:13:17.519229  7680 net.cpp:198] Scale11 needs backward computation.
I0117 22:13:17.519233  7680 net.cpp:198] BatchNorm11 needs backward computation.
I0117 22:13:17.519238  7680 net.cpp:198] Convolution11 needs backward computation.
I0117 22:13:17.519243  7680 net.cpp:198] Scale10 needs backward computation.
I0117 22:13:17.519248  7680 net.cpp:198] BatchNorm10 needs backward computation.
I0117 22:13:17.519253  7680 net.cpp:198] Convolution10 needs backward computation.
I0117 22:13:17.519258  7680 net.cpp:198] Eltwise4_ReLU9_0_split needs backward computation.
I0117 22:13:17.519263  7680 net.cpp:198] ReLU9 needs backward computation.
I0117 22:13:17.519268  7680 net.cpp:198] Eltwise4 needs backward computation.
I0117 22:13:17.519273  7680 net.cpp:198] Scale9 needs backward computation.
I0117 22:13:17.519278  7680 net.cpp:198] BatchNorm9 needs backward computation.
I0117 22:13:17.519282  7680 net.cpp:198] Convolution9 needs backward computation.
I0117 22:13:17.519287  7680 net.cpp:198] ReLU8 needs backward computation.
I0117 22:13:17.519291  7680 net.cpp:198] Scale8 needs backward computation.
I0117 22:13:17.519296  7680 net.cpp:198] BatchNorm8 needs backward computation.
I0117 22:13:17.519300  7680 net.cpp:198] Convolution8 needs backward computation.
I0117 22:13:17.519313  7680 net.cpp:198] Eltwise3_ReLU7_0_split needs backward computation.
I0117 22:13:17.519320  7680 net.cpp:198] ReLU7 needs backward computation.
I0117 22:13:17.519325  7680 net.cpp:198] Eltwise3 needs backward computation.
I0117 22:13:17.519330  7680 net.cpp:198] Scale7 needs backward computation.
I0117 22:13:17.519335  7680 net.cpp:198] BatchNorm7 needs backward computation.
I0117 22:13:17.519340  7680 net.cpp:198] Convolution7 needs backward computation.
I0117 22:13:17.519343  7680 net.cpp:198] ReLU6 needs backward computation.
I0117 22:13:17.519357  7680 net.cpp:198] Scale6 needs backward computation.
I0117 22:13:17.519362  7680 net.cpp:198] BatchNorm6 needs backward computation.
I0117 22:13:17.519366  7680 net.cpp:198] Convolution6 needs backward computation.
I0117 22:13:17.519372  7680 net.cpp:198] Eltwise2_ReLU5_0_split needs backward computation.
I0117 22:13:17.519378  7680 net.cpp:198] ReLU5 needs backward computation.
I0117 22:13:17.519383  7680 net.cpp:198] Eltwise2 needs backward computation.
I0117 22:13:17.519393  7680 net.cpp:198] Scale5 needs backward computation.
I0117 22:13:17.519399  7680 net.cpp:198] BatchNorm5 needs backward computation.
I0117 22:13:17.519404  7680 net.cpp:198] Convolution5 needs backward computation.
I0117 22:13:17.519409  7680 net.cpp:198] ReLU4 needs backward computation.
I0117 22:13:17.519413  7680 net.cpp:198] Scale4 needs backward computation.
I0117 22:13:17.519418  7680 net.cpp:198] BatchNorm4 needs backward computation.
I0117 22:13:17.519423  7680 net.cpp:198] Convolution4 needs backward computation.
I0117 22:13:17.519428  7680 net.cpp:198] Eltwise1_ReLU3_0_split needs backward computation.
I0117 22:13:17.519433  7680 net.cpp:198] ReLU3 needs backward computation.
I0117 22:13:17.519438  7680 net.cpp:198] Eltwise1 needs backward computation.
I0117 22:13:17.519443  7680 net.cpp:198] Scale3 needs backward computation.
I0117 22:13:17.519448  7680 net.cpp:198] BatchNorm3 needs backward computation.
I0117 22:13:17.519453  7680 net.cpp:198] Convolution3 needs backward computation.
I0117 22:13:17.519457  7680 net.cpp:198] ReLU2 needs backward computation.
I0117 22:13:17.519462  7680 net.cpp:198] Scale2 needs backward computation.
I0117 22:13:17.519466  7680 net.cpp:198] BatchNorm2 needs backward computation.
I0117 22:13:17.519471  7680 net.cpp:198] Convolution2 needs backward computation.
I0117 22:13:17.519479  7680 net.cpp:198] Convolution1_ReLU1_0_split needs backward computation.
I0117 22:13:17.519490  7680 net.cpp:198] ReLU1 needs backward computation.
I0117 22:13:17.519493  7680 net.cpp:198] Scale1 needs backward computation.
I0117 22:13:17.519498  7680 net.cpp:198] BatchNorm1 needs backward computation.
I0117 22:13:17.519503  7680 net.cpp:198] Convolution1 needs backward computation.
I0117 22:13:17.519508  7680 net.cpp:200] label_indian_1_split does not need backward computation.
I0117 22:13:17.519515  7680 net.cpp:200] indian does not need backward computation.
I0117 22:13:17.519518  7680 net.cpp:242] This network produces output Accuracy1
I0117 22:13:17.519523  7680 net.cpp:242] This network produces output SoftmaxWithLoss1
I0117 22:13:17.519592  7680 net.cpp:255] Network initialization done.
I0117 22:13:17.519878  7680 solver.cpp:56] Solver scaffolding done.
I0117 22:13:17.526067  7680 caffe.cpp:248] Starting Optimization
I0117 22:13:17.526082  7680 solver.cpp:272] Solving DFFN
I0117 22:13:17.526087  7680 solver.cpp:273] Learning Rate Policy: multistep
I0117 22:13:17.531054  7680 solver.cpp:330] Iteration 0, Testing net (#0)
I0117 22:13:20.753160  7680 solver.cpp:397]     Test net output #0: Accuracy1 = 1
I0117 22:13:20.753208  7680 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 87.3362 (* 1 = 87.3362 loss)
I0117 22:13:20.906934  7680 solver.cpp:218] Iteration 0 (0 iter/s, 3.38076s/1000 iters), loss = 2.75875
I0117 22:13:20.907001  7680 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.75875 (* 1 = 2.75875 loss)
I0117 22:13:20.907032  7680 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I0117 22:14:39.295800  7680 solver.cpp:218] Iteration 1000 (12.7571 iter/s, 78.388s/1000 iters), loss = 0.000747399
I0117 22:14:39.295903  7680 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000747442 (* 1 = 0.000747442 loss)
I0117 22:14:39.295914  7680 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I0117 22:15:58.050515  7680 solver.cpp:218] Iteration 2000 (12.6983 iter/s, 78.7507s/1000 iters), loss = 0.000263053
I0117 22:15:58.050658  7680 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000263096 (* 1 = 0.000263096 loss)
I0117 22:15:58.050670  7680 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I0117 22:17:17.122773  7680 solver.cpp:218] Iteration 3000 (12.6472 iter/s, 79.0686s/1000 iters), loss = 0.000180057
I0117 22:17:17.122907  7680 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0001801 (* 1 = 0.0001801 loss)
I0117 22:17:17.122922  7680 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I0117 22:18:35.686074  7680 solver.cpp:218] Iteration 4000 (12.7291 iter/s, 78.5602s/1000 iters), loss = 0.000223501
I0117 22:18:35.686275  7680 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000223544 (* 1 = 0.000223544 loss)
I0117 22:18:35.686295  7680 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I0117 22:19:53.878201  7680 solver.cpp:218] Iteration 5000 (12.7895 iter/s, 78.1892s/1000 iters), loss = 0.000264674
I0117 22:19:53.878362  7680 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000264717 (* 1 = 0.000264717 loss)
I0117 22:19:53.878377  7680 sgd_solver.cpp:46] MultiStep Status: Iteration 5000, step = 1
I0117 22:19:53.878386  7680 sgd_solver.cpp:105] Iteration 5000, lr = 0.01
I0117 22:21:11.728399  7680 solver.cpp:218] Iteration 6000 (12.8456 iter/s, 77.8476s/1000 iters), loss = 0.000537559
I0117 22:21:11.728564  7680 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000537602 (* 1 = 0.000537602 loss)
I0117 22:21:11.728579  7680 sgd_solver.cpp:105] Iteration 6000, lr = 0.01
I0117 22:22:29.580745  7680 solver.cpp:218] Iteration 7000 (12.8452 iter/s, 77.85s/1000 iters), loss = 0.000439984
I0117 22:22:29.580914  7680 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000440027 (* 1 = 0.000440027 loss)
I0117 22:22:29.580929  7680 sgd_solver.cpp:105] Iteration 7000, lr = 0.01
I0117 22:23:47.430287  7680 solver.cpp:218] Iteration 8000 (12.8456 iter/s, 77.8474s/1000 iters), loss = 0.000286212
I0117 22:23:47.430387  7680 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000286254 (* 1 = 0.000286254 loss)
I0117 22:23:47.430397  7680 sgd_solver.cpp:105] Iteration 8000, lr = 0.01
I0117 22:25:05.286958  7680 solver.cpp:218] Iteration 9000 (12.8444 iter/s, 77.8548s/1000 iters), loss = 0.000288975
I0117 22:25:05.287102  7680 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000289017 (* 1 = 0.000289017 loss)
I0117 22:25:05.287118  7680 sgd_solver.cpp:105] Iteration 9000, lr = 0.01
I0117 22:26:23.146452  7680 solver.cpp:218] Iteration 10000 (12.8439 iter/s, 77.8577s/1000 iters), loss = 0.000328582
I0117 22:26:23.146587  7680 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000328624 (* 1 = 0.000328624 loss)
I0117 22:26:23.146598  7680 sgd_solver.cpp:46] MultiStep Status: Iteration 10000, step = 2
I0117 22:26:23.146605  7680 sgd_solver.cpp:105] Iteration 10000, lr = 0.001
I0117 22:27:40.994796  7680 solver.cpp:218] Iteration 11000 (12.8458 iter/s, 77.8466s/1000 iters), loss = 0.00018253
I0117 22:27:40.994864  7680 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000182572 (* 1 = 0.000182572 loss)
I0117 22:27:40.994874  7680 sgd_solver.cpp:105] Iteration 11000, lr = 0.001
I0117 22:28:59.222424  7680 solver.cpp:218] Iteration 12000 (12.7835 iter/s, 78.2261s/1000 iters), loss = 0.000288336
I0117 22:28:59.222524  7680 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000288379 (* 1 = 0.000288379 loss)
I0117 22:28:59.222535  7680 sgd_solver.cpp:105] Iteration 12000, lr = 0.001
I0117 22:30:17.103114  7680 solver.cpp:218] Iteration 13000 (12.8404 iter/s, 77.8792s/1000 iters), loss = 0.000196379
I0117 22:30:17.103214  7680 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000196422 (* 1 = 0.000196422 loss)
I0117 22:30:17.103226  7680 sgd_solver.cpp:105] Iteration 13000, lr = 0.001
I0117 22:31:34.949414  7680 solver.cpp:218] Iteration 14000 (12.8461 iter/s, 77.8449s/1000 iters), loss = 0.000157785
I0117 22:31:34.949584  7680 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000157828 (* 1 = 0.000157828 loss)
I0117 22:31:34.949599  7680 sgd_solver.cpp:105] Iteration 14000, lr = 0.001
I0117 22:32:52.515373  7680 solver.cpp:218] Iteration 15000 (12.8925 iter/s, 77.5646s/1000 iters), loss = 0.00023243
I0117 22:32:52.515547  7680 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000232473 (* 1 = 0.000232473 loss)
I0117 22:32:52.515563  7680 sgd_solver.cpp:46] MultiStep Status: Iteration 15000, step = 3
I0117 22:32:52.515570  7680 sgd_solver.cpp:105] Iteration 15000, lr = 0.0001
I0117 22:34:10.083837  7680 solver.cpp:218] Iteration 16000 (12.8921 iter/s, 77.5671s/1000 iters), loss = 0.000232593
I0117 22:34:10.084000  7680 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000232635 (* 1 = 0.000232635 loss)
I0117 22:34:10.084015  7680 sgd_solver.cpp:105] Iteration 16000, lr = 0.0001
I0117 22:35:27.615514  7680 solver.cpp:218] Iteration 17000 (12.8982 iter/s, 77.5304s/1000 iters), loss = 0.000530417
I0117 22:35:27.615679  7680 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000530459 (* 1 = 0.000530459 loss)
I0117 22:35:27.615694  7680 sgd_solver.cpp:105] Iteration 17000, lr = 0.0001
I0117 22:36:45.296911  7680 solver.cpp:218] Iteration 18000 (12.8733 iter/s, 77.6801s/1000 iters), loss = 0.000492429
I0117 22:36:45.297077  7680 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000492472 (* 1 = 0.000492472 loss)
I0117 22:36:45.297093  7680 sgd_solver.cpp:105] Iteration 18000, lr = 0.0001
I0117 22:38:03.107424  7680 solver.cpp:218] Iteration 19000 (12.8519 iter/s, 77.8093s/1000 iters), loss = 0.000288134
I0117 22:38:03.107590  7680 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000288177 (* 1 = 0.000288177 loss)
I0117 22:38:03.107606  7680 sgd_solver.cpp:105] Iteration 19000, lr = 0.0001
I0117 22:39:20.851471  7680 solver.cpp:447] Snapshotting to binary proto file ./snapshot/indian_pines/_iter_20000.caffemodel
I0117 22:39:20.866451  7680 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshot/indian_pines/_iter_20000.solverstate
I0117 22:39:20.886524  7680 solver.cpp:310] Iteration 20000, loss = 0.00030105
I0117 22:39:20.886550  7680 solver.cpp:330] Iteration 20000, Testing net (#0)
I0117 22:39:24.041996  7680 solver.cpp:397]     Test net output #0: Accuracy1 = 0.985142
I0117 22:39:24.042039  7680 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.0450013 (* 1 = 0.0450013 loss)
I0117 22:39:24.042045  7680 solver.cpp:315] Optimization Done.
I0117 22:39:24.042050  7680 caffe.cpp:259] Optimization Done.
